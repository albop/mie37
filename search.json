[
  {
    "objectID": "notes.html",
    "href": "notes.html",
    "title": "A few things to remember",
    "section": "",
    "text": "A few things to remember\nHere is a very important one: \\[e^{-i \\pi} = -1\\]"
  },
  {
    "objectID": "pushups/Exam_mie37_2023.html",
    "href": "pushups/Exam_mie37_2023.html",
    "title": "Final Exam 2023",
    "section": "",
    "text": "Name:\nSurname:\nAfter completing the following questions, send the edited notebook to pwinant@escp.eu. You are allowed to use any available resource (but not copy/paste any code). Also, don’t forget to comment your code and take any initiative, you find relevant."
  },
  {
    "objectID": "pushups/Exam_mie37_2023.html#power-iteration-method",
    "href": "pushups/Exam_mie37_2023.html#power-iteration-method",
    "title": "Final Exam 2023",
    "section": "Power iteration method",
    "text": "Power iteration method\nIn this exercise, we implement a power iteration method power_iteration(M::Matrix) to compute the biggest eigenvalue of a given matrix M.\nDefine a random 3 times 3 matrix M. Compute its biggest eigenvalue using LinearAlgebra: eigvals.\nDefine a norm2 function, which computes the euclidean norm of any vector. Test it on some simple cases.\n\n\n\nWrite a function iteration_step(M::Matrix, u::Vector)::Tuple{Float64, Vector} which takes a random vector \\(u\\) with norm 1 and returns \\(M u\\) and \\(\\frac{M u}{|M u|}\\).\nWrite a function power_iteration(M::Matrix)::Float64, which computes the spectral radius of M using the power iteration method (spectral radius: absolute value of biggest eigenvalue)\nCheck the result is correct on matrix \\(M\\)."
  },
  {
    "objectID": "pushups/Exam_mie37_2023.html#doubling-algorithm",
    "href": "pushups/Exam_mie37_2023.html#doubling-algorithm",
    "title": "Final Exam 2023",
    "section": "Doubling algorithm",
    "text": "Doubling algorithm\nLet \\(M\\) be a square matrix with spectral radius smaller than 1. Our goal here to approximate the infinite sum \\(\\sum_{t\\geq 0} M^t\\) (whose result is a matrix).\nDefine a (non-trivial) 3x3 matrix M with spectral radius smaller than 1.\nPropose an algorithm and a function infinite_sum(M::Matrix) to approximate this sum by computing the limit of \\(S_T = \\sum_{t=0}^{T} M^t\\) when \\(T\\) goes to \\(\\infty\\).\nWe now consider the doubling algorithm. Consider the sum \\(D_N = \\sum_{t\\geq 0}^{2^N} M^t\\). Find a recursive relation between \\(D_N\\) and \\(D_{N+1}\\). Why is \\(D_N\\) less expensive to compute than \\(S^{2 N}\\) ?\nImplement a function infinite_sum_doubling(M::Matrix) which computes the infinite sum using the doubling algorithm. Check the result and time it against the other implementation."
  },
  {
    "objectID": "pushups/Exam_mie37_2023.html#reduced-form-new-keyesian-model",
    "href": "pushups/Exam_mie37_2023.html#reduced-form-new-keyesian-model",
    "title": "Final Exam 2023",
    "section": "Reduced-form New Keyesian model",
    "text": "Reduced-form New Keyesian model\nWe consider the reduced-form New Keynesian Model\n\\[\\pi_t = \\alpha E_t \\pi_{t+1} + y_t\\]\n\\[y_t = \\beta E_t y_{t+1} + \\gamma (i_t-\\pi_t) + \\delta z_t\\]\n\\[i_t = \\alpha_{y} y_t + \\alpha_{\\pi} \\pi_t\\]\nwhere \\(\\pi_t\\) is inflation, \\(y_t\\) the output gap (i.e, the gap to full employment), and \\(z_t\\) an AR1 process given by:\n\\[z_t = \\rho z_{t-1} + \\epsilon_t\\]\nwher \\(\\epsilon_t\\) is a random gaussian process with standard deviation \\(\\sigma_{\\epsilon}\\).\nWe’ll take \\(\\alpha=0.9\\), \\(\\beta=0.9\\), \\(\\gamma=0.1\\), \\(\\alpha_{\\pi}=0.5\\), \\(\\alpha_y=0.5\\), \\(\\rho=0.9\\) and \\(\\sigma=0.01\\).\n\nModel Solution\nDefine a specialized structure to hold all model parameters.\nDefine matrices \\(A\\) (2x2) and \\(B\\) (2x1) such that:\n\\[\\begin{bmatrix}\\pi_t\\\\y_t\\end{bmatrix} = A E_t \\begin{bmatrix}\\pi_{t+1}\\\\y_{t+1}\\end{bmatrix} + B z_t\\]\n\n# text\n\n\n# code\nfunction create_matrices(parameters)\n#     A = ...\n#     B = ...\n    return A, B\nend\n\nAssume the sequence \\(z_0, z_1, ...\\) is known, show that we can write \\(\\begin{bmatrix}\\pi_t\\\\y_t\\end{bmatrix}=\\sum_{s\\geq0} \\rho^s A^s B z_s\\). At which condition on \\(A\\) is this sum absolutely converging?\nCheck that this condition is met for the baseline calibration.\nBonus: find conditions on \\(\\alpha_y\\) and \\(\\alpha_{\\pi}\\) for the sum to be convergent. When it is, in this context, we say that inflation is anchored.\nCompute the solution to the system, that is find two sacalars \\(x_y\\) and \\(x_{\\pi}\\) such that \\(y_t(z) = x_{y} z_t\\) and \\(\\pi_t(z)= x_{\\pi} z_t\\) solve the system.\nCompute matrices \\(P\\) and \\(Q\\) such that \\(\\begin{bmatrix}\\pi_t\\\\y_t\\\\z_t\\end{bmatrix} =  P \\begin{bmatrix}\\pi_{t-1}\\\\y_{t-1}\\\\z_{t-1}\\end{bmatrix} + Q \\epsilon_t\\).\nSimulate variables \\(\\pi_t, y_t, z_t\\) when \\(\\pi_0 =  y_0 = 0, z_0=0.1\\) and \\(\\forall t, \\epsilon_t = 0\\).\nMake \\(N=1000\\) stochastic simulations for \\(T=200\\) periods. Find a way to compute the standard deviation of the ergodic distribution."
  },
  {
    "objectID": "students/pablo/1_epidemiology.html",
    "href": "students/pablo/1_epidemiology.html",
    "title": "Tutorial: Epidemiology Models",
    "section": "",
    "text": "H.W. Heathcote: epidemiologic models are deterministic models for infectious diseases which are spread by direct person-to-person contact in a population.\nThis kind of models has been used since by a few decades by economist, for matters that have nothing to do with health.\n\ndiffusion of information, or opinions on social medias\nasset prices and fads\nexpectation formation for macroeconomic outcomes (ex: The Epidemiology of Macroeconomic Expectations by Chris Carroll)\n\nEpidemiologic models have two features that depart from standard economic models:\n\nAgent’s behaviour does not take the full system into account, an is irrational in the sense that it isn’t forward looking. Instead, an agent is given a behavioural heuristic.\nThe transitions of the whole system can be determined without solving for complex interactions first.\n\nUnderstanding why these two assumptions are very costly for economists will keep us busy during a big part of the course. Here we just consider two simple models as small programming exercises.\n\n\nThere is a continuum of agents of mass \\(1\\). Each agent can be either “Susceptible” (S), “Infected” (I) or “Recovered” (R). In each period, one agent meets another agent drawn randomly. During a meeting Susceptible agents who meet an infected agent, will always catch the disease (or the fad) but are not contagious. Infected agents, have a probability \\(\\pi\\) of being recovered. Nothing happens to Recovered agents who meet other people. No distinction is made between recovering as a healthy or a dead person.\nWe’re interested in the evolution in the number infected persons, both the speed of infection and the total amount of infected people in every period.\nWrite down the transition equations for \\(n_I\\), the number of infected people, for \\(n_R\\) the number of recovered people and \\(n_S\\) the number of susceptible people.\nCompute the transition function f for the vector state \\(s_t\\) returning \\(s_{t+1}\\).\nCompute the transitions over \\(T\\) periods. Plot the result using Plots.jl. (bonus: check against closed form solution)\nWe now assume a Susceptible person who meets an infected one has a probability \\(\\mu\\) of catching the disease. Update the transition function. Update function \\(f\\) and write a function of \\(\\mu\\), \\(\\pi\\) which returns the simulation. Compare different values of the parameters. How would you interpret “social distancing”? How would you choose parameters \\(\\Pi\\) and \\(\\mu\\)\n\n\n\nWe now consider another version of the model where agents evolve in the space \\(\\mathcal{S}=[0,1]\\times[0,1]\\). There are \\(N\\in\\mathbb{N}\\) agent. At any date, each agent \\(n \\in [0,1]\\) is located at \\((x_n,y_n)\\in \\mathcal{S}\\).\nEach agent moves follows a random walk bounded by \\(\\mathcal{S}\\): \\[x_t = \\min(\\max( x_{t-1} + \\epsilon_t, 0), 1)\\] \\[y_t = \\min(\\max( y_{t-1} + \\eta_t, 0), 1)\\] where \\(\\epsilon_t\\) and \\(\\eta_t\\) are both normally distributed with standard deviation \\(\\sigma\\).\nAt any date, the individual state of an agent is \\(s_t=(x_t, y_t, h_t)\\) where \\(h_t\\) is either “S”, “I” or “R”. \\(v_t\\) denotes the states of all agents (for instance \\(v_t=(s_{n,t})_n\\). The health status of each agent is updated in the following way:\n\nAgents \\(R\\) stay \\(R\\).\nAgents \\(I\\) have probability \\(\\pi\\) to become \\(R\\). They stay \\(I\\) otherwise.\nAn agent of type \\(S\\) in position \\((x,y)\\) has a probability \\(prob(x,y,S)\\) to be infected that is \\(\\mu\\) if there is another infected agent within a radius \\(r&gt;0\\).\n\nDefine a type Agent, which holds the type of an agent. The state of the whole system will be held in a Vector[Agent] type.\nWrite a function spatial_transition(S::Vector{Agent})::Vector{Agent} to compute the transition of the positions. Write another function random_guess(T=100) which simulates for \\(T\\) periods in order to find a good initial guess.\nWrite a function show_population to plot all agents with different colors for different health status.\nWrite a function evolve(S::Vector[Agent])::Vector[Agent] which takes the population in a given state and returns the same population with updated health status.\nWrite a function simulate(S0::Vector[Agent], k=1) to simulate the economy starting from an initially random position with k infected individuals. The returned object should be of type Vector[Vector[Agent]].\nCompute statistics along a simulated path for \\(n_I\\), \\(n_S\\), \\(n_R\\). Plot and compare with the basic SIR model\n\n\n\nHave fun by trying to answer one of these questions: - change probability of infection so that it depends on the number of infected people in the vincinity (with some suitable functional formulation for) - compute an animation of the transition - compute an interactive visualisation (with Interact.jl if available)"
  },
  {
    "objectID": "students/pablo/1_epidemiology.html#advanced-macroeconomics-numerical-methods-mie37",
    "href": "students/pablo/1_epidemiology.html#advanced-macroeconomics-numerical-methods-mie37",
    "title": "Tutorial: Epidemiology Models",
    "section": "",
    "text": "H.W. Heathcote: epidemiologic models are deterministic models for infectious diseases which are spread by direct person-to-person contact in a population.\nThis kind of models has been used since by a few decades by economist, for matters that have nothing to do with health.\n\ndiffusion of information, or opinions on social medias\nasset prices and fads\nexpectation formation for macroeconomic outcomes (ex: The Epidemiology of Macroeconomic Expectations by Chris Carroll)\n\nEpidemiologic models have two features that depart from standard economic models:\n\nAgent’s behaviour does not take the full system into account, an is irrational in the sense that it isn’t forward looking. Instead, an agent is given a behavioural heuristic.\nThe transitions of the whole system can be determined without solving for complex interactions first.\n\nUnderstanding why these two assumptions are very costly for economists will keep us busy during a big part of the course. Here we just consider two simple models as small programming exercises.\n\n\nThere is a continuum of agents of mass \\(1\\). Each agent can be either “Susceptible” (S), “Infected” (I) or “Recovered” (R). In each period, one agent meets another agent drawn randomly. During a meeting Susceptible agents who meet an infected agent, will always catch the disease (or the fad) but are not contagious. Infected agents, have a probability \\(\\pi\\) of being recovered. Nothing happens to Recovered agents who meet other people. No distinction is made between recovering as a healthy or a dead person.\nWe’re interested in the evolution in the number infected persons, both the speed of infection and the total amount of infected people in every period.\nWrite down the transition equations for \\(n_I\\), the number of infected people, for \\(n_R\\) the number of recovered people and \\(n_S\\) the number of susceptible people.\nCompute the transition function f for the vector state \\(s_t\\) returning \\(s_{t+1}\\).\nCompute the transitions over \\(T\\) periods. Plot the result using Plots.jl. (bonus: check against closed form solution)\nWe now assume a Susceptible person who meets an infected one has a probability \\(\\mu\\) of catching the disease. Update the transition function. Update function \\(f\\) and write a function of \\(\\mu\\), \\(\\pi\\) which returns the simulation. Compare different values of the parameters. How would you interpret “social distancing”? How would you choose parameters \\(\\Pi\\) and \\(\\mu\\)\n\n\n\nWe now consider another version of the model where agents evolve in the space \\(\\mathcal{S}=[0,1]\\times[0,1]\\). There are \\(N\\in\\mathbb{N}\\) agent. At any date, each agent \\(n \\in [0,1]\\) is located at \\((x_n,y_n)\\in \\mathcal{S}\\).\nEach agent moves follows a random walk bounded by \\(\\mathcal{S}\\): \\[x_t = \\min(\\max( x_{t-1} + \\epsilon_t, 0), 1)\\] \\[y_t = \\min(\\max( y_{t-1} + \\eta_t, 0), 1)\\] where \\(\\epsilon_t\\) and \\(\\eta_t\\) are both normally distributed with standard deviation \\(\\sigma\\).\nAt any date, the individual state of an agent is \\(s_t=(x_t, y_t, h_t)\\) where \\(h_t\\) is either “S”, “I” or “R”. \\(v_t\\) denotes the states of all agents (for instance \\(v_t=(s_{n,t})_n\\). The health status of each agent is updated in the following way:\n\nAgents \\(R\\) stay \\(R\\).\nAgents \\(I\\) have probability \\(\\pi\\) to become \\(R\\). They stay \\(I\\) otherwise.\nAn agent of type \\(S\\) in position \\((x,y)\\) has a probability \\(prob(x,y,S)\\) to be infected that is \\(\\mu\\) if there is another infected agent within a radius \\(r&gt;0\\).\n\nDefine a type Agent, which holds the type of an agent. The state of the whole system will be held in a Vector[Agent] type.\nWrite a function spatial_transition(S::Vector{Agent})::Vector{Agent} to compute the transition of the positions. Write another function random_guess(T=100) which simulates for \\(T\\) periods in order to find a good initial guess.\nWrite a function show_population to plot all agents with different colors for different health status.\nWrite a function evolve(S::Vector[Agent])::Vector[Agent] which takes the population in a given state and returns the same population with updated health status.\nWrite a function simulate(S0::Vector[Agent], k=1) to simulate the economy starting from an initially random position with k infected individuals. The returned object should be of type Vector[Vector[Agent]].\nCompute statistics along a simulated path for \\(n_I\\), \\(n_S\\), \\(n_R\\). Plot and compare with the basic SIR model\n\n\n\nHave fun by trying to answer one of these questions: - change probability of infection so that it depends on the number of infected people in the vincinity (with some suitable functional formulation for) - compute an animation of the transition - compute an interactive visualisation (with Interact.jl if available)"
  },
  {
    "objectID": "tutorials/3_perturbation_neoclassical_correction.html",
    "href": "tutorials/3_perturbation_neoclassical_correction.html",
    "title": "Perturbation of Neoclassical Model",
    "section": "",
    "text": "Our goal here is to compute a linear approximation of solution to the neoclassical model, close ot the steady-state.\n\nWarm-up: install the ForwardDiff library. Use it to differentiate the function below. Check the jacobian function.\nNote: the signature of function f needs to be fixed first to allow for dual numbers as arguments.\n\n# function f(x::Vector{T}) where T &lt;: Number\nfunction f(x::Vector{&lt;:Number}) # equivalent\n    a = x[1]\n    b = x[2]\n    x1 = a+b\n    x2 = a*exp(b)\n    return [x1,x2]\nend\n\nf (generic function with 4 methods)\n\n\n\nusing ForwardDiff\n\n\nForwardDiff.jacobian(f, [0.2, 0.4])\n\n2×2 Matrix{Float64}:\n 1.0      1.0\n 1.49182  0.298365\n\n\nCreate a NamedTuple to hold the model parameters.\n\nparameters = (;\n    α=0.3,\n    β=0.96,\n    γ=4.0,\n    δ=0.1,\n    ρ=0.9\n)\n\n(α = 0.3, β = 0.96, γ = 4.0, δ = 0.1, ρ = 0.9)\n\n\nDefine two functions: - transition(z::Number, k::Number, i::Number, p)::Tuple{Number} which returns productivity and capital at date t+1 as a function of productivity, capital and investment at date t - arbitrage(z::Number, k::Number, i::Number, Z::Number, K::Number, I::Number, p)::Number which returns the residual of the euler equation (lower case variable for date t, upper case for date t+1)\n\nfunction transition(z::Number, k::Number, i::Number, p)\n\n        Z = p.ρ * z\n        K = (1-p.δ) * k + i\n\n        (;Z, K)\n\nend\n\ntransition (generic function with 1 method)\n\n\n\nfunction arbitrage(z::Number, k::Number, i::Number, Z::Number, K::Number, I::Number, p)\n\n    # positional unpacking (error-prone)\n    # α, β, γ, δ, ρ = p\n    \n    (;α, β, γ, δ, ρ) = p\n\n    # define auxiliary variables today\n    y = exp(z)k^α\n    c = y - i\n\n    # define auxiliary variables tomorrow\n    Y = exp(Z)K^α\n    C = Y - I\n\n    residual = β*(C/c)^(-γ)*( (1-δ) + α*K^(α-1)*exp(Z)) - 1\n\n    return residual\n\n\nend\n\narbitrage (generic function with 1 method)\n\n\nUsing multiple dispatch, define two variants of the same functions, that take vectors as input and output arguments: - arbitrage(s::Vector{T}, x::Vector{T}, S::Vector{T}, X::Vector{T}, p) where T&lt;:Number - transition(s::Vector{T}, x::Vector{T}, p) where T&lt;:Number\n\n# this returns a number\n# arbitrage(s::Vector{T}, x::Vector{T}, S::Vector{T}, X::Vector{T}, p) where T&lt;:Number = arbitrage(s[1],s[2],x[1],S[1],S[2],X[1],p)\n\n\n[2.4]   # create a vector from  a number\n\n1-element Vector{Float64}:\n 2.4\n\n\n\narbitrage(s::Vector{T}, x::Vector{T}, S::Vector{T}, X::Vector{T}, p) where T&lt;:Number = [\n    arbitrage(s[1],s[2],x[1],S[1],S[2],X[1],p)\n]\n\narbitrage (generic function with 2 methods)\n\n\n\n# this returns a tuple\n# transition(s::Vector{T}, x::Vector{T}, p) where T&lt;: Number = transition(s[1], s[2], x[1], p)\n\n\nt = (1,2,3)\n\n(1, 2, 3)\n\n\n\n# to convert into a tuple into a vector\n[t...]\n\n3-element Vector{Int64}:\n 1\n 2\n 3\n\n\n\ntransition(s::Vector{T}, x::Vector{T}, p) where T&lt;: Number = [transition(s[1], s[2], x[1], p)...]\n\ntransition (generic function with 2 methods)\n\n\nWrite a function steady_state(p)::Tuple{Vector,Vector} which computes the steady-state of the model computed by hand. It returns two vectors, one for the states, one for the controls. Check that the steady-state satisfies the model equations.\n\nfunction steady_state(p)\n    (;α, β, γ, δ, ρ) = p\n\n    # ...\n    z = 0.0\n\n    k = ((1/β - (1-δ))/α)^ (1/(α-1))\n    i = δ*k\n\n    s = [z,k] # vector of states\n    x = [i]  # vector controls\n\n    return (;\n        s,\n        x\n    )\n\n\nend\n\nsteady_state (generic function with 1 method)\n\n\n\nq = steady_state(parameters)\n\n(s = [0.0, 2.920822149964071], x = [0.29208221499640713])\n\n\n\n# check the steady-state is correct using the functions representing the model\n\n\nmethods(transition)\n\n# 2 methods for generic function transition from \u001b[35mMain\u001b[39m: transition(z::Number, k::Number, i::Number, p) in Main at /home/pablo/Teaching/ensae/mie37/tutorials/3_perturbation_neoclassical.ipynb:1  transition(s::Vector{T}, x::Vector{T}, p) where T&lt;:Number in Main at /home/pablo/Teaching/ensae/mie37/tutorials/3_perturbation_neoclassical.ipynb:1 \n\n\n\n@assert maximum(transition(q.s, q.x, parameters) - q.s) == 0.0\n\n\n@assert maximum(arbitrage(q.s, q.x, q.s, q.x, parameters)) == 0.0\n\nThe first order system satisfies: \\[\\begin{align}A s_t + B x_t + C s_{t+1} + D x_{t+1} & = & 0 \\\\\\\\\ns_{t+1} & = & E s_t + F x_t\n\\end{align}\\]\nDefine a structure PerturbedModel to hold matrices A,B,C,D,E,F.\n\nstruct PerturbedModel\n    A::Matrix\n    B::Matrix\n    C::Matrix\n    D::Matrix\n    E::Matrix\n    F::Matrix\n\nend\n\nWrite a function first_order_model(s::Vector, x::Vector, p)::PerturbedModel, which returns the first order model, given the steady-state and the calibration. Suggestion: use ForwardDiff.jl library.\n\n# we need to loosen the constraint on the arbitrage arguments:\n\n# brutal\narbitrage(s, x, S, X, p) where T&lt;:Number = [\n    arbitrage(s[1],s[2],x[1],S[1],S[2],X[1],p)\n]\n\n\n# more precise\n# arbitrage(s::Vector{&lt;:Number}, x::Vector{&lt;:Number}, S::Vector{&lt;:Number}, X::Vector{&lt;:Number}, p) = [\n#     arbitrage(s[1],s[2],x[1],S[1],S[2],X[1],p)\n# ]\n\nWARNING: method definition for arbitrage at /home/pablo/Teaching/ensae/mie37/tutorials/3_perturbation_neoclassical.ipynb:4 declares type variable T but does not use it.\n\n\narbitrage (generic function with 3 methods)\n\n\n\narbitrage(s,x,s,x,parameters)\n\nUndefVarError: UndefVarError: `s` not defined\nUndefVarError: `s` not defined\n\n\n\nStacktrace:\n\n [1] top-level scope\n\n   @ ~/Teaching/ensae/mie37/tutorials/3_perturbation_neoclassical.ipynb:1\n\n\n\ntransition(s, x, p) where T&lt;: Number = [transition(s[1], s[2], x[1], p)...]\n\nWARNING: method definition for transition at /home/pablo/Teaching/ensae/mie37/tutorials/3_perturbation_neoclassical.ipynb:1 declares type variable T but does not use it.\n\n\ntransition (generic function with 3 methods)\n\n\n\nusing ForwardDiff\n\n\nfunction first_order_model(s, x, parameters)\n\n    A = ForwardDiff.jacobian(  u-&gt;arbitrage(u, x, s, x, parameters), s    )\n    B = ForwardDiff.jacobian(  u-&gt;arbitrage(s, u, s, x, parameters), x    )\n    C = ForwardDiff.jacobian(  u-&gt;arbitrage(s, x, u, x, parameters), s    )\n    D = ForwardDiff.jacobian(  u-&gt;arbitrage(s, x, s, u, parameters), x    )\n    E = ForwardDiff.jacobian(  u-&gt;transition(u, x, parameters), s    )\n    F = ForwardDiff.jacobian(  u-&gt;transition(s, u, parameters), x    )\n\n    return PerturbedModel(A,B,C,D,E,F)\n\nend\n\nfirst_order_model (generic function with 1 method)\n\n\n\n@time model = first_order_model(q.s, q.x, parameters)\n\n  1.343581 seconds (7.27 M allocations: 474.892 MiB, 7.63% gc time, 99.95% compilation time)\n\n\nPerturbedModel([5.074626865671642 0.5212190203776081], [-3.679193085018409;;], [-4.938626865671642 -0.5538125831185546], [3.679193085018409;;], [0.9 0.0; 0.0 0.9], [0.0; 1.0;;])\n\n\nWe look for a linear solution \\(x_t = X s_t\\) . Write the matrix equation which X must satisfy. Write a function residual(X::Array, M::PerturbedModel) which computes the residual of this equation for a given X.\n\nfunction residual(X::Matrix, M::PerturbedModel)\n    (;A,B,C,D,E,F) = M # keyword unpacking\n    return A + B*X + (C+D*X)*(E+F*X)\nend\n\nresidual (generic function with 1 method)\n\n\n\nX0 = zeros(1, 2)\nresidual(X0, model)\n\n1×2 Matrix{Float64}:\n 0.629863  0.0227877\n\n\nWrite a function T(X, M::PerturbedModel) which implements the time iteration step.\n\nfunction T(X::Matrix, M::PerturbedModel)\n    (;A,B,C,D,E,F) = M # keyword unpacking\n\n    C_DX = (C+D*X)\n\n    return -(B+C_DX*F) \\ (A+C_DX*E)\n    # return  -solve(B+C_DX*F ,   (A+C_DX*E))\n    # return  -inv(B+C_DX*F)*(A+C_DX*E)) # not ok\nend\n\nT (generic function with 1 method)\n\n\n\nT(X0, model)\n\n1×2 Matrix{Float64}:\n 0.148798  0.00538334\n\n\nWrite function linear_time_iteration(X_0::Matrix, m::PerturbedModel)::Matrix which implements the time iteration algorithm. Apply it to X0 = rand(1,2) and check that the result satisfies the first order model.\n\nA = rand(10000, 10000);\nB = rand(10000, 10000);\n\n\ndistance(A,B) = sum(abs(e1-e2) for (e1, e2) in zip(A,B))\n\ndistance (generic function with 1 method)\n\n\n\nfunction linear_time_iteration(X_0, M; N=5, τ_η=1e-8, verbose=true)\n\n    η_0 = 1.0\n\n    for n in 1:N\n\n        X = T(X_0, M)\n\n        # successive approximation error\n        η = distance(X, X_0)\n\n\n        # ratio of successive approximation errors\n        λ = η/η_0\n\n        if verbose\n            println(n, \" : \", η, \" : \", λ)\n        end\n\n        # η_0 will be the value from last iteration\n        η_0 = η\n\n        if η&lt;τ_η\n            return X\n        end\n\n        X_0 = X\n    end\n\n    error(\"No convergence\")\n\nend\n\nlinear_time_iteration (generic function with 1 method)\n\n\n\n@time sol = linear_time_iteration(X0, model; N=500)\n\n1 : 0.15418131543048902 : 0.15418131543048902\n2 : 0.12190031209691013 : 0.7906296022741327\n3 : 0.0971923112531961 : 0.7973097819136732\n4 : 0.07801352484927856 : 0.802671773552593\n5 : 0.06295682833902616 : 0.8069988948795506\n6 : 0.05102689044058986 : 0.8105060529067174\n7 : 0.04150316170984929 : 0.8133586301554283\n8 : 0.033853524549360574 : 0.815685435871905\n9 : 0.027678228788813052 : 0.8175878038476156\n10 : 0.022672513753932016 : 0.8191461211960124\n11 : 0.018601088097577975 : 0.8204246030880477\n12 : 0.01528032593947912 : 0.8214748438006029\n13 : 0.01256560026933672 : 0.8223384971698489\n14 : 0.010342108838667052 : 0.8230493264937326\n15 : 0.008518120644127804 : 0.8236347902547955\n16 : 0.007019930424960394 : 0.8241172810577381\n17 : 0.005788038650448812 : 0.8245151020113518\n18 : 0.004774224564889556 : 0.8248432419364298\n19 : 0.0039392795027168095 : 0.8251139947808338\n20 : 0.003251234928149705 : 0.8253374572450166\n21 : 0.0026839657341018452 : 0.8255219304097795\n22 : 0.0022160813815156506 : 0.8256742451509851\n23 : 0.0018300400639542705 : 0.8258000266680848\n24 : 0.001511437244487067 : 0.8259039101150711\n25 : 0.0012484316214957068 : 0.8259897167741055\n26 : 0.001031280172156878 : 0.8260605982739636\n27 : 0.0008519603042240476 : 0.8261191548386015\n28 : 0.0007038619422192541 : 0.8261675323715003\n29 : 0.000581536017211115 : 0.826207502251863\n30 : 0.00048048862532256223 : 0.8262405269872226\n31 : 0.00039701228622349843 : 0.8262678142629821\n32 : 0.0003280474254938187 : 0.8262903614754736\n33 : 0.0002710685376324101 : 0.8263089924402341\n34 : 0.00022399054337329805 : 0.8263243876611255\n35 : 0.00018509169812225973 : 0.8263371093028231\n36 : 0.00015295008455855352 : 0.8263476218016245\n37 : 0.00012639126731726208 : 0.826356308870663\n38 : 0.00010444512845603215 : 0.826363487549012\n39 : 8.631026020181412e-5 : 0.8263694197872312\n40 : 7.132458275916145e-5 : 0.8263743220375822\n41 : 5.894109266629463e-5 : 0.8263783731524711\n42 : 4.870784159012598e-5 : 0.8263817209140318\n43 : 4.0251404707945804e-5 : 0.8263844874642432\n44 : 3.3263228473082856e-5 : 0.8263867736898273\n45 : 2.7488354905323004e-5 : 0.8263886630116805\n46 : 2.2716107776505484e-5 : 0.826390224323923\n47 : 1.8772398710901333e-5 : 0.8263915145849502\n48 : 1.551337101909217e-5 : 0.8263925808311001\n49 : 1.2820148383725638e-5 : 0.826393461997911\n50 : 1.0594496141231452e-5 : 0.8263941901546545\n51 : 8.755236434329627e-6 : 0.8263947919388228\n52 : 7.235286145202552e-6 : 0.8263952892046078\n53 : 5.979209359931875e-6 : 0.8263957001751017\n54 : 4.94119493606518e-6 : 0.8263960397803294\n55 : 4.083385313793236e-6 : 0.8263963204505664\n56 : 3.374495545591105e-6 : 0.8263965524371217\n57 : 2.788672131517206e-6 : 0.8263967439994704\n58 : 2.304550011482387e-6 : 0.826396902467187\n59 : 1.9044732927631092e-6 : 0.8263970333792274\n60 : 1.5738512852726816e-6 : 0.8263971415368372\n61 : 1.300626344003658e-6 : 0.8263972309037538\n62 : 1.074834105267708e-6 : 0.8263973048239941\n63 : 8.882400730839124e-7 : 0.826397365631303\n64 : 7.340393016162794e-7 : 0.8263974164864485\n65 : 6.066082128101946e-7 : 0.8263974578397988\n66 : 5.012995060102443e-7 : 0.8263974925230678\n67 : 4.1427266909629945e-7 : 0.826397521101554\n68 : 3.4235391643128166e-7 : 0.8263975443470543\n69 : 2.8292044249381143e-7 : 0.8263975637930232\n70 : 2.338047691008427e-7 : 0.8263975803231571\n71 : 1.9321569839914066e-7 : 0.8263975929242252\n72 : 1.596729903574623e-7 : 0.8263976047516254\n73 : 1.3195337798116435e-7 : 0.826397612305991\n74 : 1.0904595768024272e-7 : 0.8263976212553532\n75 : 9.011532065353323e-8 : 0.8263976269324892\n76 : 7.44710876507404e-8 : 0.826397632618539\n77 : 6.154273075875683e-8 : 0.8263976356486713\n78 : 5.085876750646201e-8 : 0.8263976407843324\n79 : 4.202956567153637e-8 : 0.8263976445397774\n80 : 3.473313383434151e-8 : 0.8263976388855188\n81 : 2.870338035310116e-8 : 0.8263976550460705\n82 : 2.372040580275736e-8 : 0.8263976406595807\n83 : 1.9602487667802482e-8 : 0.8263976523337474\n84 : 1.619944979894261e-8 : 0.8263976528627315\n85 : 1.33871871400848e-8 : 0.8263976435149435\n86 : 1.1063140292755236e-8 : 0.8263976724153838\n87 : 9.142552898772083e-9 : 0.8263976282357315\n  0.188574 seconds (380.90 k allocations: 25.696 MiB, 5.04% gc time, 99.17% compilation time)\n\n\n1×2 Matrix{Float64}:\n 0.768674  0.0278097\n\n\n\nresidual(sol, model)\n\n1×2 Matrix{Float64}:\n 3.01193e-8  1.08968e-9\n\n\nCheck blanchard Kahn Conditions\n\n# check that solution is not diverging\n# let's check the transition matrix has spectral radius smaller than 1\n\n\nusing LinearAlgebra\n\n\nfunction bk_check(X, M)\n    (;A,B,C,D,E,F) = M # keyword unpacking\n\n    P = E+F*X\n    maximum(abs,eigvals(P))\n\n    # can check the solution is unique by computing the first \"rejected\" eigenvalue\n\n\nend\n\nbk_check (generic function with 1 method)\n\n\n\nbk_check(sol, model)\n\n4.13068831324392\n\n\nDefine two linear operators L_S(U::Union{Vector, Matrix}, X_0::Matrix, m::PerturbedModel)::Matrix and L_T(U::Matrix, X_0::Matrix, m::PerturbedModel)::Matrix which implement the derivatives of the simulation and the time-iteration operator respectively.\nImplement a function spectral_radius(f::Function)::Float64 which implements the power iteration method to compute the biggest eigenvalues of the two previously defined operators. Check that Blanchard-Kahn conditions are met.\nWrite a function simulate(s0::Vector, X::Matrix, p, T::Int64)::Tuple{Matrix, Matrix} to simulate the model over \\(T\\) periods (by using the formula \\(\\Delta s_t = (E + F X) \\Delta s_{t-1}\\). Return a matrix for the states (one line per date) and another matrix for the controls. Bonus: add a keyword option to compute variables levels or log-deviations. If possible, return a DataFrame object.\n\nP = model.E + model.F*sol\n\n2×2 Matrix{Float64}:\n 0.9       0.0\n 0.768674  0.92781\n\n\nMake some nice plots."
  },
  {
    "objectID": "tutorials/2_solow_pablo.html",
    "href": "tutorials/2_solow_pablo.html",
    "title": "Convergence of Sequences",
    "section": "",
    "text": "Tutorial: Convergence\n\nSolow Model\nA representative agent uses capital \\(k_t\\) to produce \\(y_t\\) using the following production function:\n\\[y_t = k_t^{\\alpha}\\]\nHe chooses to consume an amount \\(c_t \\in ]0, y_t]\\) and invests what remains:\n\\[i_t = y_t - c_t\\]\nHe accumulates capital \\(k_t\\) according to:\n\\[k_{t+1} = \\left( 1-\\delta \\right) k_{t} + i_{t}\\]\nwhere \\(\\delta\\) is the depreciation rate and \\(i_t\\) is the amount invested.\nThe goal of the representative agent is to maximize:\n\\[\\sum_{t\\geq 0} \\beta^t U(c_t)\\]\nwhere \\(U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}\\) and \\(\\beta&lt;1\\) is the discount factor.\nFor now, we ignore the objective and assume that the saving rate \\(s=\\frac{c_t}{y_t}\\) is constant over time.\n\n# # how to represent the model?\n\n# struct Model\n#     α\n#     β\n#     γ\n#     δ\n# end\n\n# model = Model(0.3, 0.9, 4, 0.1)\n\nModel(0.3, 0.9, 4, 0.1)\n\n\n\n# model_2 = recalibrate(model; α=0.3)\n\nModel(0.3, 0.9)\n\n\nCreate a NamedTuple to hold parameter values \\(\\beta=0.96\\), \\(\\delta=0.1\\), \\(\\alpha=0.3\\), \\(\\gamma=4\\).\n\nmodel = (;α=0.3, β=0.1, γ=4.0, δ=0.1  )\n\n(α = 0.3, β = 0.1, γ = 4.0, δ = 0.1)\n\n\n\nmodel.α\n\n0.3\n\n\n\nmodel_2 = merge(model, (;α=0.4))\n\n(α = 0.4, β = 0.1, γ = 4.0, δ = 0.1)\n\n\n\n# why not a dictionary\ntypeof(model) # each named typle has its own type (based on names)\n\nNamedTuple{(:α, :β, :γ, :δ), NTuple{4, Float64}}\n\n\nWrite down the formula of function \\(f\\) such that \\(k_{t+1}\\): \\(k_{t+1} = f(k_t)\\).\nThe equation for capital transition is: \\(...\\)\nDefine a function f(k::Float64, p::NamedTuple)::Float64 to represent \\(f\\) for a given calibration\n\nfunction f(k, model; s=0.3)\n\n    # α = model.α\n    # β = model.β\n    # γ = model.γ\n    # δ = model.δ\n\n    # specialized syntax to \"unpack\" values from namedtuples\n    (;α,β,γ,δ) = model\n\n    y = k^α\n    i = s*y\n    K = (1-δ)*k + i\n\n    return K\n\nend\n\nf (generic function with 1 method)\n\n\n\nf(0.5, model; s=0.4)\n\n0.7749009585424942\n\n\nWrite a function simulate(k0::Float64, T::Int, p::NamedTuple)::Vector{Float64} to compute the simulation over T periods starting from initial capital level k0.\n\n# let' s add saving rate as named argumetn\n\nfunction simulate(k0, model; s=0.4, T=100)\n    \n    res = [k0]\n    for t=1:T\n        k = res[end]\n        K = f(k, model; s=s)\n        push!(res, K)\n    end\n\n    return res\n\nend\n\nsimulate (generic function with 2 methods)\n\n\n\nsim = simulate(0.5, model)\n\n101-element Vector{Float64}:\n 0.5\n 0.7749009585424942\n 1.0679497992469396\n 1.3691220146661789\n 1.6717439771875893\n 1.9712406953317936\n 2.2644391998184954\n 2.5491450744662236\n 2.8238676158995952\n 3.087632556067258\n ⋮\n 7.234413529429885\n 7.235209646662481\n 7.2359500610507625\n 7.236638668366576\n 7.23727909214093\n 7.237874702658239\n 7.238428634629446\n 7.238943803635337\n 7.2394229214251595\n\n\n\nsimulate(k0, model, T; s=0.4) = simulate(k0, model; s=s, T=T)\n\nsimulate (generic function with 2 methods)\n\n\n\nmethods(simulate)\n\n# 2 methods for generic function simulate from \u001b[35mMain\u001b[39m: simulate(k0, model; s, T) in Main at /home/pablo/Teaching/ensae/mie37/tutorials/2_solow_pablo.ipynb:3  simulate(k0, model, T; s) in Main at /home/pablo/Teaching/ensae/mie37/tutorials/2_solow_pablo.ipynb:1 \n\n\nMake a nice plot to illustrate the convergence. Do we get convergence from any initial level of capital?\n\n# different libraries. Main options:\n# Plots.jl -&gt; different backends, including matplotlib\n# Makie.jl -&gt; fast with easy animations\n\n\nusing Plots\n\n\nplot(sim)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsim_1 = simulate(0.5, model; s=0.3)\nsim_2 = simulate(0.5, model; s=0.4)\nsim_3 = simulate(0.5, model; s=0.5)\n\n101-element Vector{Float64}:\n 0.5\n 0.8561261981781177\n 1.2477475382753753\n 1.6573008927807404\n 2.073393171590884\n 2.4883176067712327\n 2.8967527254553693\n 3.2950061580751355\n 3.680539839343968\n 4.051654372933684\n ⋮\n 9.949900641171165\n 9.951039677408726\n 9.952099018857133\n 9.95308423905062\n 9.954000522065433\n 9.954852689688693\n 9.95564522669805\n 9.956382304382648\n 9.957067802427053\n\n\n\npl = plot(title=\"Convergence in Solow Model\")\nplot!(pl, sim_1; label=\"s=0.3\")\nplot!(pl, sim_2; label=\"s=0.4\")\nplot!(pl, sim_3; label=\"s=0.5\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose you were interested in using f to compute the steady-state. What would you propose to measure convergence speed? To speed-up convergence? Implement these ideas."
  },
  {
    "objectID": "tutorials/3_perturbation_neoclassical.html",
    "href": "tutorials/3_perturbation_neoclassical.html",
    "title": "Perturbation of Neoclassical Model",
    "section": "",
    "text": "Our goal here is to compute a linear approximation of solution to the neoclassical model, close ot the steady-state.\n\nWarm-up: install the ForwardDiff library. Use it to differentiate the function below. Check the jacobian function.\nNote: the signature of function f needs to be fixed first to allow for dual numbers as arguments.\n\n# function f(x::Vector{T}) where T &lt;: Number\nfunction f(x)\n    a = x[1]\n    b = x[2]\n    x1 = a+b\n    x2 = a*exp(b)\n    return [x1,x2]\nend\n\nf (generic function with 2 methods)\n\n\n\nusing ForwardDiff\nx0 = [0.21, 1//2]\nf(x0)\n\nForwardDiff.jacobian(f,x0)\n\n2×2 Matrix{Float64}:\n 1.0      1.0\n 1.64872  0.346231\n\n\nCreate a NamedTuple to hold the model parameters.\n\nmodel = (α = 0.3, β = 0.96,  ρ = 0.9, γ = 4.0, δ = 0.1,)\n\n(α = 0.3, β = 0.96, ρ = 0.9, γ = 4.0, δ = 0.1)\n\n\n\ntypeof(model)\n\n@NamedTuple{α::Float64, β::Float64, γ::Float64, δ::Float64, ρ::Float64}\n\n\nDefine two functions: - transition(z::Number, k::Number, i::Number, p)::Tuple{Number} which returns productivity and capital at date t+1 as a function of productivity, capital and investment at date t - arbitrage(z::Number, k::Number, i::Number, Z::Number, K::Number, I::Number, p)::Number which returns the residual of the euler equation (lower case variable for date t, upper case for date t+1)\n\nfunction transition(z, k, i, model)\n    (;α, β, γ, δ, ρ) = model\n    z_new = ρ*z\n    k_new = (1-δ)*k + i\n    return (z_new, k_new)\nend\n    \n\ntransition (generic function with 1 method)\n\n\n\nfunction arbitrage(z, k, i, Z, K, I, model)\n\n    (;α, β, γ, δ, ρ) = model\n\n    y = exp(z)*k^α\n    c = y - i\n    Y = exp(Z)*K^α\n    C = Y - I\n    \n    r = β*(C/c)^(-γ)*( (1-δ) + α*exp(Z)*K^(α-1) ) - 1\n\n    return r\n\nend\n\narbitrage (generic function with 2 methods)\n\n\nUsing multiple dispatch, define two variants of the same functions, that take vectors as input and output arguments: - arbitrage(s::Vector{T}, x::Vector{T}, S::Vector{T}, X::Vector{T}, p) where T&lt;:Number - transition(s::Vector{T}, x::Vector{T}, p) where T&lt;:Number\n\nfunction transition(s::Vector{T},x::Vector{U},model) where T&lt;:Number where U&lt;:Number\n    r = transition(s[1],s[2],x[1],model)\n    # return [r[1], r[2]]\n    return [r...]\nend\n\ntransition (generic function with 2 methods)\n\n\n\ntransition(m.s,m.x, model)\n\n2-element Vector{Float64}:\n 0.0\n 2.920822149964071\n\n\n\nfunction arbitrage(s,x,S,X,model)\n    r = arbitrage(s[1],s[2],x[1],S[1],S[2],X[1],model)\n    return [r]\nend\n\narbitrage (generic function with 3 methods)\n\n\nWrite a function steady_state(p)::Tuple{Vector,Vector} which computes the steady-state of the model computed by hand. It returns two vectors, one for the states, one for the controls. Check that the steady-state satisfies the model equations.\n\nfunction steady_state(model)\n    (;α, β, γ, δ, ρ) = model\n    k = (( 1/β - (1-δ)) / α )^ (1/(α-1))\n    z = 0.0\n    i = δ*k\n    return (;\n        s = [z,k],\n        x = [i],\n    )\nend\n\nsteady_state (generic function with 1 method)\n\n\n\nm = steady_state(model)\n\nr1 = arbitrage(m.s, m.x, m.s, m.x, model)\nr2 = transition(m.s, m.x, model) - m.s\n[r1,r2]\n\n@assert maximum(abs, [r1; r2]) &lt; 1e-12\n\nThe first order system satisfies: \\[\\begin{align}A s_t + B x_t + C s_{t+1} + D x_{t+1} & = & 0 \\\\\\\\\ns_{t+1} & = & E s_t + F x_t\n\\end{align}\\]\nDefine a structure PerturbedModel to hold matrices A,B,C,D,E,F.\n\nimport ForwardDiff: jacobian\n\n\nA = jacobian(u-&gt;arbitrage(u, m.x, m.s, m.x, model), m.s)\nB = jacobian(u-&gt;arbitrage(m.s, u, m.s, m.x, model), m.x)\nC = jacobian(u-&gt;arbitrage(m.s, m.x, u, m.x, model), m.s)\nD = jacobian(u-&gt;arbitrage(m.s, m.x, m.s, u, model), m.x)\nE = jacobian(u-&gt;transition(u, m.x, model), m.s)\nF = jacobian(u-&gt;transition(m.s, u, model), m.x)\n\n2×1 Matrix{Float64}:\n 0.0\n 1.0\n\n\n\n\n\n(A = [5.074626865671642 0.5212190203776081], B = [-3.679193085018409;;], C = [-4.938626865671642 -0.5538125831185546], D = [3.679193085018409;;], E = [0.9 0.0; 0.0 0.9], F = [0.0; 1.0;;])\n\n\nWrite a function first_order_model(s::Vector, x::Vector, p)::PerturbedModel, which returns the first order model, given the steady-state and the calibration. Suggestion: use ForwardDiff.jl library.\n\nfunction first_order_model(model)\n    m = steady_state(model)\n    A = jacobian(u-&gt;arbitrage(u, m.x, m.s, m.x, model), m.s)\n    B = jacobian(u-&gt;arbitrage(m.s, u, m.s, m.x, model), m.x)\n    C = jacobian(u-&gt;arbitrage(m.s, m.x, u, m.x, model), m.s)\n    D = jacobian(u-&gt;arbitrage(m.s, m.x, m.s, u, model), m.x)\n    E = jacobian(u-&gt;transition(u, m.x, model), m.s)\n    F = jacobian(u-&gt;transition(m.s, u, model), m.x)\n    pm = (;A, B, C, D, E, F)\n    pm\nend\n\nfirst_order_model (generic function with 1 method)\n\n\n\nfirst_order_model(merge(model, (;α=0.2)))\n\n(A = [4.6575342465753415 0.6053173918792945], B = [-4.272828648559724;;], C = [-4.521534246575342 -0.6760184632507961], D = [4.272828648559724;;], E = [0.9 0.0; 0.0 0.9], F = [0.0; 1.0;;])\n\n\nWe look for a linear solution \\(x_t = X s_t\\) . Write the matrix equation which X must satisfy. Write a function residual(X::Array, M::PerturbedModel) which computes the residual of this equation for a given X.\n\nresidual(X::Array, M)  = M.A + M.B*X + (M.C+M.D*X)*(M.E+M.F*X)\n\nresidual (generic function with 1 method)\n\n\nWrite a function T(X, M::PerturbedModel) which implements the time iteration step.\n\nT(X, M) = - (B+(C+D*X)*F) \\ (A+(C+D*X)*E)\n\nT (generic function with 1 method)\n\n\nWrite function linear_time_iteration(X_0::Matrix, m::PerturbedModel)::Matrix which implements the time iteration algorithm. Apply it to X0 = rand(1,2) and check that the result satisfies the first order model.\n\nfunction linear_time_iteration(M; TT=200)\n    nx, ns = size(M.A)\n    X0 = rand(nx, ns)\n    for t=1:TT\n\n        X = T(X0, M)\n        r = residual(X,M)\n        ϵ= maximum(abs,r)\n        println(t, ϵ)\n        if ϵ&lt;1e-10 \n            return X\n        end\n        X0 = X\n    end\n\n    error(\"No convergence\")\n\n\n\n\nend\n\nlinear_time_iteration (generic function with 1 method)\n\n\nCheck blanchard Kahn Conditions\n\nM = first_order_model(model)\n\n(A = [5.074626865671642 0.5212190203776081], B = [-3.679193085018409;;], C = [-4.938626865671642 -0.5538125831185546], D = [3.679193085018409;;], E = [0.9 0.0; 0.0 0.9], F = [0.0; 1.0;;])\n\n\n\nlinear_time_iteration(M)\n\n132.50570793314876\n210.455512505432662\n31.9466036686389936\n40.9287841848793645\n50.5970565928183014\n60.4386101972004859\n70.34512711663380324\n80.28217302112220377\n90.23593757247082392\n100.1999610141445829\n110.1708632158035548\n120.14671240459370383\n130.12631996092750652\n140.10890566120863943\n150.09392679583513797\n160.08098577929560458\n170.06977783639770285\n180.060060235812492646\n190.051633602213620566\n200.04433022883245341\n210.038006555509233486\n220.03253817699504857\n230.02781641354569553\n240.023745859597579688\n250.02024255316404\n260.0172325456218263\n270.014650735639557322\n280.012439883089379045\n290.010549751162809429\n300.008936344979571409\n310.007561227293772177\n320.006390899327732402\n330.005396239121463253\n340.0045519922426331405\n350.003836311007448856\n360.00323033899607017\n370.0027178379089787263\n380.002284853889691796\n390.0019194204454136\n400.001611295093300047\n410.001351726877772741\n420.0011332519568290067\n430.0009495145444757824\n440.000795110618227568\n450.0006654519482678367\n460.0005566481706718029\n470.0004654048037391334\n480.0003889352874364427\n490.0003248853059747425\n500.00027126782837472163\n510.00022640746855007166\n520.00018889292281487613\n530.00015753638752835641\n540.00013133899222594891\n550.00010946140386947079\n569.119886607455996e-5\n577.596003383314454e-5\n586.324905002186298e-5\n595.2650385693464585e-5\n604.381603262348932e-5\n613.645469470381357e-5\n623.0322675377281172e-5\n632.521620221651588e-5\n642.096496770853662e-5\n651.742669806636954e-5\n661.4482590021458464e-5\n671.2033479718898121e-5\n689.996628493436077e-6\n698.303027978939781e-6\n706.895142039997637e-6\n715.725015829405322e-6\n724.752693176346412e-6\n733.944892712937076e-6\n743.2739010031868077e-6\n752.7166475389250877e-6\n762.253932073426057e-6\n771.8697794725852646e-6\n781.550901268299043e-6\n791.2862464315865907e-6\n801.0666267296066678e-6\n818.844043821731873e-7\n827.332317570885039e-7\n836.078344969573379e-7\n845.038308832361338e-7\n854.1758143876080567e-7\n863.4606372745216163e-7\n872.867681665463806e-7\n882.3761134482214175e-7\n891.9686392294104849e-7\n901.6309067474296057e-7\n911.3510063912036685e-7\n921.1190568782737387e-7\n939.268608858192806e-8\n947.6761896394828e-8\n956.356918635930242e-8\n965.2640311665186346e-8\n974.35875118220963e-8\n983.6089302657416056e-8\n992.9879175134084335e-8\n1002.4736217962839646e-8\n1012.047733405063923e-8\n1021.6950784331726254e-8\n1031.4030824946331677e-8\n1041.1613267236754155e-8\n1059.611787366026192e-9\n1067.954870984150375e-9\n1076.583275702354285e-9\n1085.447930107038701e-9\n1094.508190265539724e-9\n1103.730394215750721e-9\n1113.086666477969402e-9\n1122.553921962800132e-9\n1132.1130466265617542e-9\n1141.7482140179936323e-9\n1151.4463208408699302e-9\n1161.1965197721508503e-9\n1179.898299957455947e-10\n1188.188179023704834e-10\n1196.773301919338337e-10\n1205.602740493770852e-10\n1214.634341799203412e-10\n1223.833213746418096e-10\n1233.1704905367746505e-10\n1242.6222757298910437e-10\n1252.1687940332526523e-10\n1261.793694082152797e-10\n1271.4834311556910507e-10\n1281.2268097648870935e-10\n1291.014557327039256e-10\n1308.390088623855263e-11\n\n\n1×2 Matrix{Float64}:\n 0.768674  0.0278097\n\n\nDefine two linear operators L_S(U::Union{Vector, Matrix}, X_0::Matrix, m::PerturbedModel)::Matrix and L_T(U::Matrix, X_0::Matrix, m::PerturbedModel)::Matrix which implement the derivatives of the simulation and the time-iteration operator respectively.\nImplement a function spectral_radius(f::Function)::Float64 which implements the power iteration method to compute the biggest eigenvalues of the two previously defined operators. Check that Blanchard-Kahn conditions are met.\nWrite a function simulate(s0::Vector, X::Matrix, p, T::Int64)::Tuple{Matrix, Matrix} to simulate the model over \\(T\\) periods (by using the formula \\(\\Delta s_t = (E + F X) \\Delta s_{t-1}\\). Return a matrix for the states (one line per date) and another matrix for the controls. Bonus: add a keyword option to compute variables levels or log-deviations. If possible, return a DataFrame object.\nMake some nice plots.",
    "crumbs": [
      "Tutorials",
      "Perturbation of Neoclassical Model"
    ]
  },
  {
    "objectID": "tutorials/6_discrete_dynamic_programming.html",
    "href": "tutorials/6_discrete_dynamic_programming.html",
    "title": "Discrete Dynamic Programming",
    "section": "",
    "text": "A worker’s employment dynamics obey the stochastic matrix\n\\[P = \\begin{bmatrix}\n1-\\alpha & \\alpha \\\\\n\\beta & 1-\\beta\n\\end{bmatrix}\\]\n\\[P = \\begin{bmatrix}\n1-\\alpha & ... \\\\\n\\beta & ...\n\\end{bmatrix}\\]\nwith \\(\\alpha\\in(0,1)\\) and \\(\\beta\\in (0,1)\\). First line corresponds to employment, second line to unemployment.\nWhich is the stationary equilibrium? (choose any value for \\(\\alpha\\) and \\(\\beta\\))\n\nα = 0.123\nβ = 0.345\nP = [1-α α ; β 1-β]\n\n2×2 Matrix{Float64}:\n 0.877  0.123\n 0.345  0.655\n\n\n\nα = 0.123\nβ = 0.345\nγ = 0.678\nP = [α/2 1-α  α/2; 1-β β/2 β/2; γ*0.8 γ*0.2 1-γ]\n\n3×3 Matrix{Float64}:\n 0.0615  0.877   0.0615\n 0.655   0.1725  0.1725\n 0.5424  0.1356  0.322\n\n\n\nα = 0.123\nβ = 0.345\nγ = 0.678\nP = [α/2 1-α  α/2; 1-β β/2 β/2; γ*0.8 γ*0.2 1-γ]\nP\n\n3×3 Matrix{Float64}:\n 0.0615  0.877   0.0615\n 0.655   0.1725  0.1725\n 0.5424  0.1356  0.322\n\n\n\nPp = P'\n\n3×3 adjoint(::Matrix{Float64}) with eltype Float64:\n 0.0615  0.655   0.5424\n 0.877   0.1725  0.1356\n 0.0615  0.1725  0.322\n\n\n\n\n\n3-element Vector{Float64}:\n 0.41963333333333336\n 0.39503333333333335\n 0.18533333333333332\n\n\n\nμbar = μ0'*P^50 # stupid too many matrix multiplications \n\n1×3 adjoint(::Vector{Float64}) with eltype Float64:\n 0.400406  0.44903  0.150564\n\n\n\nμ0 = ones(3)/3 # initial probability vector\n\nfor t=1:40\n    μ1 = Pp * μ0\n    μ0 = μ1\nend\n\nμ0\n\n3-element Vector{Float64}:\n 0.4004056827203767\n 0.4490299796026508\n 0.1505643376769728\n\n\n\nsize(P, 1)\n\n3\n\n\n\n# refactor as a function to solve any stochastic matrix by simulation\n\nfunction solve_by_simulation(P; T=1000, τ_η=1e-10)\n\n    n = size(P, 1)\n\n    Pp = P'\n\n    μ0 = ones(n)/n # initial probability vector\n\n    for t=1:T\n        μ1 = Pp * μ0\n\n        # check whether we have a fixed point\n        # ϵ = maximum(abs, μ1 - Pp*μ1)\n        # not useful because Pp*μ1 will be computed in the next iteration\n\n        # check successsive approximation errors\n        η = maximum(abs,μ1 - μ0)\n\n        if η&lt;τ_η\n            return μ1\n        end\n\n        μ0 = μ1\n    end\n\n    error(\"No convegence\")\n\nend\n\nsolve_by_simulation (generic function with 1 method)\n\n\n\nsolve_by_simulation(P)\n\n3-element Vector{Float64}:\n 0.40040568284433287\n 0.4490299794605776\n 0.15056433769508987\n\n\n\n### Solve with linear algebra\n\n# let's solve M μ = μ by defining the appropriate M\n\n\nusing LinearAlgebra: I\n\n\nP' - I\n\n3×3 Matrix{Float64}:\n -0.9385   0.655    0.5424\n  0.877   -0.8275   0.1356\n  0.0615   0.1725  -0.678\n\n\n\n# using least square solver\nF = cat( P' - I, ones(1, 3); dims=1)\nR = zeros(4)\nR[end] = 1.0\nF \\ R # here it solves a nonsquare system\n\n3-element Vector{Float64}:\n 0.4004056828214058\n 0.44902997948685536\n 0.15056433769173883\n\n\n\n# using linear solver\nM = cat( P' - I,; dims=1)\n# replace last line with ones\nM[end,:] .= 1.0\nD = zeros(3)\nD[end] = 1.0\nM \\ D\n\n3-element Vector{Float64}:\n 0.40040568282140593\n 0.44902997948685536\n 0.15056433769173877\n\n\nIn the long run, what will the the fraction \\(p\\) of time spent unemployed? (Denote by \\(X_m\\) the fraction of dates were one is unemployed)\n\nusing Plots\n\n\nfunction forecast(P; T=100, μ0=ones(size(P,1))/size(P,1) )\n\n    sim = [μ0]\n\n    Pp = P'\n\n     # initial probability vector\n\n    for t=1:T\n        μ1 = Pp * μ0\n        push!(sim, μ1)\n\n        μ0 = μ1\n    end\n\n    return sim\nend\n\nforecast (generic function with 1 method)\n\n\n\nforecast(P)\n\n101-element Vector{Vector{Float64}}:\n [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n [0.41963333333333336, 0.39503333333333335, 0.18533333333333332]\n [0.3850790833333334, 0.4612928833333334, 0.15362803333333333]\n [0.4091570474883334, 0.4381193397783334, 0.15272361273333335]\n [0.3949686135219009, 0.4551156386456709, 0.14991574783242834]\n [0.4037056146688205, 0.4452234971311626, 0.15107088820001704]\n [0.39839013568273324, 0.45133608975960343, 0.15027377455766347]\n [0.40163462745710504, 0.4476207483073078, 0.1507446242355873]\n [0.3996560039152811, 0.44988911840923734, 0.15045487767548166]\n [0.4008629424500215, 0.4485058697720903, 0.1506311877778883]\n ⋮\n [0.4004056828214061, 0.4490299794868556, 0.15056433769173902]\n [0.40040568282140615, 0.4490299794868555, 0.15056433769173902]\n [0.4004056828214061, 0.4490299794868556, 0.15056433769173902]\n [0.40040568282140615, 0.4490299794868555, 0.15056433769173902]\n [0.4004056828214061, 0.4490299794868556, 0.15056433769173902]\n [0.40040568282140615, 0.4490299794868555, 0.15056433769173902]\n [0.4004056828214061, 0.4490299794868556, 0.15056433769173902]\n [0.40040568282140615, 0.4490299794868555, 0.15056433769173902]\n [0.4004056828214061, 0.4490299794868556, 0.15056433769173902]\n\n\nIllustrate this convergence by generating a simulated series of length 10000 starting at \\(X_0=1\\). Plot \\(X_m-p\\) against \\(m\\). (Take \\(\\alpha=\\beta=0.1\\)).",
    "crumbs": [
      "Tutorials",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "tutorials/6_discrete_dynamic_programming.html#markov-chains",
    "href": "tutorials/6_discrete_dynamic_programming.html#markov-chains",
    "title": "Discrete Dynamic Programming",
    "section": "",
    "text": "A worker’s employment dynamics obey the stochastic matrix\n\\[P = \\begin{bmatrix}\n1-\\alpha & \\alpha \\\\\n\\beta & 1-\\beta\n\\end{bmatrix}\\]\n\\[P = \\begin{bmatrix}\n1-\\alpha & ... \\\\\n\\beta & ...\n\\end{bmatrix}\\]\nwith \\(\\alpha\\in(0,1)\\) and \\(\\beta\\in (0,1)\\). First line corresponds to employment, second line to unemployment.\nWhich is the stationary equilibrium? (choose any value for \\(\\alpha\\) and \\(\\beta\\))\n\nα = 0.123\nβ = 0.345\nP = [1-α α ; β 1-β]\n\n2×2 Matrix{Float64}:\n 0.877  0.123\n 0.345  0.655\n\n\n\nα = 0.123\nβ = 0.345\nγ = 0.678\nP = [α/2 1-α  α/2; 1-β β/2 β/2; γ*0.8 γ*0.2 1-γ]\n\n3×3 Matrix{Float64}:\n 0.0615  0.877   0.0615\n 0.655   0.1725  0.1725\n 0.5424  0.1356  0.322\n\n\n\nα = 0.123\nβ = 0.345\nγ = 0.678\nP = [α/2 1-α  α/2; 1-β β/2 β/2; γ*0.8 γ*0.2 1-γ]\nP\n\n3×3 Matrix{Float64}:\n 0.0615  0.877   0.0615\n 0.655   0.1725  0.1725\n 0.5424  0.1356  0.322\n\n\n\nPp = P'\n\n3×3 adjoint(::Matrix{Float64}) with eltype Float64:\n 0.0615  0.655   0.5424\n 0.877   0.1725  0.1356\n 0.0615  0.1725  0.322\n\n\n\n\n\n3-element Vector{Float64}:\n 0.41963333333333336\n 0.39503333333333335\n 0.18533333333333332\n\n\n\nμbar = μ0'*P^50 # stupid too many matrix multiplications \n\n1×3 adjoint(::Vector{Float64}) with eltype Float64:\n 0.400406  0.44903  0.150564\n\n\n\nμ0 = ones(3)/3 # initial probability vector\n\nfor t=1:40\n    μ1 = Pp * μ0\n    μ0 = μ1\nend\n\nμ0\n\n3-element Vector{Float64}:\n 0.4004056827203767\n 0.4490299796026508\n 0.1505643376769728\n\n\n\nsize(P, 1)\n\n3\n\n\n\n# refactor as a function to solve any stochastic matrix by simulation\n\nfunction solve_by_simulation(P; T=1000, τ_η=1e-10)\n\n    n = size(P, 1)\n\n    Pp = P'\n\n    μ0 = ones(n)/n # initial probability vector\n\n    for t=1:T\n        μ1 = Pp * μ0\n\n        # check whether we have a fixed point\n        # ϵ = maximum(abs, μ1 - Pp*μ1)\n        # not useful because Pp*μ1 will be computed in the next iteration\n\n        # check successsive approximation errors\n        η = maximum(abs,μ1 - μ0)\n\n        if η&lt;τ_η\n            return μ1\n        end\n\n        μ0 = μ1\n    end\n\n    error(\"No convegence\")\n\nend\n\nsolve_by_simulation (generic function with 1 method)\n\n\n\nsolve_by_simulation(P)\n\n3-element Vector{Float64}:\n 0.40040568284433287\n 0.4490299794605776\n 0.15056433769508987\n\n\n\n### Solve with linear algebra\n\n# let's solve M μ = μ by defining the appropriate M\n\n\nusing LinearAlgebra: I\n\n\nP' - I\n\n3×3 Matrix{Float64}:\n -0.9385   0.655    0.5424\n  0.877   -0.8275   0.1356\n  0.0615   0.1725  -0.678\n\n\n\n# using least square solver\nF = cat( P' - I, ones(1, 3); dims=1)\nR = zeros(4)\nR[end] = 1.0\nF \\ R # here it solves a nonsquare system\n\n3-element Vector{Float64}:\n 0.4004056828214058\n 0.44902997948685536\n 0.15056433769173883\n\n\n\n# using linear solver\nM = cat( P' - I,; dims=1)\n# replace last line with ones\nM[end,:] .= 1.0\nD = zeros(3)\nD[end] = 1.0\nM \\ D\n\n3-element Vector{Float64}:\n 0.40040568282140593\n 0.44902997948685536\n 0.15056433769173877\n\n\nIn the long run, what will the the fraction \\(p\\) of time spent unemployed? (Denote by \\(X_m\\) the fraction of dates were one is unemployed)\n\nusing Plots\n\n\nfunction forecast(P; T=100, μ0=ones(size(P,1))/size(P,1) )\n\n    sim = [μ0]\n\n    Pp = P'\n\n     # initial probability vector\n\n    for t=1:T\n        μ1 = Pp * μ0\n        push!(sim, μ1)\n\n        μ0 = μ1\n    end\n\n    return sim\nend\n\nforecast (generic function with 1 method)\n\n\n\nforecast(P)\n\n101-element Vector{Vector{Float64}}:\n [0.3333333333333333, 0.3333333333333333, 0.3333333333333333]\n [0.41963333333333336, 0.39503333333333335, 0.18533333333333332]\n [0.3850790833333334, 0.4612928833333334, 0.15362803333333333]\n [0.4091570474883334, 0.4381193397783334, 0.15272361273333335]\n [0.3949686135219009, 0.4551156386456709, 0.14991574783242834]\n [0.4037056146688205, 0.4452234971311626, 0.15107088820001704]\n [0.39839013568273324, 0.45133608975960343, 0.15027377455766347]\n [0.40163462745710504, 0.4476207483073078, 0.1507446242355873]\n [0.3996560039152811, 0.44988911840923734, 0.15045487767548166]\n [0.4008629424500215, 0.4485058697720903, 0.1506311877778883]\n ⋮\n [0.4004056828214061, 0.4490299794868556, 0.15056433769173902]\n [0.40040568282140615, 0.4490299794868555, 0.15056433769173902]\n [0.4004056828214061, 0.4490299794868556, 0.15056433769173902]\n [0.40040568282140615, 0.4490299794868555, 0.15056433769173902]\n [0.4004056828214061, 0.4490299794868556, 0.15056433769173902]\n [0.40040568282140615, 0.4490299794868555, 0.15056433769173902]\n [0.4004056828214061, 0.4490299794868556, 0.15056433769173902]\n [0.40040568282140615, 0.4490299794868555, 0.15056433769173902]\n [0.4004056828214061, 0.4490299794868556, 0.15056433769173902]\n\n\nIllustrate this convergence by generating a simulated series of length 10000 starting at \\(X_0=1\\). Plot \\(X_m-p\\) against \\(m\\). (Take \\(\\alpha=\\beta=0.1\\)).",
    "crumbs": [
      "Tutorials",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "tutorials/6_discrete_dynamic_programming.html#basic-asset-pricing-model",
    "href": "tutorials/6_discrete_dynamic_programming.html#basic-asset-pricing-model",
    "title": "Discrete Dynamic Programming",
    "section": "Basic Asset Pricing model",
    "text": "Basic Asset Pricing model\nA financial asset yields dividend \\((x_t)\\), which follows an AR1. It is evaluated using the stochastic discount factor: \\(\\rho_{0,t} = \\beta^t \\exp(y_t)\\) where \\(\\beta&lt;1\\) and \\(y_t\\) is an \\(AR1\\). The price of the asset is given by \\(p_0 = \\sum_{t\\geq 0} \\rho_{0,t} U(x_t)\\) where \\(U(u)=\\exp(u)^{0.5}/{0.5}\\). Our goal is to find the pricing function \\(p(x,y)\\), which yields the price of the asset in any state.\nWrite down the recursive equation which must be satisfied by \\(p\\).\n\\[p_t = U(x_t) + \\beta E_t \\left[ \\frac{e^{y_{t+1}}}{e^{y_t}} p_{t+1} \\right]\\]\nCompute the ergodic distribution of \\(x\\) and \\(y\\).\nDiscretize processes \\((x_t)\\) and \\((y_t)\\) using 2 states each. How would you represent the unknown \\(p()\\)?\nSolve for \\(p()\\) using successive approximations\nSolve for \\(p()\\) by solving a linear system (homework)",
    "crumbs": [
      "Tutorials",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "tutorials/6_discrete_dynamic_programming.html#asset-replacement-from-compecon",
    "href": "tutorials/6_discrete_dynamic_programming.html#asset-replacement-from-compecon",
    "title": "Discrete Dynamic Programming",
    "section": "Asset replacement (from Compecon)",
    "text": "Asset replacement (from Compecon)\nAt the beginning of each year, a manufacturer must decide whether to continue to operate an aging physical asset or replace it with a new one.\nAn asset that is \\(a\\) years old yields a profit contribution \\(p(a)\\) up to \\(n\\) years, at which point, the asset becomes unsafe and must be replaced by law.\nThe cost of a new asset is \\(c\\). What replacement policy maximizes profits?\nCalibration: profit \\(p(a)=50-2.5a-2.5a^2\\). Maximum asset age: 5 years. Asset replacement cost: 75, annual discount factor \\(\\delta=0.9\\).\nDefine kind of problem, the state space, the actions, the reward function, and the Bellman updating equation\nSolve the problem using Value Function Iteration\nSolve the problem using Policy Iteration. Compare with VFI.",
    "crumbs": [
      "Tutorials",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "tutorials/mccall.html",
    "href": "tutorials/mccall.html",
    "title": "McCall Model",
    "section": "",
    "text": "Job-Search Model\n\nWhen unemployed in date, a job-seeker\n\nconsumes unemployment benefit \\(c_t = \\underline{c}\\)\nreceives in every date \\(t\\) a job offer \\(w_t\\)\n\n\\(w_t\\) is i.i.d.,\ntakes values \\(w_1, w_2, w_3\\) with probabilities \\(p_1, p_2, p_3\\)\n\nif job-seeker accepts, becomes employed at rate \\(w_t\\) in the next period\nelse he stays unemployed\n\nWhen employed at rate \\(w\\)\n\nworker consumes salary \\(c_t = w\\)\nwith small probability \\(\\lambda&gt;0\\) looses his job:\n\nstarts next period unemployed\n\notherwise stays employed at same rate\n\nObjective: \\(\\max E_0 \\left\\{ \\sum \\beta^t \\log(c_t) \\right\\}\\)\n\nWhat are the states, the controls, the reward of this problem ? Write down the Bellman equation.\nDefine a named tuple for the model.\n\n1/3\n\n0.3333333333333333\n\n\n\nm = (;\n    β=0.96,\n    λ=0.01,\n    cbar=0.8,\n    wvec=[0.6, 1.0, 1.4],\n    pvec=ones(3)/3\n\n)\n\n(β = 0.96, λ = 0.01, cbar = 0.8, wvec = [0.6, 1.0, 1.4], pvec = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333])\n\n\nDefine a function value_update(V_U::Vector{Float64}, V_E::Vector{Float64}, x::Vector{Bool}, p::Parameters)::Tuple{Vector, Vector}, which takes in value functions tomorrow and a policy vector and return updated values for today.\n\nfunction value_update(V_U, V_E, x, p)\n\n    (;β,λ,cbar,wvec,pvec) = p\n\n    n_V_U = zeros(3)\n    n_V_E = zeros(3)\n\n    # enumerate all unemployed states\n    for n=1:3\n        # compute continuation value\n        if x[n] # if offer is accepted\n            cont = V_E[n] \n        else\n            # cont = V_U' * pvec\n            cont = sum(V_U[m]*pvec[m] for m=1:3)\n            # cont = sum(zip(V_U, pvec))\n        end\n\n        n_V_U[n] = log(cbar) + β*cont\n    end\n\n    # enumerate all employed states\n    for n=1:3\n\n        # receive wage\n        w = wvec[n]\n\n        # compute continuation value\n\n        cont_U = sum(V_U[m]*pvec[m] for m=1:3) # as before\n        cont_E = V_E[n]\n\n        n_V_E[n] = log(w) + β*(λ*cont_U + (1-λ)*cont_E)\n    end\n\n\n    return n_V_U, n_V_E\n\nend\n\nvalue_update (generic function with 1 method)\n\n\n\nV_U_0 = [0.3,2.4, 2.0]\nV_E_0 = [0.3, - 476, 2.0]\nx_0 = [true, false, true]\nvalue_update(V_U_0, V_E_0, x_0, m)\n\n([0.06485644868579027, 1.28085644868579, 1.6968564486857902], [-0.21066562376599074, -452.37536, 2.2523122366212127])\n\n\nDefine a function policy_eval(x::Vector{Bool}, p::Parameter)::Tuple{Vector, Vector} which takes in a policy vector and returns the value(s) of following this policies forever. You can add relevant arguments to the function.\n\n@time distance( (V_E_0, V_U_0), (V_E_0, V_U_0) )\n\n  0.000006 seconds (3 allocations: 80 bytes)\n\n\n0.0\n\n\n\ndistance(a::Tuple{Vector, Vector}, b::Tuple{Vector, Vector})  = max(\n    maximum(abs, ((e-f) for (e,f) in  zip(a[1],b[1]))  ),\n    maximum(abs, ((e-f) for (e,f) in  zip(a[2],b[2]))  ),\n)\n\ndistance (generic function with 1 method)\n\n\n\ndistance( 3,2)\n\nUndefVarError: UndefVarError: `distance` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nUndefVarError: `distance` not defined in `Main`\n\nSuggestion: check for spelling errors or missing imports.\n\n\n\nStacktrace:\n\n [1] top-level scope\n\n   @ ~/Teaching/ensae/mie37/tutorials/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X31sZmlsZQ==.jl:1\n\n\n\ndistance(a::Tuple{Vector, Vector}, b::Tuple{Vector, Vector})  = max(\n    maximum(abs.(a[1]-b[1])),\n    maximum(abs.(a[2]-b[2])),\n)\n\ndistance (generic function with 1 method)\n\n\n\nfun(a, p=.04) = a^2+p\n\nmethods(fun)\n\n# 2 methods for generic function fun from \u001b[35mMain\u001b[39m: fun(a, p) in Main at /home/pablo/Teaching/ensae/mie37/tutorials/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X36sZmlsZQ==.jl:1  fun(a) in Main at /home/pablo/Teaching/ensae/mie37/tutorials/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_X36sZmlsZQ==.jl:1 \n\n\n\nfunction policy_eval(x, p; T=1000, τ_η=1e-8, verbose=true)\n\n    V_U_0 = zeros(3)\n    V_E_0 = zeros(3)\n    # V_U = zeros(3)\n    # V_E = zeros(3)\n\n    local V_U, V_E\n\n    for t=1:T\n\n        V_U, V_E = value_update(V_U_0, V_E_0, x, p)\n        \n        η = distance( (V_U_0, V_E_0), (V_U, V_E))\n\n        V_U_0, V_E_0 = V_U, V_E\n\n        if η&lt;τ_η\n            break\n        end\n\n        if verbose\n            @show (t, η)\n        end\n\n        # println(\"Iteration: $n ; η = $η\")\n\n    end\n\n    return (; V_U, V_E)\n    \nend\n\npolicy_eval (generic function with 1 method)\n\n\n\npolicy_eval([false, false, false], m; T=200, verbose=false)\n\n(V_U = [-5.577001073670461, -5.577001073670461, -5.577001073670461], V_E = [-11.376821691845214, -1.0783107010132913, 5.705145072812092])\n\n\n\npolicy_eval([true, true, true], m;)\n\n(t, η) = (1, 0.5108256237659907)\n(t, η) = (2, 0.490392598815351)\n(t, η) = (3, 0.46812561688302146)\n(t, η) = (4, 0.4454207753467201)\n(t, η) = (5, 0.42383554279395796)\n(t, η) = (6, 0.4033004977021406)\n(t, η) = (7, 0.38376450422539854)\n(t, η) = (8, 0.36517878756433)\n(t, η) = (9, 0.34749696233982963)\n(t, η) = (10, 0.3306749139409164)\n(t, η) = (11, 0.31467068710526247)\n(t, η) = (12, 0.2994443799648252)\n(t, η) = (13, 0.28495804330095265)\n(t, η) = (14, 0.2711755847523154)\n(t, η) = (15, 0.25806267773172475)\n(t, η) = (16, 0.24558667482003127)\n(t, η) = (17, 0.23371652541660648)\n(t, η) = (18, 0.22242269743688414)\n(t, η) = (19, 0.21167710285771957)\n(t, η) = (20, 0.20145302692113276)\n(t, η) = (21, 0.1917250608163963)\n(t, η) = (22, 0.18246903766922973)\n(t, η) = (23, 0.17366197167539088)\n(t, η) = (24, 0.16528200022386397)\n(t, η) = (25, 0.15730832886259094)\n(t, η) = (26, 0.14972117896684178)\n(t, η) = (27, 0.14250173797729015)\n(t, η) = (28, 0.13563211208133197)\n(t, η) = (29, 0.1290952812175039)\n(t, η) = (30, 0.12287505628870754)\n(t, η) = (31, 0.11695603847559344)\n(t, η) = (32, 0.11132358054685731)\n(t, η) = (33, 0.10596375006820224)\n(t, η) = (34, 0.10086329441662656)\n(t, η) = (35, 0.09600960751129861)\n(t, η) = (36, 0.09139069817656775)\n(t, η) = (37, 0.08699516005692587)\n(t, η) = (38, 0.08281214300761874)\n(t, η) = (39, 0.07883132588838038)\n(t, η) = (40, 0.075042890691293)\n(t, η) = (41, 0.07143749793730336)\n(t, η) = (42, 0.06800626327894577)\n(t, η) = (43, 0.06474073525006219)\n(t, η) = (44, 0.061632874106226865)\n(t, η) = (45, 0.0586750317021405)\n(t, η) = (46, 0.0558599323552329)\n(t, η) = (47, 0.053180654646908465)\n(t, η) = (48, 0.05063061411546599)\n(t, η) = (49, 0.04820354679681316)\n(t, η) = (50, 0.04589349357151207)\n(t, η) = (51, 0.04369478527834758)\n(t, η) = (52, 0.04160202855700845)\n(t, η) = (53, 0.03961009238390645)\n(t, η) = (54, 0.03771409526725833)\n(t, η) = (55, 0.03590939306897312)\n(t, η) = (56, 0.03419156742264562)\n(t, η) = (57, 0.032556414718378335)\n(t, η) = (58, 0.030999935626642383)\n(t, η) = (59, 0.02951832513473107)\n(t, η) = (60, 0.028107963070610253)\n(t, η) = (61, 0.0267654050903694)\n(t, η) = (62, 0.02548737410641877)\n(t, η) = (63, 0.02427075213493879)\n(t, η) = (64, 0.023112572541872822)\n(t, η) = (65, 0.022010012668108203)\n(t, η) = (66, 0.02096038681511203)\n(t, η) = (67, 0.019961139573410946)\n(t, η) = (68, 0.019009839477124757)\n(t, η) = (69, 0.01810417296855249)\n(t, η) = (70, 0.017241938657623024)\n(t, η) = (71, 0.01642104186178628)\n(t, η) = (72, 0.015639489412556884)\n(t, η) = (73, 0.01489538471572871)\n(t, η) = (74, 0.014186923052740497)\n(t, η) = (75, 0.013512387111479285)\n(t, η) = (76, 0.012870142735216916)\n(t, η) = (77, 0.012258634879042773)\n(t, η) = (78, 0.01167638376358937)\n(t, η) = (79, 0.011121981216486887)\n(t, η) = (80, 0.010594087192210111)\n(t, η) = (81, 0.010091426461784181)\n(t, η) = (82, 0.009612785463808393)\n(t, η) = (83, 0.009157009309152642)\n(t, η) = (84, 0.00872299893159223)\n(t, η) = (85, 0.008309708377396419)\n(t, η) = (86, 0.007916142226971346)\n(t, η) = (87, 0.007541353142205054)\n(t, η) = (88, 0.007184439533261866)\n(t, η) = (89, 0.0068445433390351695)\n(t, η) = (90, 0.006520847915787442)\n(t, η) = (91, 0.0062125760284708065)\n(t, η) = (92, 0.005918987939995901)\n(t, η) = (93, 0.005639379593404215)\n(t, η) = (94, 0.005373080882598913)\n(t, η) = (95, 0.0051194540071648476)\n(t, η) = (96, 0.004877891907302256)\n(t, η) = (97, 0.004647816774834723)\n(t, η) = (98, 0.004428678636692496)\n(t, η) = (99, 0.004219954007247395)\n(t, η) = (100, 0.004021144606181082)\n(t, η) = (101, 0.0038317761387069993)\n(t, η) = (102, 0.0036513971350160546)\n(t, η) = (103, 0.0034795778461962357)\n(t, η) = (104, 0.0033159091937378093)\n(t, η) = (105, 0.0031600017700981198)\n(t, η) = (106, 0.003011484887771587)\n(t, η) = (107, 0.002870005674587617)\n(t, η) = (108, 0.00273522821289518)\n(t, η) = (109, 0.0026068327205059916)\n(t, η) = (110, 0.0024845147714600557)\n(t, η) = (111, 0.0023679845545352407)\n(t, η) = (112, 0.002256966167735186)\n(t, η) = (113, 0.0021511969470395798)\n(t, η) = (114, 0.002050426827644003)\n(t, η) = (115, 0.0019544177361972004)\n(t, η) = (116, 0.001862943012525875)\n(t, η) = (117, 0.001775786859298023)\n(t, η) = (118, 0.0016927438184666244)\n(t, η) = (119, 0.0016136182729695747)\n(t, η) = (120, 0.0015382239726058344)\n(t, η) = (121, 0.0014663835829011873)\n(t, η) = (122, 0.0013979282557592398)\n(t, η) = (123, 0.0013326972208957955)\n(t, η) = (124, 0.001270537397097371)\n(t, η) = (125, 0.0012113030222238308)\n(t, η) = (126, 0.001154855301145119)\n(t, η) = (127, 0.0011010620706777274)\n(t, η) = (128, 0.0010497974807428534)\n(t, η) = (129, 0.0010009416909184665)\n(t, η) = (130, 0.0009543805816640827)\n(t, η) = (131, 0.0009100054794757284)\n(t, η) = (132, 0.0008677128953742397)\n(t, η) = (133, 0.0008274042759381928)\n(t, η) = (134, 0.0007889857664196143)\n(t, η) = (135, 0.0007523679852674547)\n(t, η) = (136, 0.0007174658095472353)\n(t, η) = (137, 0.0006841981706884326)\n(t, η) = (138, 0.0006524878601084083)\n(t, η) = (139, 0.0006222613441799751)\n(t, η) = (140, 0.000593448588169565)\n(t, η) = (141, 0.0005659828885846707)\n(t, η) = (142, 0.000539800713688976)\n(t, η) = (143, 0.0005148415516131877)\n(t, η) = (144, 0.0004910477658413015)\n(t, η) = (145, 0.00046836445763887014)\n(t, η) = (146, 0.0004467393350786608)\n(t, η) = (147, 0.0004261225884185649)\n(t, η) = (148, 0.0004064667714231973)\n(t, η) = (149, 0.0003877266884053654)\n(t, η) = (150, 0.00036985928675647983)\n(t, η) = (151, 0.00035282355455024117)\n(t, η) = (152, 0.00033658042311657255)\n(t, η) = (153, 0.00032109267433355626)\n(t, η) = (154, 0.00030632485227855)\n(t, η) = (155, 0.00029224317921361376)\n(t, η) = (156, 0.0002788154755535288)\n(t, η) = (157, 0.0002660110836671947)\n(t, η) = (158, 0.00025380079539161216)\n(t, η) = (159, 0.0002421567829564708)\n(t, η) = (160, 0.00023105253325894637)\n(t, η) = (161, 0.00022046278527554364)\n(t, η) = (162, 0.00021036347048664084)\n(t, η) = (163, 0.00020073165613609945)\n(t, η) = (164, 0.00019154549122291087)\n(t, η) = (165, 0.00018278415508632406)\n(t, η) = (166, 0.0001744278084103712)\n(t, η) = (167, 0.00016645754663002776)\n(t, η) = (168, 0.00015885535553294972)\n(t, η) = (169, 0.00015160406899283885)\n(t, η) = (170, 0.0001446873286923278)\n(t, η) = (171, 0.00013808954585670108)\n(t, η) = (172, 0.0001317958647000239)\n(t, η) = (173, 0.00012579212771868242)\n(t, η) = (174, 0.00012006484256943395)\n(t, η) = (175, 0.00011460115059591658)\n(t, η) = (176, 0.00010938879676913871)\n(t, η) = (177, 0.00010441610116274092)\n(t, η) = (178, 9.967193171434019e-5)\n(t, η) = (179, 9.514567830137821e-5)\n(t, η) = (180, 9.082722808173571e-5)\n(t, η) = (181, 8.670694197832063e-5)\n(t, η) = (182, 8.277563228276108e-5)\n(t, η) = (183, 7.902454137109771e-5)\n(t, η) = (184, 7.54453213431816e-5)\n(t, η) = (185, 7.203001474920256e-5)\n(t, η) = (186, 6.877103609781443e-5)\n(t, η) = (187, 6.566115439099462e-5)\n(t, η) = (188, 6.269347634813016e-5)\n(t, η) = (189, 5.9861430525387505e-5)\n(t, η) = (190, 5.7158752152730585e-5)\n(t, η) = (191, 5.457946868503427e-5)\n(t, η) = (192, 5.2117886049529716e-5)\n(t, η) = (193, 4.976857555405445e-5)\n(t, η) = (194, 4.752636139571109e-5)\n(t, η) = (195, 4.538630876993466e-5)\n(t, η) = (196, 4.33437125550995e-5)\n(t, η) = (197, 4.139408653003329e-5)\n(t, η) = (198, 3.953315306759464e-5)\n(t, η) = (199, 3.7756833375368615e-5)\n(t, η) = (200, 3.606123815202977e-5)\n(t, η) = (201, 3.444265870555796e-5)\n(t, η) = (202, 3.289755848001619e-5)\n(t, η) = (203, 3.1422564997996005e-5)\n(t, η) = (204, 3.0014462176097823e-5)\n(t, η) = (205, 2.8670183002788008e-5)\n(t, η) = (206, 2.738680254310566e-5)\n(t, η) = (207, 2.6161531334167876e-5)\n(t, η) = (208, 2.4991709011601415e-5)\n(t, η) = (209, 2.387479828769301e-5)\n(t, η) = (210, 2.2808379210204066e-5)\n(t, η) = (211, 2.179014368408616e-5)\n(t, η) = (212, 2.081789024543923e-5)\n(t, η) = (213, 1.9889519059290706e-5)\n(t, η) = (214, 1.90030272406716e-5)\n(t, η) = (215, 1.8156504285826713e-5)\n(t, η) = (216, 1.73481277769838e-5)\n(t, η) = (217, 1.6576159303838267e-5)\n(t, η) = (218, 1.5838940516488265e-5)\n(t, η) = (219, 1.5134889437717902e-5)\n(t, η) = (220, 1.4462496871203712e-5)\n(t, η) = (221, 1.3820323058411077e-5)\n(t, η) = (222, 1.3206994427861218e-5)\n(t, η) = (223, 1.2621200525586573e-5)\n(t, η) = (224, 1.2061691073483871e-5)\n(t, η) = (225, 1.152727320530289e-5)\n(t, η) = (226, 1.1016808791453059e-5)\n(t, η) = (227, 1.0529211870391464e-5)\n(t, η) = (228, 1.006344628962097e-5)\n(t, η) = (229, 9.618523350241048e-6)\n(t, η) = (230, 9.193499622028867e-6)\n(t, η) = (231, 8.787474875759926e-6)\n(t, η) = (232, 8.399590040397698e-6)\n(t, η) = (233, 8.029025337918938e-6)\n(t, η) = (234, 7.674998443008008e-6)\n(t, η) = (235, 7.336762774201588e-6)\n(t, η) = (236, 7.013605824113256e-6)\n(t, η) = (237, 6.704847599792174e-6)\n(t, η) = (238, 6.4098391163724955e-6)\n(t, η) = (239, 6.127960979540603e-6)\n(t, η) = (240, 5.858621999976776e-6)\n(t, η) = (241, 5.60125791793098e-6)\n(t, η) = (242, 5.355330152667648e-6)\n(t, η) = (243, 5.120324619412031e-6)\n(t, η) = (244, 4.895750606692673e-6)\n(t, η) = (245, 4.681139703421877e-6)\n(t, η) = (246, 4.476044765056031e-6)\n(t, η) = (247, 4.280038950810194e-6)\n(t, η) = (248, 4.092714789294405e-6)\n(t, η) = (249, 3.9136832725716886e-6)\n(t, η) = (250, 3.7425730354812003e-6)\n(t, η) = (251, 3.5790295207505096e-6)\n(t, η) = (252, 3.422714250689296e-6)\n(t, η) = (253, 3.2733040278287717e-6)\n(t, η) = (254, 3.1304902954332192e-6)\n(t, η) = (255, 2.9939784411681103e-6)\n(t, η) = (256, 2.863487157611644e-6)\n(t, η) = (257, 2.738747834740707e-6)\n(t, η) = (258, 2.6195040021548266e-6)\n(t, η) = (259, 2.5055107357729867e-6)\n(t, η) = (260, 2.3965341746645663e-6)\n(t, η) = (261, 2.2923509810368614e-6)\n(t, η) = (262, 2.192747871276879e-6)\n(t, η) = (263, 2.097521178967554e-6)\n(t, η) = (264, 2.006476389482259e-6)\n(t, η) = (265, 1.9194277278700156e-6)\n(t, η) = (266, 1.8361977751624181e-6)\n(t, η) = (267, 1.75661708823327e-6)\n(t, η) = (268, 1.6805238125527922e-6)\n(t, η) = (269, 1.607763362443393e-6)\n(t, η) = (270, 1.538188090677295e-6)\n(t, η) = (271, 1.471656961626877e-6)\n(t, η) = (272, 1.4080352563894394e-6)\n(t, η) = (273, 1.3471942885701083e-6)\n(t, η) = (274, 1.2890111307228835e-6)\n(t, η) = (275, 1.2333683478971125e-6)\n(t, η) = (276, 1.1801537596056733e-6)\n(t, η) = (277, 1.1292602017931586e-6)\n(t, η) = (278, 1.0805852745932043e-6)\n(t, η) = (279, 1.0340311717982331e-6)\n(t, η) = (280, 9.895044357222105e-7)\n(t, η) = (281, 9.469157760122471e-7)\n(t, η) = (282, 9.061798849074876e-7)\n(t, η) = (283, 8.672152453925719e-7)\n(t, η) = (284, 8.299439819836607e-7)\n(t, η) = (285, 7.942916688818968e-7)\n(t, η) = (286, 7.601871878648581e-7)\n(t, η) = (287, 7.27562596836151e-7)\n(t, η) = (288, 6.963529557424408e-7)\n(t, η) = (289, 6.66496219992041e-7)\n(t, η) = (290, 6.37933077030084e-7)\n(t, η) = (291, 6.106068681788202e-7)\n(t, η) = (292, 5.844634252127889e-7)\n(t, η) = (293, 5.594509921991175e-7)\n(t, η) = (294, 5.355200975998287e-7)\n(t, η) = (295, 5.126234619012848e-7)\n(t, η) = (296, 4.90715891032778e-7)\n(t, η) = (297, 4.6975419465411505e-7)\n(t, η) = (298, 4.496970831269209e-7)\n(t, η) = (299, 4.3050510001307885e-7)\n(t, η) = (300, 4.1214051904603366e-7)\n(t, η) = (301, 3.9456728018194553e-7)\n(t, η) = (302, 3.777509185454164e-7)\n(t, η) = (303, 3.616584791643618e-7)\n(t, η) = (304, 3.4625846367930535e-7)\n(t, η) = (305, 3.31520766394533e-7)\n(t, η) = (306, 3.1741658190753697e-7)\n(t, η) = (307, 3.0391839800358866e-7)\n(t, η) = (308, 2.909999032851829e-7)\n(t, η) = (309, 2.7863591967047796e-7)\n(t, η) = (310, 2.668024166041505e-7)\n(t, η) = (311, 2.554763689488482e-7)\n(t, η) = (312, 2.4463581382860866e-7)\n(t, η) = (313, 2.3425969786217138e-7)\n(t, η) = (314, 2.2432792334825535e-7)\n(t, η) = (315, 2.1482127010585828e-7)\n(t, η) = (316, 2.05721345736265e-7)\n(t, η) = (317, 1.9701056785947912e-7)\n(t, η) = (318, 1.886721214816589e-7)\n(t, η) = (319, 1.8068993767883512e-7)\n(t, η) = (320, 1.730486260953512e-7)\n(t, η) = (321, 1.6573348915471797e-7)\n(t, η) = (322, 1.5873046166348104e-7)\n(t, η) = (323, 1.520260859422251e-7)\n(t, η) = (324, 1.4560750827286029e-7)\n(t, η) = (325, 1.394624078443485e-7)\n(t, η) = (326, 1.335790251744129e-7)\n(t, η) = (327, 1.2794610171340537e-7)\n(t, η) = (328, 1.225528656334518e-7)\n(t, η) = (329, 1.1738902117031103e-7)\n(t, η) = (330, 1.1244470954352437e-7)\n(t, η) = (331, 1.0771051250912933e-7)\n(t, η) = (332, 1.0317740262166808e-7)\n(t, η) = (333, 9.88367681031832e-8)\n(t, η) = (334, 9.468034534165781e-8)\n(t, η) = (335, 9.070025086543865e-8)\n(t, η) = (336, 8.688892449981722e-8)\n(t, η) = (337, 8.323914002517085e-8)\n(t, η) = (338, 7.974399451882164e-8)\n(t, η) = (339, 7.639686572247228e-8)\n(t, η) = (340, 7.319142625306085e-8)\n(t, η) = (341, 7.012162583919235e-8)\n(t, η) = (342, 6.718166645214296e-8)\n(t, η) = (343, 6.436600230586009e-8)\n(t, η) = (344, 6.166933630424865e-8)\n(t, η) = (345, 5.9086595172175294e-8)\n(t, η) = (346, 5.661290458647272e-8)\n(t, η) = (347, 5.424363536121746e-8)\n(t, η) = (348, 5.19743288407426e-8)\n(t, η) = (349, 4.980073953220199e-8)\n(t, η) = (350, 4.7718781814865e-8)\n(t, η) = (351, 4.572456546725334e-8)\n(t, η) = (352, 4.3814349481863246e-8)\n(t, η) = (353, 4.198458114501591e-8)\n(t, η) = (354, 4.023182853529761e-8)\n(t, η) = (355, 3.855282315612385e-8)\n(t, η) = (356, 3.694443861945729e-8)\n(t, η) = (357, 3.540367998766669e-8)\n(t, η) = (358, 3.3927669562672236e-8)\n(t, η) = (359, 3.2513668202227564e-8)\n(t, η) = (360, 3.115905400363772e-8)\n(t, η) = (361, 2.986130454019076e-8)\n(t, η) = (362, 2.861801107201245e-8)\n(t, η) = (363, 2.7426874993352612e-8)\n(t, η) = (364, 2.628568651630303e-8)\n(t, η) = (365, 2.519233177622482e-8)\n(t, η) = (366, 2.414479283174842e-8)\n(t, η) = (367, 2.3141129901205204e-8)\n(t, η) = (368, 2.217949202076852e-8)\n(t, η) = (369, 2.125810283359897e-8)\n(t, η) = (370, 2.0375271247985438e-8)\n(t, η) = (371, 1.9529359462922002e-8)\n(t, η) = (372, 1.8718825600672062e-8)\n(t, η) = (373, 1.7942159757922127e-8)\n(t, η) = (374, 1.7197955060055392e-8)\n(t, η) = (375, 1.6484822396023446e-8)\n(t, η) = (376, 1.5801472130760885e-8)\n(t, η) = (377, 1.5146643050911734e-8)\n(t, η) = (378, 1.4519137891966238e-8)\n(t, η) = (379, 1.3917802021978787e-8)\n(t, η) = (380, 1.3341544757849988e-8)\n(t, η) = (381, 1.278930383818988e-8)\n(t, η) = (382, 1.2260077397741043e-8)\n(t, η) = (383, 1.1752895545669162e-8)\n(t, η) = (384, 1.1266831023704071e-8)\n(t, η) = (385, 1.080099920613975e-8)\n(t, η) = (386, 1.0354554547120642e-8)\n\n\n(V_U = [-10.417717805631884, -0.5307702781758938, 5.9815955726093115], V_E = [-10.619348191494039, -0.320444515546618, 6.463269913351949])\n\n\n\npolicy_eval(x_0, m;)\n\n(t, η) = (1, 0.5108256237659907)\n(t, η) = (2, 0.490392598815351)\n(t, η) = (3, 0.46812561688302146)\n(t, η) = (4, 0.4460788524567716)\n(t, η) = (5, 0.4248297869138624)\n(t, η) = (6, 0.40452234933286846)\n(t, η) = (7, 0.3851676119158367)\n(t, η) = (8, 0.3667370420134395)\n(t, η) = (9, 0.3491913678231824)\n(t, η) = (10, 0.332489462473883)\n(t, η) = (11, 0.31659102952791507)\n(t, η) = (12, 0.30145736797222167)\n(t, η) = (13, 0.2870515444381647)\n(t, η) = (14, 0.27333838461626314)\n(t, η) = (15, 0.2602844115834575)\n(t, η) = (16, 0.24785777053778268)\n(t, η) = (17, 0.2360281520580898)\n(t, η) = (18, 0.22476671751561916)\n(t, η) = (19, 0.2140460276352858)\n(t, η) = (20, 0.20383997439472346)\n(t, η) = (21, 0.19412371620383695)\n(t, η) = (22, 0.18487361623708498)\n(t, η) = (23, 0.17606718377422315)\n(t, η) = (24, 0.16768301840536726)\n(t, η) = (25, 0.1597007569609339)\n(t, η) = (26, 0.152101023033401)\n(t, η) = (27, 0.14486537896396268)\n(t, η) = (28, 0.1379762801734481)\n(t, η) = (29, 0.13141703172269814)\n(t, η) = (30, 0.1251717469932716)\n(t, η) = (31, 0.11922530838466017)\n(t, η) = (32, 0.11356332992935236)\n(t, η) = (33, 0.10817212173179769)\n(t, η) = (34, 0.10303865614217145)\n(t, η) = (35, 0.09815053557985465)\n(t, η) = (36, 0.09349596192613419)\n(t, η) = (37, 0.08906370740919911)\n(t, η) = (38, 0.08484308690852416)\n(t, η) = (39, 0.08082393160920631)\n(t, η) = (40, 0.07699656394028054)\n(t, η) = (41, 0.07335177373417423)\n(t, η) = (42, 0.06988079554768589)\n(t, η) = (43, 0.06657528708760907)\n(t, η) = (44, 0.06342730868719926)\n(t, η) = (45, 0.0604293037818735)\n(t, η) = (46, 0.05757408033563394)\n(t, η) = (47, 0.05485479317147224)\n(t, η) = (48, 0.052264927161839836)\n(t, η) = (49, 0.04979828123701324)\n(t, η) = (50, 0.047448953171560504)\n(t, η) = (51, 0.04521132511080239)\n(t, η) = (52, 0.043080049801194065)\n(t, η) = (53, 0.041050037490308)\n(t, η) = (54, 0.03911644346366927)\n(t, η) = (55, 0.037274656187435085)\n(t, η) = (56, 0.03552028602732449)\n(t, η) = (57, 0.033849154515682045)\n(t, η) = (58, 0.03225728414000173)\n(t, η) = (59, 0.03074088862742741)\n(t, η) = (60, 0.0292963637010466)\n(t, η) = (61, 0.027920278285026967)\n(t, η) = (62, 0.026609366136703727)\n(t, η) = (63, 0.02536051788475291)\n(t, η) = (64, 0.024170773453757732)\n(t, η) = (65, 0.02303731485630678)\n(t, η) = (66, 0.02195745933464366)\n(t, η) = (67, 0.020928652835053185)\n(t, η) = (68, 0.01994846379849946)\n(t, η) = (69, 0.019014577252406184)\n(t, η) = (70, 0.018124789188657786)\n(t, η) = (71, 0.01727700121415765)\n(t, η) = (72, 0.01646921546041824)\n(t, η) = (73, 0.015699529739805484)\n(t, η) = (74, 0.01496613293629423)\n(t, η) = (75, 0.014267300619362544)\n(t, η) = (76, 0.013601390870292107)\n(t, η) = (77, 0.01296684031030182)\n(t, η) = (78, 0.012362160321004012)\n(t, η) = (79, 0.011785933447569619)\n(t, η) = (80, 0.01123680997591947)\n(t, η) = (81, 0.010713504675369023)\n(t, η) = (82, 0.010214793698754221)\n(t, η) = (83, 0.009739511632368192)\n(t, η) = (84, 0.009286548688436369)\n(t, η) = (85, 0.008854848033198692)\n(t, η) = (86, 0.008443403244072556)\n(t, η) = (87, 0.008051255889554909)\n(t, η) = (88, 0.007677493225962451)\n(t, η) = (89, 0.007321246005346893)\n(t, η) = (90, 0.006981686389138986)\n(t, η) = (91, 0.006658025962469338)\n(t, η) = (92, 0.006349513844227772)\n(t, η) = (93, 0.006055434888274647)\n(t, η) = (94, 0.005775107971306426)\n(t, η) = (95, 0.005507884363286308)\n(t, η) = (96, 0.005253146176322332)\n(t, η) = (97, 0.00501030488833365)\n(t, η) = (98, 0.004778799937739109)\n(t, η) = (99, 0.004558097385817916)\n(t, η) = (100, 0.0043476886434739015)\n(t, η) = (101, 0.0041470892592272435)\n(t, η) = (102, 0.003955837765538206)\n(t, η) = (103, 0.003773494580602943)\n(t, η) = (104, 0.003599640962899997)\n(t, η) = (105, 0.0034338780161036198)\n(t, η) = (106, 0.0032758257416638514)\n(t, η) = (107, 0.0031251221370354187)\n(t, η) = (108, 0.0029814223371040782)\n(t, η) = (109, 0.0028443977969345724)\n(t, η) = (110, 0.0027137355136375163)\n(t, η) = (111, 0.0025891372857032025)\n(t, η) = (112, 0.002470319007731092)\n(t, η) = (113, 0.0023570099990841697)\n(t, η) = (114, 0.0022489523647095666)\n(t, η) = (115, 0.002145900386533839)\n(t, η) = (116, 0.002047619944107737)\n(t, η) = (117, 0.0019538879629585892)\n(t, η) = (118, 0.001864491889353559)\n(t, η) = (119, 0.0017792291902196666)\n(t, η) = (120, 0.0016979068770268668)\n(t, η) = (121, 0.0016203410523765172)\n(t, η) = (122, 0.0015463564783715356)\n(t, η) = (123, 0.0014757861655532167)\n(t, η) = (124, 0.0014084709815058716)\n(t, η) = (125, 0.0013442592781984786)\n(t, η) = (126, 0.0012830065370792454)\n(t, η) = (127, 0.0012245750311592474)\n(t, η) = (128, 0.001168833503200517)\n(t, η) = (129, 0.0011156568592802785)\n(t, η) = (130, 0.0010649258769888093)\n(t, η) = (131, 0.0010165269275006494)\n(t, η) = (132, 0.0009703517109436177)\n(t, η) = (133, 0.0009262970043728558)\n(t, η) = (134, 0.0008842644217104123)\n(t, η) = (135, 0.000844160185199172)\n(t, η) = (136, 0.0008058949076676925)\n(t, η) = (137, 0.0007693833851938336)\n(t, η) = (138, 0.0007345443996413792)\n(t, η) = (139, 0.000701300530554505)\n(t, η) = (140, 0.0006695779760477194)\n(t, η) = (141, 0.0006393063821761302)\n(t, η) = (142, 0.0006104186804058997)\n(t, η) = (143, 0.000582850932854484)\n(t, η) = (144, 0.0005565421848245933)\n(t, η) = (145, 0.000531434324361868)\n(t, η) = (146, 0.0005074719485094192)\n(t, η) = (147, 0.000484602235825804)\n(t, η) = (148, 0.0004627748250598529)\n(t, η) = (149, 0.0004419416994565495)\n(t, η) = (150, 0.00042205707665843306)\n(t, η) = (151, 0.00040307730373001505)\n(t, η) = (152, 0.00038496075721283773)\n(t, η) = (153, 0.00036766774789853685)\n(t, η) = (154, 0.0003511604300747706)\n(t, η) = (155, 0.0003354027151125649)\n(t, η) = (156, 0.00032036018912151576)\n(t, η) = (157, 0.00030600003447034396)\n(t, η) = (158, 0.00029229095506622116)\n(t, η) = (159, 0.0002792031050979915)\n(t, η) = (160, 0.0002667080212397366)\n(t, η) = (161, 0.00025477855793454296)\n(t, η) = (162, 0.0002433888258259742)\n(t, η) = (163, 0.00023251413305303004)\n(t, η) = (164, 0.00022213092932688028)\n(t, η) = (165, 0.0002122167526081853)\n(t, η) = (166, 0.0002027501783672392)\n(t, η) = (167, 0.0001937107711356134)\n(t, η) = (168, 0.00018507903843811846)\n(t, η) = (169, 0.00017683638682086666)\n(t, η) = (170, 0.0001689650799825415)\n(t, η) = (171, 0.00016144819883479045)\n(t, η) = (172, 0.00015426960352726837)\n(t, η) = (173, 0.00014741389713179842)\n(t, η) = (174, 0.000140866391134864)\n(t, η) = (175, 0.00013461307250040022)\n(t, η) = (176, 0.00012864057229933223)\n(t, η) = (177, 0.00012293613577796236)\n(t, η) = (178, 0.0001174875938758646)\n(t, η) = (179, 0.00011228333603341412)\n(t, η) = (180, 0.00010731228431026807)\n(t, η) = (181, 0.00010256386867624201)\n(t, η) = (182, 9.802800351366159e-5)\n(t, η) = (183, 9.369506515710668e-5)\n(t, η) = (184, 8.95558705167332e-5)\n(t, η) = (185, 8.560165670701281e-5)\n(t, η) = (186, 8.182406160628375e-5)\n(t, η) = (187, 7.821510534000709e-5)\n(t, η) = (188, 7.476717262022703e-5)\n(t, η) = (189, 7.147299589860268e-5)\n(t, η) = (190, 6.832563934366931e-5)\n(t, η) = (191, 6.531848351087888e-5)\n(t, η) = (192, 6.24452107729212e-5)\n(t, η) = (193, 5.969979140019177e-5)\n(t, η) = (194, 5.707647030561702e-5)\n(t, η) = (195, 5.456975439699363e-5)\n(t, η) = (196, 5.217440051197286e-5)\n(t, η) = (197, 4.9885403946348106e-5)\n(t, η) = (198, 4.7697987461958746e-5)\n(t, η) = (199, 4.560759084881738e-5)\n(t, η) = (200, 4.360986097040609e-5)\n(t, η) = (201, 4.170064222819292e-5)\n(t, η) = (202, 3.9875967519975575e-5)\n(t, η) = (203, 3.813204958902361e-5)\n(t, η) = (204, 3.6465272788888115e-5)\n(t, η) = (205, 3.4872185203482786e-5)\n(t, η) = (206, 3.33494911615162e-5)\n(t, η) = (207, 3.18940440919846e-5)\n(t, η) = (208, 3.0502839688750782e-5)\n(t, η) = (209, 2.9173009416183504e-5)\n(t, η) = (210, 2.7901814306119377e-5)\n(t, η) = (211, 2.6686639024831038e-5)\n(t, η) = (212, 2.552498624552868e-5)\n(t, η) = (213, 2.441447126955154e-5)\n(t, η) = (214, 2.33528168571695e-5)\n(t, η) = (215, 2.2337848374576197e-5)\n(t, η) = (216, 2.136748907588526e-5)\n(t, η) = (217, 2.0439755676449067e-5)\n(t, η) = (218, 1.955275409670776e-5)\n(t, η) = (219, 1.8704675380121216e-5)\n(t, η) = (220, 1.7893791856238295e-5)\n(t, η) = (221, 1.711845341390017e-5)\n(t, η) = (222, 1.637708401602822e-5)\n(t, η) = (223, 1.5668178306782465e-5)\n(t, η) = (224, 1.4990298414119252e-5)\n(t, η) = (225, 1.4342070890904779e-5)\n(t, η) = (226, 1.372218380168988e-5)\n(t, η) = (227, 1.3129383930277072e-5)\n(t, η) = (228, 1.2562474111632582e-5)\n(t, η) = (229, 1.2020310716565064e-5)\n(t, η) = (230, 1.1501801211011298e-5)\n(t, η) = (231, 1.1005901864535872e-5)\n(t, η) = (232, 1.0531615522779703e-5)\n(t, η) = (233, 1.0077989532675247e-5)\n(t, η) = (234, 9.644113699636137e-6)\n(t, η) = (235, 9.229118411724357e-6)\n(t, η) = (236, 8.832172785133707e-6)\n(t, η) = (237, 8.45248290914924e-6)\n(t, η) = (238, 8.089290219004397e-6)\n(t, η) = (239, 7.74186986873815e-6)\n(t, η) = (240, 7.409529224844391e-6)\n(t, η) = (241, 7.091606438081044e-6)\n(t, η) = (242, 6.787469022384585e-6)\n(t, η) = (243, 6.496512575893121e-6)\n(t, η) = (244, 6.218159487758612e-6)\n(t, η) = (245, 5.951857755093215e-6)\n(t, η) = (246, 5.697079828337337e-6)\n(t, η) = (247, 5.453321520576537e-6)\n(t, η) = (248, 5.220100945280137e-6)\n(t, η) = (249, 4.996957549963099e-6)\n(t, η) = (250, 4.7834511214261966e-6)\n(t, η) = (251, 4.579160901130308e-6)\n(t, η) = (252, 4.38368471833428e-6)\n(t, η) = (253, 4.196638151654497e-6)\n(t, η) = (254, 4.017653719046166e-6)\n(t, η) = (255, 3.8463801708132905e-6)\n(t, η) = (256, 3.6824816973535235e-6)\n(t, η) = (257, 3.5256373145386988e-6)\n(t, η) = (258, 3.375540146066669e-6)\n(t, η) = (259, 3.231896815947266e-6)\n(t, η) = (260, 3.094426858751831e-6)\n(t, η) = (261, 2.9628621263100285e-6)\n(t, η) = (262, 2.8369462476973695e-6)\n(t, η) = (263, 2.7164341211971532e-6)\n(t, η) = (264, 2.6010913707352756e-6)\n(t, η) = (265, 2.4906939302127284e-6)\n(t, η) = (266, 2.3850275319148295e-6)\n(t, η) = (267, 2.2838873121600045e-6)\n(t, η) = (268, 2.187077356552436e-6)\n(t, η) = (269, 2.094410337605268e-6)\n(t, η) = (270, 2.0057071310475294e-6)\n(t, η) = (271, 1.920796414367487e-6)\n(t, η) = (272, 1.8395143790428392e-6)\n(t, η) = (273, 1.7617043504003504e-6)\n(t, η) = (274, 1.6872165069514722e-6)\n(t, η) = (275, 1.6159075535426837e-6)\n(t, η) = (276, 1.5476404442438252e-6)\n(t, η) = (277, 1.4822841016837174e-6)\n(t, η) = (278, 1.4197131754656311e-6)\n(t, η) = (279, 1.3598077472920522e-6)\n(t, η) = (280, 1.3024531426708563e-6)\n(t, η) = (281, 1.247539643145501e-6)\n(t, η) = (282, 1.1949623335283377e-6)\n(t, η) = (283, 1.1446208247889444e-6)\n(t, η) = (284, 1.0964191154982927e-6)\n(t, η) = (285, 1.0502653502442172e-6)\n(t, η) = (286, 1.0060716668647274e-6)\n(t, η) = (287, 9.637540081541829e-7)\n(t, η) = (288, 9.232319690966051e-7)\n(t, η) = (289, 8.844286156772796e-7)\n(t, η) = (290, 8.472703498796363e-7)\n(t, η) = (291, 8.116867569185615e-7)\n(t, η) = (292, 7.776104773427051e-7)\n(t, η) = (293, 7.449770365042241e-7)\n(t, η) = (294, 7.13724777057223e-7)\n(t, η) = (295, 6.83794688427497e-7)\n(t, η) = (296, 6.551302966784078e-7)\n(t, η) = (297, 6.276775934566103e-7)\n(t, η) = (298, 6.01384876119937e-7)\n(t, η) = (299, 5.76202666024983e-7)\n(t, η) = (300, 5.520836374728333e-7)\n(t, η) = (301, 5.289824898113693e-7)\n(t, η) = (302, 5.06855865722855e-7)\n(t, η) = (303, 4.856622943805178e-7)\n(t, η) = (304, 4.653620564454286e-7)\n(t, η) = (305, 4.4591716985564744e-7)\n(t, η) = (306, 4.272912654812444e-7)\n(t, η) = (307, 4.0944954804444933e-7)\n(t, η) = (308, 3.9235869664366874e-7)\n(t, η) = (309, 3.7598683633177643e-7)\n(t, η) = (310, 3.6030345995641255e-7)\n(t, η) = (311, 3.4527935710571e-7)\n(t, η) = (312, 3.3088656792301663e-7)\n(t, η) = (313, 3.170983369216174e-7)\n(t, η) = (314, 3.0388905614131545e-7)\n(t, η) = (315, 2.912342011995861e-7)\n(t, η) = (316, 2.791103099752945e-7)\n(t, η) = (317, 2.6749490444899493e-7)\n(t, η) = (318, 2.563664907029306e-7)\n(t, η) = (319, 2.4570446655047817e-7)\n(t, η) = (320, 2.3548913574700236e-7)\n(t, η) = (321, 2.2570161206658668e-7)\n(t, η) = (322, 2.1632385127645648e-7)\n(t, η) = (323, 2.0733853389742762e-7)\n(t, η) = (324, 1.987291220473253e-7)\n(t, η) = (325, 1.9047975285957364e-7)\n(t, η) = (326, 1.8257524558862315e-7)\n(t, η) = (327, 1.750010731882412e-7)\n(t, η) = (328, 1.6774331612623428e-7)\n(t, η) = (329, 1.6078865172630685e-7)\n(t, η) = (330, 1.5412432219363836e-7)\n(t, η) = (331, 1.4773811685131477e-7)\n(t, η) = (332, 1.4161832595505075e-7)\n(t, η) = (333, 1.3575376200947176e-7)\n(t, η) = (334, 1.3013368516112678e-7)\n(t, η) = (335, 1.2474783517291144e-7)\n(t, η) = (336, 1.1958637458064914e-7)\n(t, η) = (337, 1.1463987803495002e-7)\n(t, η) = (338, 1.0989932874849728e-7)\n(t, η) = (339, 1.0535609007433777e-7)\n(t, η) = (340, 1.0100188418959988e-7)\n(t, η) = (341, 9.68287849900662e-8)\n(t, η) = (342, 9.282921098474617e-8)\n(t, η) = (343, 8.899588621602561e-8)\n(t, η) = (344, 8.532186157594879e-8)\n(t, η) = (345, 8.180045796279956e-8)\n(t, η) = (346, 7.842529115009711e-8)\n(t, η) = (347, 7.519025047031391e-8)\n(t, η) = (348, 7.208947394587994e-8)\n(t, η) = (349, 6.911734473646902e-8)\n(t, η) = (350, 6.626850179713983e-8)\n(t, η) = (351, 6.353777592948973e-8)\n(t, η) = (352, 6.092025373050092e-8)\n(t, η) = (353, 5.841119943283957e-8)\n(t, η) = (354, 5.600609043199256e-8)\n(t, η) = (355, 5.3700592417271764e-8)\n(t, η) = (356, 5.149055226638666e-8)\n(t, η) = (357, 4.9371987387303307e-8)\n(t, η) = (358, 4.7341089270958037e-8)\n(t, η) = (359, 4.539420572768904e-8)\n(t, η) = (360, 4.35278373345227e-8)\n(t, η) = (361, 4.173863743517359e-8)\n(t, η) = (362, 4.0023387271048705e-8)\n(t, η) = (363, 3.8379010192102214e-8)\n(t, η) = (364, 3.6802571656835426e-8)\n(t, η) = (365, 3.52912294943053e-8)\n(t, η) = (366, 3.384229430025698e-8)\n(t, η) = (367, 3.245316193556391e-8)\n(t, η) = (368, 3.112135615879197e-8)\n(t, η) = (369, 2.9844489546348996e-8)\n(t, η) = (370, 2.8620284808766883e-8)\n(t, η) = (371, 2.7446560579846846e-8)\n(t, η) = (372, 2.6321213653091036e-8)\n(t, η) = (373, 2.5242254508839324e-8)\n(t, η) = (374, 2.4207739812709406e-8)\n(t, η) = (375, 2.32158399171567e-8)\n(t, η) = (376, 2.2264785570769163e-8)\n(t, η) = (377, 2.1352885681835687e-8)\n(t, η) = (378, 2.0478520212918738e-8)\n(t, η) = (379, 1.9640129522713323e-8)\n(t, η) = (380, 1.8836228576901703e-8)\n(t, η) = (381, 1.8065399842726038e-8)\n(t, η) = (382, 1.7326261314565272e-8)\n(t, η) = (383, 1.661750559378561e-8)\n(t, η) = (384, 1.593788212517211e-8)\n(t, η) = (385, 1.5286182986073982e-8)\n(t, η) = (386, 1.4661253544545616e-8)\n(t, η) = (387, 1.4061996012060263e-8)\n(t, η) = (388, 1.3487333916373245e-8)\n(t, η) = (389, 1.293626894494082e-8)\n(t, η) = (390, 1.240782054878764e-8)\n(t, η) = (391, 1.1901057916929858e-8)\n(t, η) = (392, 1.141507510737938e-8)\n(t, η) = (393, 1.0949033679708009e-8)\n(t, η) = (394, 1.0502095193487548e-8)\n(t, η) = (395, 1.0073488709849698e-8)\n\n\n(V_U = [-10.56046812449, -2.5500924348984393, 5.838845271607704], V_E = [-10.768046440045865, -0.46914275344062545, 6.314571682478065])\n\n\nDefine a function bellman_step(V_E::Vector, V_U::Vector, p::Parameters)::Tuple{Vector, Vector, Vector} which returns updated values, together with improved policy rules.\n\nfunction bellman_step(V_U, V_E, p)\n\n    (;β,λ,cbar,wvec,pvec) = p\n\n\n    n_x = zeros(Bool, 3)\n\n    n_V_U = zeros(3)\n    n_V_E = zeros(3)\n\n    # enumerate all unemployed states\n    for n=1:3\n        # compute continuation value\n\n        # if accept\n        cont_accept = V_E[n] \n        \n        # if reject\n        cont_reject = sum(V_U[m]*pvec[m] for m=1:3)\n\n        if cont_accept &gt; cont_reject\n            n_x[n] = true\n            n_V_U[n] = log(cbar) + β*cont_accept\n        else\n            n_x[n] = false\n            n_V_U[n] = log(cbar) + β*cont_reject\n\n        end\n\n    end\n\n    # enumerate all employed states\n    for n=1:3\n\n        # receive wage\n        w = wvec[n]\n\n        # compute continuation value\n\n        cont_U = sum(V_U[m]*pvec[m] for m=1:3) # as before\n        cont_E = V_E[n]\n\n        n_V_E[n] = log(w) + β*(λ*cont_U + (1-λ)*cont_E)\n    end\n    return (;n_V_U, n_V_E, n_x)\nend\n\nbellman_step (generic function with 1 method)\n\n\n\nbellman_step(V_U_0, V_E_0, m)\n\n(n_V_U = [0.06485644868579027, 2.08085644868579, 1.6968564486857902], n_V_E = [-1.741545623765991, 0.7651199999999997, 0.7214322366212127], n_x = Bool[1, 1, 1])\n\n\nImplement Value Function Iteration\n\nfunction value_iteration(p; T=1000, τ_η=1e-8, verbose=true)\n\n    V_U_0 = zeros(3)\n    V_E_0 = zeros(3)\n\n    local V_U, V_E\n\n    for t=1:T\n\n        V_U, V_E, x = bellman_step(V_U_0, V_E_0, p)\n        \n        η = distance( (V_U_0, V_E_0), (V_U, V_E))\n\n        V_U_0, V_E_0 = V_U, V_E\n\n        if η&lt;τ_η\n            break\n        end\n\n        if verbose\n            @show (t, η, x)\n        end\n\n        # println(\"Iteration: $n ; η = $η\")\n\n    end\n\n    return (; V_U, V_E)\n    \nend\n\nvalue_iteration (generic function with 1 method)\n\n\n\nm\n\n(β = 0.96, λ = 0.01, cbar = 0.8, wvec = [0.6, 1.0, 1.4], pvec = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333])\n\n\n\nvalue_iteration(m)\n\n(t, η, x) = (1, 0.5108256237659907, Bool[0, 0, 0])\n(t, η, x) = (2, 0.48763085091981395, Bool[0, 1, 1])\n(t, η, x) = (3, 0.4630962149929281, Bool[0, 1, 1])\n(t, η, x) = (4, 0.43904602360823586, Bool[0, 1, 1])\n(t, η, x) = (5, 0.4160002641604996, Bool[0, 0, 1])\n(t, η, x) = (6, 0.39388523729722946, Bool[0, 0, 1])\n(t, η, x) = (7, 0.3725547270934362, Bool[0, 0, 1])\n(t, η, x) = (8, 0.3521196771442874, Bool[0, 0, 1])\n(t, η, x) = (9, 0.3326287657342153, Bool[0, 0, 1])\n(t, η, x) = (10, 0.31409252865426396, Bool[0, 0, 1])\n(t, η, x) = (11, 0.2964985089906609, Bool[0, 0, 1])\n(t, η, x) = (12, 0.2798207532429604, Bool[0, 0, 1])\n(t, η, x) = (13, 0.26402574614661223, Bool[0, 0, 1])\n(t, η, x) = (14, 0.24907610309183692, Bool[0, 0, 1])\n(t, η, x) = (15, 0.2349328514342366, Bool[0, 0, 1])\n(t, η, x) = (16, 0.2215568246184949, Bool[0, 0, 1])\n(t, η, x) = (17, 0.20890949927437052, Bool[0, 0, 1])\n(t, η, x) = (18, 0.1969534833026243, Bool[0, 0, 1])\n(t, η, x) = (19, 0.18565278597628865, Bool[0, 0, 1])\n(t, η, x) = (20, 0.17497295255231649, Bool[0, 0, 1])\n(t, η, x) = (21, 0.1648811153002665, Bool[0, 0, 1])\n(t, η, x) = (22, 0.15534599357687018, Bool[0, 0, 1])\n(t, η, x) = (23, 0.14633786342713684, Bool[0, 0, 1])\n(t, η, x) = (24, 0.13782850953908365, Bool[0, 0, 1])\n(t, η, x) = (25, 0.12979116755851905, Bool[0, 0, 1])\n(t, η, x) = (26, 0.12220046173543686, Bool[0, 0, 1])\n(t, η, x) = (27, 0.11503234096423398, Bool[0, 0, 1])\n(t, η, x) = (28, 0.10826401507998096, Bool[0, 0, 1])\n(t, η, x) = (29, 0.10202559979801862, Bool[0, 0, 1])\n(t, η, x) = (30, 0.09794454836367006, Bool[0, 0, 1])\n(t, η, x) = (31, 0.09402674912941844, Bool[0, 0, 1])\n(t, η, x) = (32, 0.09026566825850679, Bool[0, 0, 1])\n(t, η, x) = (33, 0.08665503465319091, Bool[0, 0, 1])\n(t, η, x) = (34, 0.08318882893307933, Bool[0, 0, 1])\n(t, η, x) = (35, 0.07986127304361101, Bool[0, 0, 1])\n(t, η, x) = (36, 0.07666682039952377, Bool[0, 0, 1])\n(t, η, x) = (37, 0.07360014649777913, Bool[0, 0, 1])\n(t, η, x) = (38, 0.07065613995340048, Bool[0, 0, 1])\n(t, η, x) = (39, 0.06782989392377736, Bool[0, 0, 1])\n(t, η, x) = (40, 0.06511669789481633, Bool[0, 0, 1])\n(t, η, x) = (41, 0.06251202980754833, Bool[0, 0, 1])\n(t, η, x) = (42, 0.06001154850714929, Bool[0, 0, 1])\n(t, η, x) = (43, 0.05761108649871716, Bool[0, 0, 1])\n(t, η, x) = (44, 0.05530664299581112, Bool[0, 0, 1])\n(t, η, x) = (45, 0.05309437724889765, Bool[0, 0, 1])\n(t, η, x) = (46, 0.0509706021418701, Bool[0, 0, 1])\n(t, η, x) = (47, 0.04893177804543303, Bool[0, 0, 1])\n(t, η, x) = (48, 0.046974506916830805, Bool[0, 0, 1])\n(t, η, x) = (49, 0.045095526635881455, Bool[0, 0, 1])\n(t, η, x) = (50, 0.043291705567749084, Bool[0, 0, 1])\n(t, η, x) = (51, 0.04156003734333957, Bool[0, 0, 1])\n(t, η, x) = (52, 0.03989763584853456, Bool[0, 0, 1])\n(t, η, x) = (53, 0.03830173041391749, Bool[0, 0, 1])\n(t, η, x) = (54, 0.03676966119693503, Bool[0, 0, 1])\n(t, η, x) = (55, 0.0352988747487899, Bool[0, 0, 1])\n(t, η, x) = (56, 0.03388691975866909, Bool[0, 0, 1])\n(t, η, x) = (57, 0.03253144296821553, Bool[0, 0, 1])\n(t, η, x) = (58, 0.03123018524941923, Bool[0, 0, 1])\n(t, η, x) = (59, 0.02998097783940068, Bool[0, 0, 1])\n(t, η, x) = (60, 0.028781738725797368, Bool[0, 0, 1])\n(t, η, x) = (61, 0.027630469176748385, Bool[0, 0, 1])\n(t, η, x) = (62, 0.026525250409668466, Bool[0, 0, 1])\n(t, η, x) = (63, 0.02546424039327455, Bool[0, 0, 1])\n(t, η, x) = (64, 0.02444567077753934, Bool[0, 0, 1])\n(t, η, x) = (65, 0.02346784394643464, Bool[0, 0, 1])\n(t, η, x) = (66, 0.02252913018857594, Bool[0, 0, 1])\n(t, η, x) = (67, 0.02162796498103159, Bool[0, 0, 1])\n(t, η, x) = (68, 0.020762846381790823, Bool[0, 0, 1])\n(t, η, x) = (69, 0.01993233252651816, Bool[0, 0, 1])\n(t, η, x) = (70, 0.019135039225457007, Bool[0, 0, 1])\n(t, η, x) = (71, 0.01836963765643862, Bool[0, 0, 1])\n(t, η, x) = (72, 0.01763485215018079, Bool[0, 0, 1])\n(t, η, x) = (73, 0.01692945806417434, Bool[0, 0, 1])\n(t, η, x) = (74, 0.016252279741607367, Bool[0, 0, 1])\n(t, η, x) = (75, 0.015602188551943286, Bool[0, 0, 1])\n(t, η, x) = (76, 0.014978101009865519, Bool[0, 0, 1])\n(t, η, x) = (77, 0.014378976969469548, Bool[0, 0, 1])\n(t, η, x) = (78, 0.013803817890691406, Bool[0, 0, 1])\n(t, η, x) = (79, 0.01325166517506382, Bool[0, 0, 1])\n(t, η, x) = (80, 0.012721598568061765, Bool[0, 0, 1])\n(t, η, x) = (81, 0.012212734625339117, Bool[0, 0, 1])\n(t, η, x) = (82, 0.011724225240325126, Bool[0, 0, 1])\n(t, η, x) = (83, 0.01125525623071244, Bool[0, 0, 1])\n(t, η, x) = (84, 0.010805045981484795, Bool[0, 0, 1])\n(t, η, x) = (85, 0.010372844142223947, Bool[0, 0, 1])\n(t, η, x) = (86, 0.009957930376534918, Bool[0, 0, 1])\n(t, η, x) = (87, 0.0095596131614748, Bool[0, 0, 1])\n(t, η, x) = (88, 0.009177228635015133, Bool[0, 0, 1])\n(t, η, x) = (89, 0.008810139489614954, Bool[0, 0, 1])\n(t, η, x) = (90, 0.008457733910029575, Bool[0, 0, 1])\n(t, η, x) = (91, 0.008119424553628463, Bool[0, 0, 1])\n(t, η, x) = (92, 0.00779464757148407, Bool[0, 0, 1])\n(t, η, x) = (93, 0.007482861668624885, Bool[0, 0, 1])\n(t, η, x) = (94, 0.0071835472018797475, Bool[0, 0, 1])\n(t, η, x) = (95, 0.0068962053138044155, Bool[0, 0, 1])\n(t, η, x) = (96, 0.0066203571012524165, Bool[0, 0, 1])\n(t, η, x) = (97, 0.006355542817202853, Bool[0, 0, 1])\n(t, η, x) = (98, 0.006101321104514668, Bool[0, 0, 1])\n(t, η, x) = (99, 0.005857268260333726, Bool[0, 0, 1])\n(t, η, x) = (100, 0.005622977529919915, Bool[0, 0, 1])\n(t, η, x) = (101, 0.005398058428723651, Bool[0, 0, 1])\n(t, η, x) = (102, 0.005182136091574918, Bool[0, 0, 1])\n(t, η, x) = (103, 0.0049748506479119214, Bool[0, 0, 1])\n(t, η, x) = (104, 0.004775856621995089, Bool[0, 0, 1])\n(t, η, x) = (105, 0.0045848223571143265, Bool[0, 0, 1])\n(t, η, x) = (106, 0.004401429462830286, Bool[0, 0, 1])\n(t, η, x) = (107, 0.004225372284317075, Bool[0, 0, 1])\n(t, η, x) = (108, 0.004056357392944854, Bool[0, 0, 1])\n(t, η, x) = (109, 0.003894103097227486, Bool[0, 0, 1])\n(t, η, x) = (110, 0.0037383389733376404, Bool[0, 0, 1])\n(t, η, x) = (111, 0.003588805414404206, Bool[0, 0, 1])\n(t, η, x) = (112, 0.0034452531978281797, Bool[0, 0, 1])\n(t, η, x) = (113, 0.0033074430699153723, Bool[0, 0, 1])\n(t, η, x) = (114, 0.003175145347118935, Bool[0, 0, 1])\n(t, η, x) = (115, 0.003048139533234462, Bool[0, 0, 1])\n(t, η, x) = (116, 0.0029262139519046215, Bool[0, 0, 1])\n(t, η, x) = (117, 0.002809165393828472, Bool[0, 0, 1])\n(t, η, x) = (118, 0.0026967987780759373, Bool[0, 0, 1])\n(t, η, x) = (119, 0.0025889268269523313, Bool[0, 0, 1])\n(t, η, x) = (120, 0.0024853697538738118, Bool[0, 0, 1])\n(t, η, x) = (121, 0.0023859549637190725, Bool[0, 0, 1])\n(t, η, x) = (122, 0.0022905167651705582, Bool[0, 0, 1])\n(t, η, x) = (123, 0.002198896094562919, Bool[0, 0, 1])\n(t, η, x) = (124, 0.0021109402507812902, Bool[0, 0, 1])\n(t, η, x) = (125, 0.0020265026407502162, Bool[0, 0, 1])\n(t, η, x) = (126, 0.001945442535120634, Bool[0, 0, 1])\n(t, η, x) = (127, 0.0018676248337152757, Bool[0, 0, 1])\n(t, η, x) = (128, 0.001792919840366558, Bool[0, 0, 1])\n(t, η, x) = (129, 0.001721203046751718, Bool[0, 0, 1])\n(t, η, x) = (130, 0.0016523549248814717, Bool[0, 0, 1])\n(t, η, x) = (131, 0.001586260727885147, Bool[0, 0, 1])\n(t, η, x) = (132, 0.0015228102987716596, Bool[0, 0, 1])\n(t, η, x) = (133, 0.0014618978868208288, Bool[0, 0, 1])\n(t, η, x) = (134, 0.0014034219713474627, Bool[0, 0, 1])\n(t, η, x) = (135, 0.0013472850924927116, Bool[0, 0, 1])\n(t, η, x) = (136, 0.0012933936887931097, Bool[0, 0, 1])\n(t, η, x) = (137, 0.0012416579412413142, Bool[0, 0, 1])\n(t, η, x) = (138, 0.0011919916235916261, Bool[0, 0, 1])\n(t, η, x) = (139, 0.001144311958649169, Bool[0, 0, 1])\n(t, η, x) = (140, 0.0010985394803038062, Bool[0, 0, 1])\n(t, η, x) = (141, 0.0010545979010911921, Bool[0, 0, 1])\n(t, η, x) = (142, 0.0010124139850473668, Bool[0, 0, 1])\n(t, η, x) = (143, 0.0009719174256446195, Bool[0, 0, 1])\n(t, η, x) = (144, 0.0009330407286203268, Bool[0, 0, 1])\n(t, η, x) = (145, 0.0008957190994758335, Bool[0, 0, 1])\n(t, η, x) = (146, 0.0008598903354961607, Bool[0, 0, 1])\n(t, η, x) = (147, 0.0008254947220764919, Bool[0, 0, 1])\n(t, η, x) = (148, 0.0007924749331937875, Bool[0, 0, 1])\n(t, η, x) = (149, 0.000760775935865432, Bool[0, 0, 1])\n(t, η, x) = (150, 0.0007303448984306016, Bool[0, 0, 1])\n(t, η, x) = (151, 0.0007011311024935907, Bool[0, 0, 1])\n(t, η, x) = (152, 0.0006730858583940957, Bool[0, 0, 1])\n(t, η, x) = (153, 0.0006461624240579056, Bool[0, 0, 1])\n(t, η, x) = (154, 0.0006203159270956604, Bool[0, 0, 1])\n(t, η, x) = (155, 0.0005955032900120116, Bool[0, 0, 1])\n(t, η, x) = (156, 0.0005716831584114956, Bool[0, 0, 1])\n(t, η, x) = (157, 0.0005488158320741121, Bool[0, 0, 1])\n(t, η, x) = (158, 0.0005268631987913608, Bool[0, 0, 1])\n(t, η, x) = (159, 0.0005057886708410564, Bool[0, 0, 1])\n(t, η, x) = (160, 0.0004855571240076628, Bool[0, 0, 1])\n(t, η, x) = (161, 0.00046613483904689446, Bool[0, 0, 1])\n(t, η, x) = (162, 0.00044748944548445024, Bool[0, 0, 1])\n(t, η, x) = (163, 0.000429589867665392, Bool[0, 0, 1])\n(t, η, x) = (164, 0.00041240627295913157, Bool[0, 0, 1])\n(t, η, x) = (165, 0.00039591002204097947, Bool[0, 0, 1])\n(t, η, x) = (166, 0.00038007362115966004, Bool[0, 0, 1])\n(t, η, x) = (167, 0.00036487067631263415, Bool[0, 0, 1])\n(t, η, x) = (168, 0.00035027584925995114, Bool[0, 0, 1])\n(t, η, x) = (169, 0.00033626481528870045, Bool[0, 0, 1])\n(t, η, x) = (170, 0.00032281422267743665, Bool[0, 0, 1])\n(t, η, x) = (171, 0.00030990165377176027, Bool[0, 0, 1])\n(t, η, x) = (172, 0.000297505587620428, Bool[0, 0, 1])\n(t, η, x) = (173, 0.0002856053641160372, Bool[0, 0, 1])\n(t, η, x) = (174, 0.0002741811495514668, Bool[0, 0, 1])\n(t, η, x) = (175, 0.0002632139035689818, Bool[0, 0, 1])\n(t, η, x) = (176, 0.0002526853474265067, Bool[0, 0, 1])\n(t, η, x) = (177, 0.00024257793352955304, Bool[0, 0, 1])\n(t, η, x) = (178, 0.0002328748161879446, Bool[0, 0, 1])\n(t, η, x) = (179, 0.00022355982354049786, Bool[0, 0, 1])\n(t, η, x) = (180, 0.00021461743059969507, Bool[0, 0, 1])\n(t, η, x) = (181, 0.0002060327333754941, Bool[0, 0, 1])\n(t, η, x) = (182, 0.00019779142404008354, Bool[0, 0, 1])\n(t, η, x) = (183, 0.00018987976707851573, Bool[0, 0, 1])\n(t, η, x) = (184, 0.00018228457639501983, Bool[0, 0, 1])\n(t, η, x) = (185, 0.00017499319333946772, Bool[0, 0, 1])\n(t, η, x) = (186, 0.00016799346560603112, Bool[0, 0, 1])\n(t, η, x) = (187, 0.00016127372698093723, Bool[0, 0, 1])\n(t, η, x) = (188, 0.00015482277790290766, Bool[0, 0, 1])\n(t, η, x) = (189, 0.00014862986678654266, Bool[0, 0, 1])\n(t, η, x) = (190, 0.0001426846721148678, Bool[0, 0, 1])\n(t, η, x) = (191, 0.00013697728523087704, Bool[0, 0, 1])\n(t, η, x) = (192, 0.00013149819382007877, Bool[0, 0, 1])\n(t, η, x) = (193, 0.00012623826606805721, Bool[0, 0, 1])\n(t, η, x) = (194, 0.00012118873542554809, Bool[0, 0, 1])\n(t, η, x) = (195, 0.00011634118600856169, Bool[0, 0, 1])\n(t, η, x) = (196, 0.0001116875385687166, Bool[0, 0, 1])\n(t, η, x) = (197, 0.0001072200370257903, Bool[0, 0, 1])\n(t, η, x) = (198, 0.00010293123554383499, Bool[0, 0, 1])\n(t, η, x) = (199, 9.881398612332504e-5, Bool[0, 0, 1])\n(t, η, x) = (200, 9.486142667736175e-5, Bool[0, 0, 1])\n(t, η, x) = (201, 9.10669696114752e-5, Bool[0, 0, 1])\n(t, η, x) = (202, 8.742429082708725e-5, Bool[0, 0, 1])\n(t, η, x) = (203, 8.39273191939327e-5, Bool[0, 0, 1])\n(t, η, x) = (204, 8.057022642571354e-5, Bool[0, 0, 1])\n(t, η, x) = (205, 7.734741736875606e-5, Bool[0, 0, 1])\n(t, η, x) = (206, 7.425352067436108e-5, Bool[0, 0, 1])\n(t, η, x) = (207, 7.128337984774191e-5, Bool[0, 0, 1])\n(t, η, x) = (208, 6.843204465312169e-5, Bool[0, 0, 1])\n(t, η, x) = (209, 6.569476286610865e-5, Bool[0, 0, 1])\n(t, η, x) = (210, 6.306697235114456e-5, Bool[0, 0, 1])\n(t, η, x) = (211, 6.054429345780932e-5, Bool[0, 0, 1])\n(t, η, x) = (212, 5.8122521719994324e-5, Bool[0, 0, 1])\n(t, η, x) = (213, 5.579762085083928e-5, Bool[0, 0, 1])\n(t, η, x) = (214, 5.35657160174452e-5, Bool[0, 0, 1])\n(t, η, x) = (215, 5.142308737671186e-5, Bool[0, 0, 1])\n(t, η, x) = (216, 4.9366163882069714e-5, Bool[0, 0, 1])\n(t, η, x) = (217, 4.739151732646718e-5, Bool[0, 0, 1])\n(t, η, x) = (218, 4.5495856633159804e-5, Bool[0, 0, 1])\n(t, η, x) = (219, 4.3676022368543954e-5, Bool[0, 0, 1])\n(t, η, x) = (220, 4.192898147348245e-5, Bool[0, 0, 1])\n(t, η, x) = (221, 4.0251822214898425e-5, Bool[0, 0, 1])\n(t, η, x) = (222, 3.864174932655118e-5, Bool[0, 0, 1])\n(t, η, x) = (223, 3.7096079353204914e-5, Bool[0, 0, 1])\n(t, η, x) = (224, 3.561223617865039e-5, Bool[0, 0, 1])\n(t, η, x) = (225, 3.418774673136227e-5, Bool[0, 0, 1])\n(t, η, x) = (226, 3.282023686246305e-5, Bool[0, 0, 1])\n(t, η, x) = (227, 3.150742738800005e-5, Bool[0, 0, 1])\n(t, η, x) = (228, 3.024713029198267e-5, Bool[0, 0, 1])\n(t, η, x) = (229, 2.9037245080409946e-5, Bool[0, 0, 1])\n(t, η, x) = (230, 2.787575527740671e-5, Bool[0, 0, 1])\n(t, η, x) = (231, 2.6760725066132807e-5, Bool[0, 0, 1])\n(t, η, x) = (232, 2.569029606291906e-5, Bool[0, 0, 1])\n(t, η, x) = (233, 2.4662684221077313e-5, Bool[0, 0, 1])\n(t, η, x) = (234, 2.3676176851950004e-5, Bool[0, 0, 1])\n(t, η, x) = (235, 2.272912977741015e-5, Bool[0, 0, 1])\n(t, η, x) = (236, 2.1819964586278218e-5, Bool[0, 0, 1])\n(t, η, x) = (237, 2.0947166002649453e-5, Bool[0, 0, 1])\n(t, η, x) = (238, 2.010927936346718e-5, Bool[0, 0, 1])\n(t, η, x) = (239, 1.930490818846664e-5, Bool[0, 0, 1])\n(t, η, x) = (240, 1.8532711861141138e-5, Bool[0, 0, 1])\n(t, η, x) = (241, 1.779140338697971e-5, Bool[0, 0, 1])\n(t, η, x) = (242, 1.7079747251180777e-5, Bool[0, 0, 1])\n(t, η, x) = (243, 1.6396557361630926e-5, Bool[0, 0, 1])\n(t, η, x) = (244, 1.574069506737885e-5, Bool[0, 0, 1])\n(t, η, x) = (245, 1.5111067265038969e-5, Bool[0, 0, 1])\n(t, η, x) = (246, 1.4506624574472937e-5, Bool[0, 0, 1])\n(t, η, x) = (247, 1.392635959174271e-5, Bool[0, 0, 1])\n(t, η, x) = (248, 1.3369305206900606e-5, Bool[0, 0, 1])\n(t, η, x) = (249, 1.2834532998162729e-5, Bool[0, 0, 1])\n(t, η, x) = (250, 1.2321151679373088e-5, Bool[0, 0, 1])\n(t, η, x) = (251, 1.1828305611416567e-5, Bool[0, 0, 1])\n(t, η, x) = (252, 1.1355173388238882e-5, Bool[0, 0, 1])\n(t, η, x) = (253, 1.0900966453064598e-5, Bool[0, 0, 1])\n(t, η, x) = (254, 1.0464927793663037e-5, Bool[0, 0, 1])\n(t, η, x) = (255, 1.0046330682023097e-5, Bool[0, 0, 1])\n(t, η, x) = (256, 9.644477454884282e-6, Bool[0, 0, 1])\n(t, η, x) = (257, 9.258698357328399e-6, Bool[0, 0, 1])\n(t, η, x) = (258, 8.888350423674751e-6, Bool[0, 0, 1])\n(t, η, x) = (259, 8.532816405448784e-6, Bool[0, 0, 1])\n(t, η, x) = (260, 8.191503749088724e-6, Bool[0, 0, 1])\n(t, η, x) = (261, 7.863843599409392e-6, Bool[0, 0, 1])\n(t, η, x) = (262, 7.549289856356722e-6, Bool[0, 0, 1])\n(t, η, x) = (263, 7.247318261960345e-6, Bool[0, 0, 1])\n(t, η, x) = (264, 6.957425531695094e-6, Bool[0, 0, 1])\n(t, η, x) = (265, 6.679128510711507e-6, Bool[0, 0, 1])\n(t, η, x) = (266, 6.411963370034357e-6, Bool[0, 0, 1])\n(t, η, x) = (267, 6.155484834735603e-6, Bool[0, 0, 1])\n(t, η, x) = (268, 5.909265441417233e-6, Bool[0, 0, 1])\n(t, η, x) = (269, 5.672894824115815e-6, Bool[0, 0, 1])\n(t, η, x) = (270, 5.445979031293291e-6, Bool[0, 0, 1])\n(t, η, x) = (271, 5.2281398703613036e-6, Bool[0, 0, 1])\n(t, η, x) = (272, 5.0190142752981615e-6, Bool[0, 0, 1])\n(t, η, x) = (273, 4.818253703575692e-6, Bool[0, 0, 1])\n(t, η, x) = (274, 4.625523555290556e-6, Bool[0, 0, 1])\n(t, η, x) = (275, 4.440502613611841e-6, Bool[0, 0, 1])\n(t, η, x) = (276, 4.262882508321297e-6, Bool[0, 0, 1])\n(t, η, x) = (277, 4.092367207775283e-6, Bool[0, 0, 1])\n(t, η, x) = (278, 3.928672519748488e-6, Bool[0, 0, 1])\n(t, η, x) = (279, 3.7715256189230217e-6, Bool[0, 0, 1])\n(t, η, x) = (280, 3.6206645948055893e-6, Bool[0, 0, 1])\n(t, η, x) = (281, 3.4758380111910014e-6, Bool[0, 0, 1])\n(t, η, x) = (282, 3.33680449138285e-6, Bool[0, 0, 1])\n(t, η, x) = (283, 3.2033323114077916e-6, Bool[0, 0, 1])\n(t, η, x) = (284, 3.0751990180988287e-6, Bool[0, 0, 1])\n(t, η, x) = (285, 2.9521910578367283e-6, Bool[0, 0, 1])\n(t, η, x) = (286, 2.8341034150614064e-6, Bool[0, 0, 1])\n(t, η, x) = (287, 2.72073927920502e-6, Bool[0, 0, 1])\n(t, η, x) = (288, 2.611909707184168e-6, Bool[0, 0, 1])\n(t, η, x) = (289, 2.507433319642871e-6, Bool[0, 0, 1])\n(t, η, x) = (290, 2.4071359874255904e-6, Bool[0, 0, 1])\n(t, η, x) = (291, 2.310850548248311e-6, Bool[0, 0, 1])\n(t, η, x) = (292, 2.2184165260341615e-6, Bool[0, 0, 1])\n(t, η, x) = (293, 2.1296798653480664e-6, Bool[0, 0, 1])\n(t, η, x) = (294, 2.044492670272291e-6, Bool[0, 0, 1])\n(t, η, x) = (295, 1.962712962821911e-6, Bool[0, 0, 1])\n(t, η, x) = (296, 1.8842044440248173e-6, Bool[0, 0, 1])\n(t, η, x) = (297, 1.8088362665480417e-6, Bool[0, 0, 1])\n(t, η, x) = (298, 1.7364828162058643e-6, Bool[0, 0, 1])\n(t, η, x) = (299, 1.6670235032378855e-6, Bool[0, 0, 1])\n(t, η, x) = (300, 1.6003425642452385e-6, Bool[0, 0, 1])\n(t, η, x) = (301, 1.536328861462266e-6, Bool[0, 0, 1])\n(t, η, x) = (302, 1.474875706897194e-6, Bool[0, 0, 1])\n(t, η, x) = (303, 1.4158806775910193e-6, Bool[0, 0, 1])\n(t, η, x) = (304, 1.3592454513045027e-6, Bool[0, 0, 1])\n(t, η, x) = (305, 1.3048756333233769e-6, Bool[0, 0, 1])\n(t, η, x) = (306, 1.252680607244372e-6, Bool[0, 0, 1])\n(t, η, x) = (307, 1.2025733830967056e-6, Bool[0, 0, 1])\n(t, η, x) = (308, 1.1544704481281087e-6, Bool[0, 0, 1])\n(t, η, x) = (309, 1.1082916309135271e-6, Bool[0, 0, 1])\n(t, η, x) = (310, 1.0639599654638232e-6, Bool[0, 0, 1])\n(t, η, x) = (311, 1.0214015668807974e-6, Bool[0, 0, 1])\n(t, η, x) = (312, 9.805455034594956e-7, Bool[0, 0, 1])\n(t, η, x) = (313, 9.413236830013716e-7, Bool[0, 0, 1])\n(t, η, x) = (314, 9.036707364629137e-7, Bool[0, 0, 1])\n(t, η, x) = (315, 8.675239069333429e-7, Bool[0, 0, 1])\n(t, η, x) = (316, 8.328229501586293e-7, Bool[0, 0, 1])\n(t, η, x) = (317, 7.995100332891525e-7, Bool[0, 0, 1])\n(t, η, x) = (318, 7.67529631851005e-7, Bool[0, 0, 1])\n(t, η, x) = (319, 7.368284462572205e-7, Bool[0, 0, 1])\n(t, η, x) = (320, 7.073553085490403e-7, Bool[0, 0, 1])\n(t, η, x) = (321, 6.790610953544274e-7, Bool[0, 0, 1])\n(t, η, x) = (322, 6.518986523929016e-7, Bool[0, 0, 1])\n(t, η, x) = (323, 6.25822705657697e-7, Bool[0, 0, 1])\n(t, η, x) = (324, 6.007897983550947e-7, Bool[0, 0, 1])\n(t, η, x) = (325, 5.767582065274723e-7, Bool[0, 0, 1])\n(t, η, x) = (326, 5.536878777689935e-7, Bool[0, 0, 1])\n(t, η, x) = (327, 5.315403628358695e-7, Bool[0, 0, 1])\n(t, η, x) = (328, 5.102787490329774e-7, Bool[0, 0, 1])\n(t, η, x) = (329, 4.898675989295498e-7, Bool[0, 0, 1])\n(t, η, x) = (330, 4.70272895292112e-7, Bool[0, 0, 1])\n(t, η, x) = (331, 4.5146197891199336e-7, Bool[0, 0, 1])\n(t, η, x) = (332, 4.334034988673352e-7, Bool[0, 0, 1])\n(t, η, x) = (333, 4.1606736012056444e-7, Bool[0, 0, 1])\n(t, η, x) = (334, 3.9942466578679614e-7, Bool[0, 0, 1])\n(t, η, x) = (335, 3.834476789421615e-7, Bool[0, 0, 1])\n(t, η, x) = (336, 3.6810977199763784e-7, Bool[0, 0, 1])\n(t, η, x) = (337, 3.533853814019494e-7, Bool[0, 0, 1])\n(t, η, x) = (338, 3.3924996500900306e-7, Bool[0, 0, 1])\n(t, η, x) = (339, 3.256799665507515e-7, Bool[0, 0, 1])\n(t, η, x) = (340, 3.1265276856373703e-7, Bool[0, 0, 1])\n(t, η, x) = (341, 3.0014665775013327e-7, Bool[0, 0, 1])\n(t, η, x) = (342, 2.8814079211514354e-7, Bool[0, 0, 1])\n(t, η, x) = (343, 2.7661515922261515e-7, Bool[0, 0, 1])\n(t, η, x) = (344, 2.655505531024005e-7, Bool[0, 0, 1])\n(t, η, x) = (345, 2.5492853161779294e-7, Bool[0, 0, 1])\n(t, η, x) = (346, 2.447313907083526e-7, Bool[0, 0, 1])\n(t, η, x) = (347, 2.3494213419184007e-7, Bool[0, 0, 1])\n(t, η, x) = (348, 2.2554444889522074e-7, Bool[0, 0, 1])\n(t, η, x) = (349, 2.1652267090388477e-7, Bool[0, 0, 1])\n(t, η, x) = (350, 2.0786176424536507e-7, Bool[0, 0, 1])\n(t, η, x) = (351, 1.9954729424398465e-7, Bool[0, 0, 1])\n(t, η, x) = (352, 1.9156540265186095e-7, Bool[0, 0, 1])\n(t, η, x) = (353, 1.839027863326237e-7, Bool[0, 0, 1])\n(t, η, x) = (354, 1.7654667505695443e-7, Bool[0, 0, 1])\n(t, η, x) = (355, 1.6948480663359078e-7, Bool[0, 0, 1])\n(t, η, x) = (356, 1.6270541447482856e-7, Bool[0, 0, 1])\n(t, η, x) = (357, 1.5619719917481234e-7, Bool[0, 0, 1])\n(t, η, x) = (358, 1.499493116341455e-7, Bool[0, 0, 1])\n(t, η, x) = (359, 1.4395133796085702e-7, Bool[0, 0, 1])\n(t, η, x) = (360, 1.3819328437136846e-7, Bool[0, 0, 1])\n(t, η, x) = (361, 1.3266555320967655e-7, Bool[0, 0, 1])\n(t, η, x) = (362, 1.2735893140103371e-7, Bool[0, 0, 1])\n(t, η, x) = (363, 1.2226457357655818e-7, Bool[0, 0, 1])\n(t, η, x) = (364, 1.1737399141509286e-7, Bool[0, 0, 1])\n(t, η, x) = (365, 1.1267903232692333e-7, Bool[0, 0, 1])\n(t, η, x) = (366, 1.0817187057199362e-7, Bool[0, 0, 1])\n(t, η, x) = (367, 1.0384499482540832e-7, Bool[0, 0, 1])\n(t, η, x) = (368, 9.969119574293472e-8, Bool[0, 0, 1])\n(t, η, x) = (369, 9.570354819743443e-8, Bool[0, 0, 1])\n(t, η, x) = (370, 9.187540683797124e-8, Bool[0, 0, 1])\n(t, η, x) = (371, 8.820039010259961e-8, Bool[0, 0, 1])\n(t, η, x) = (372, 8.467237400111571e-8, Bool[0, 0, 1])\n(t, η, x) = (373, 8.128547968055955e-8, Bool[0, 0, 1])\n(t, η, x) = (374, 7.803406099071708e-8, Bool[0, 0, 1])\n(t, η, x) = (375, 7.49126982668713e-8, Bool[0, 0, 1])\n(t, η, x) = (376, 7.191619033619645e-8, Bool[0, 0, 1])\n(t, η, x) = (377, 6.903954297143855e-8, Bool[0, 0, 1])\n(t, η, x) = (378, 6.627796089730964e-8, Bool[0, 0, 1])\n(t, η, x) = (379, 6.362684246141725e-8, Bool[0, 0, 1])\n(t, η, x) = (380, 6.108176897612339e-8, Bool[0, 0, 1])\n(t, η, x) = (381, 5.8638498501295544e-8, Bool[0, 0, 1])\n(t, η, x) = (382, 5.6292957850700986e-8, Bool[0, 0, 1])\n(t, η, x) = (383, 5.404123992747145e-8, Bool[0, 0, 1])\n(t, η, x) = (384, 5.187959040142687e-8, Bool[0, 0, 1])\n(t, η, x) = (385, 4.980440682089693e-8, Bool[0, 0, 1])\n(t, η, x) = (386, 4.7812230619115326e-8, Bool[0, 0, 1])\n(t, η, x) = (387, 4.589974178514922e-8, Bool[0, 0, 1])\n(t, η, x) = (388, 4.406375175847188e-8, Bool[0, 0, 1])\n(t, η, x) = (389, 4.230120165260587e-8, Bool[0, 0, 1])\n(t, η, x) = (390, 4.060915337333881e-8, Bool[0, 0, 1])\n(t, η, x) = (391, 3.8984787842366586e-8, Bool[0, 0, 1])\n(t, η, x) = (392, 3.74253961155091e-8, Bool[0, 0, 1])\n(t, η, x) = (393, 3.592838027088874e-8, Bool[0, 0, 1])\n(t, η, x) = (394, 3.4491245415324556e-8, Bool[0, 0, 1])\n(t, η, x) = (395, 3.3111595243440206e-8, Bool[0, 0, 1])\n(t, η, x) = (396, 3.178713203766392e-8, Bool[0, 0, 1])\n(t, η, x) = (397, 3.0515646010087494e-8, Bool[0, 0, 1])\n(t, η, x) = (398, 2.9295019743358353e-8, Bool[0, 0, 1])\n(t, η, x) = (399, 2.8123219308895386e-8, Bool[0, 0, 1])\n(t, η, x) = (400, 2.6998289825996835e-8, Bool[0, 0, 1])\n(t, η, x) = (401, 2.591835901455397e-8, Bool[0, 0, 1])\n(t, η, x) = (402, 2.4881624760553223e-8, Bool[0, 0, 1])\n(t, η, x) = (403, 2.3886359556968273e-8, Bool[0, 0, 1])\n(t, η, x) = (404, 2.2930905174689542e-8, Bool[0, 0, 1])\n(t, η, x) = (405, 2.2013668221632088e-8, Bool[0, 0, 1])\n(t, η, x) = (406, 2.1133121919092446e-8, Bool[0, 0, 1])\n(t, η, x) = (407, 2.028779810814285e-8, Bool[0, 0, 1])\n(t, η, x) = (408, 1.947628636145282e-8, Bool[0, 0, 1])\n(t, η, x) = (409, 1.8697233983289152e-8, Bool[0, 0, 1])\n(t, η, x) = (410, 1.79493451213375e-8, Bool[0, 0, 1])\n(t, η, x) = (411, 1.723137188491819e-8, Bool[0, 0, 1])\n(t, η, x) = (412, 1.6542117009521462e-8, Bool[0, 0, 1])\n(t, η, x) = (413, 1.5880432080450646e-8, Bool[0, 0, 1])\n(t, η, x) = (414, 1.5245214868286894e-8, Bool[0, 0, 1])\n(t, η, x) = (415, 1.4635406664353923e-8, Bool[0, 0, 1])\n(t, η, x) = (416, 1.4049989616182756e-8, Bool[0, 0, 1])\n(t, η, x) = (417, 1.3487990280225404e-8, Bool[0, 0, 1])\n(t, η, x) = (418, 1.2948470740070661e-8, Bool[0, 0, 1])\n(t, η, x) = (419, 1.2430532159157792e-8, Bool[0, 0, 1])\n(t, η, x) = (420, 1.1933310339884429e-8, Bool[0, 0, 1])\n(t, η, x) = (421, 1.145597838814183e-8, Bool[0, 0, 1])\n(t, η, x) = (422, 1.0997738719709105e-8, Bool[0, 0, 1])\n(t, η, x) = (423, 1.0557828389323731e-8, Bool[0, 0, 1])\n(t, η, x) = (424, 1.0135515537967876e-8, Bool[0, 0, 1])\n\n\n(V_U = [6.049790992670206, 6.049790992670206, 7.503338493801174], V_E = [-9.034199339279674, 1.2647043614819962, 8.048418806725287])\n\n\nImplement Policy Iteration and compare rates of convergence.\n\n[true, false, true] == [true, true, true]\n\nfalse\n\n\n\nfunction policy_iteration(p; T=1000,  verbose=true)\n\n\n    local V_U, V_E, x\n    \n    x_0 = zeros(Bool, 3)\n    V_U_0, V_E_0 = policy_eval(x_0, p; verbose=false)\n\n    for t=1:T\n\n        V_U_t, V_E_t, x = bellman_step(V_U_0, V_E_0, p)\n\n        V_U, V_E = policy_eval(x, p; verbose=false)\n        \n        V_U_0, V_E_0 = V_U, V_E\n\n        if verbose\n            @show (t, x, V_U, V_E)\n        end\n\n        if (x==x_0)\n            break\n        end\n\n        x_0 = x\n\n\n    end\n\n    return (; V_U, V_E, x)\n    \nend\n\npolicy_iteration (generic function with 1 method)\n\n\n\npolicy_iteration(m)\n\n(t, x, V_U, V_E) = (1, Bool[0, 1, 1], [3.1389163916366356, 0.42757754738899856, 6.939943411173783], [-9.621069208340083, 0.6778344871456846, 7.461548928913835])\n(t, x, V_U, V_E) = (2, Bool[0, 0, 1], [6.049790992524931, 6.049790992524931, 7.503338493655899], [-9.034199339424942, 1.264704361336724, 8.048418806580012])\n(t, x, V_U, V_E) = (3, Bool[0, 0, 1], [6.049790992524931, 6.049790992524931, 7.503338493655899], [-9.034199339424942, 1.264704361336724, 8.048418806580012])\n\n\n(V_U = [6.049790992524931, 6.049790992524931, 7.503338493655899], V_E = [-9.034199339424942, 1.264704361336724, 8.048418806580012], x = Bool[0, 0, 1])\n\n\nDiscuss the Effects of the Parameters\n\nm\n\n(β = 0.96, λ = 0.01, cbar = 0.8, wvec = [0.6, 1.0, 1.4], pvec = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333])\n\n\n\npolicy_iteration(m; verbose=false).x\n\n3-element Vector{Bool}:\n 0\n 0\n 1\n\n\n\nmerge(m, (;cbar=0.5))\n\n(β = 0.96, λ = 0.01, cbar = 0.5, wvec = [0.6, 1.0, 1.4], pvec = [0.3333333333333333, 0.3333333333333333, 0.3333333333333333])\n\n\n\npolicy_iteration(merge(m, (;cbar=0.5, β=0.1)); verbose=false).x\n\n3-element Vector{Bool}:\n 1\n 1\n 1\n\n\n\npolicy_iteration(merge(m, (;cbar=0.5, λ=0.2)); verbose=false).x\n\n3-element Vector{Bool}:\n 0\n 1\n 1\n\n\n\npolicy_iteration(merge(m, (;cbar=0.6, wvec=[0.9, 1.0, 1.1], λ=0.1)); verbose=false).xa\n\n3-element Vector{Bool}:\n 0\n 1\n 1\n\n\n\nvalue_iteration(merge(m, (;cbar=0.5)))\n\n(t, η, x) = (1, 0.6931471805599453, Bool[0, 0, 0])\n(t, η, x) = (2, 0.4921428857605732, Bool[1, 1, 1])\n(t, η, x) = (3, 0.4682682122321573, Bool[0, 1, 1])\n(t, η, x) = (4, 0.4448321065334351, Bool[0, 1, 1])\n(t, η, x) = (5, 0.421809731483338, Bool[0, 1, 1])\n(t, η, x) = (6, 0.3997326104086891, Bool[0, 1, 1])\n(t, η, x) = (7, 0.37872378365529347, Bool[0, 1, 1])\n(t, η, x) = (8, 0.3587816360837337, Bool[0, 1, 1])\n(t, η, x) = (9, 0.3398678888101081, Bool[0, 1, 1])\n(t, η, x) = (10, 0.3219348089922658, Bool[0, 1, 1])\n(t, η, x) = (11, 0.3049335580865655, Bool[0, 0, 1])\n(t, η, x) = (12, 0.288499138959482, Bool[0, 0, 1])\n(t, η, x) = (13, 0.27272309403811246, Bool[0, 0, 1])\n(t, η, x) = (14, 0.2576563449970104, Bool[0, 0, 1])\n(t, η, x) = (15, 0.24331537237385614, Bool[0, 0, 1])\n(t, η, x) = (16, 0.22969576080372534, Bool[0, 0, 1])\n(t, η, x) = (17, 0.2167806958310372, Bool[0, 0, 1])\n(t, η, x) = (18, 0.20454628035002465, Bool[0, 0, 1])\n(t, η, x) = (19, 0.192964848183526, Bool[0, 0, 1])\n(t, η, x) = (20, 0.1820070169983703, Bool[0, 0, 1])\n(t, η, x) = (21, 0.17164294834044735, Bool[0, 0, 1])\n(t, η, x) = (22, 0.16184310958625314, Bool[0, 0, 1])\n(t, η, x) = (23, 0.15257872356187008, Bool[0, 0, 1])\n(t, η, x) = (24, 0.14382202284234058, Bool[0, 0, 1])\n(t, η, x) = (25, 0.1355463824162415, Bool[0, 0, 1])\n(t, η, x) = (26, 0.12772637709023904, Bool[0, 0, 1])\n(t, η, x) = (27, 0.12033779279605739, Bool[0, 0, 1])\n(t, η, x) = (28, 0.11335761011523093, Bool[0, 0, 1])\n(t, η, x) = (29, 0.10676397150256633, Bool[0, 0, 1])\n(t, η, x) = (30, 0.10053613938402695, Bool[0, 0, 1])\n(t, η, x) = (31, 0.0946544495939623, Bool[0, 0, 1])\n(t, η, x) = (32, 0.08910026291063655, Bool[0, 0, 1])\n(t, η, x) = (33, 0.08385591637642165, Bool[0, 0, 1])\n(t, η, x) = (34, 0.07920130290952265, Bool[0, 0, 1])\n(t, η, x) = (35, 0.07603322629350462, Bool[0, 0, 1])\n(t, η, x) = (36, 0.0729918817971944, Bool[0, 0, 1])\n(t, η, x) = (37, 0.07007219678904875, Bool[0, 0, 1])\n(t, η, x) = (38, 0.06726930277975018, Bool[0, 0, 1])\n(t, η, x) = (39, 0.06457852679933129, Bool[0, 0, 1])\n(t, η, x) = (40, 0.06199538328819543, Bool[0, 0, 1])\n(t, η, x) = (41, 0.05951556641901945, Bool[0, 0, 1])\n(t, η, x) = (42, 0.05713494279292508, Bool[0, 0, 1])\n(t, η, x) = (43, 0.05484954447014179, Bool[0, 0, 1])\n(t, η, x) = (44, 0.052655562306118675, Bool[0, 0, 1])\n(t, η, x) = (45, 0.0505493395710328, Bool[0, 0, 1])\n(t, η, x) = (46, 0.04852736583510531, Bool[0, 0, 1])\n(t, η, x) = (47, 0.046586271105194754, Bool[0, 0, 1])\n(t, η, x) = (48, 0.04472282020014973, Bool[0, 0, 1])\n(t, η, x) = (49, 0.04293390735379177, Bool[0, 0, 1])\n(t, η, x) = (50, 0.04121655103546207, Bool[0, 0, 1])\n(t, η, x) = (51, 0.03956788897880337, Bool[0, 0, 1])\n(t, η, x) = (52, 0.037985173410042705, Bool[0, 0, 1])\n(t, η, x) = (53, 0.03646576646758426, Bool[0, 0, 1])\n(t, η, x) = (54, 0.03500713580506343, Bool[0, 0, 1])\n(t, η, x) = (55, 0.033606850370453856, Bool[0, 0, 1])\n(t, η, x) = (56, 0.032262576354117556, Bool[0, 0, 1])\n(t, η, x) = (57, 0.030972073298996428, Bool[0, 0, 1])\n(t, η, x) = (58, 0.02973319036643307, Bool[0, 0, 1])\n(t, η, x) = (59, 0.028543862751395643, Bool[0, 0, 1])\n(t, η, x) = (60, 0.027402108241100898, Bool[0, 0, 1])\n(t, η, x) = (61, 0.026306023911305765, Bool[0, 0, 1])\n(t, η, x) = (62, 0.02525378295475811, Bool[0, 0, 1])\n(t, η, x) = (63, 0.02424363163650689, Bool[0, 0, 1])\n(t, η, x) = (64, 0.023273886371010022, Bool[0, 0, 1])\n(t, η, x) = (65, 0.022342930916145143, Bool[0, 0, 1])\n(t, η, x) = (66, 0.021449213679483492, Bool[0, 0, 1])\n(t, η, x) = (67, 0.020591245132295377, Bool[0, 0, 1])\n(t, η, x) = (68, 0.019767595326998233, Bool[0, 0, 1])\n(t, η, x) = (69, 0.018976891513912797, Bool[0, 0, 1])\n(t, η, x) = (70, 0.018217815853355468, Bool[0, 0, 1])\n(t, η, x) = (71, 0.017489103219220148, Bool[0, 0, 1])\n(t, η, x) = (72, 0.01678953909044978, Bool[0, 0, 1])\n(t, η, x) = (73, 0.016117957526832427, Bool[0, 0, 1])\n(t, η, x) = (74, 0.015473239225757496, Bool[0, 0, 1])\n(t, η, x) = (75, 0.014854309656726628, Bool[0, 0, 1])\n(t, η, x) = (76, 0.014260137270457385, Bool[0, 0, 1])\n(t, η, x) = (77, 0.013689731779639835, Bool[0, 0, 1])\n(t, η, x) = (78, 0.013142142508454135, Bool[0, 0, 1])\n(t, η, x) = (79, 0.012616456808116183, Bool[0, 0, 1])\n(t, η, x) = (80, 0.012111798535791252, Bool[0, 0, 1])\n(t, η, x) = (81, 0.011627326594359388, Bool[0, 0, 1])\n(t, η, x) = (82, 0.011162233530584764, Bool[0, 0, 1])\n(t, η, x) = (83, 0.010715744189361942, Bool[0, 0, 1])\n(t, η, x) = (84, 0.010287114421787535, Bool[0, 0, 1])\n(t, η, x) = (85, 0.009875629844915856, Bool[0, 0, 1])\n(t, η, x) = (86, 0.009480604651119329, Bool[0, 0, 1])\n(t, η, x) = (87, 0.009101380465074804, Bool[0, 0, 1])\n(t, η, x) = (88, 0.008737325246471528, Bool[0, 0, 1])\n(t, η, x) = (89, 0.00838783223661288, Bool[0, 0, 1])\n(t, η, x) = (90, 0.008052318947147974, Bool[0, 0, 1])\n(t, η, x) = (91, 0.007730226189262446, Bool[0, 0, 1])\n(t, η, x) = (92, 0.007421017141691522, Bool[0, 0, 1])\n(t, η, x) = (93, 0.007124176456024145, Bool[0, 0, 1])\n(t, η, x) = (94, 0.0068392093977829305, Bool[0, 0, 1])\n(t, η, x) = (95, 0.006565641021872182, Bool[0, 0, 1])\n(t, η, x) = (96, 0.006303015380996868, Bool[0, 0, 1])\n(t, η, x) = (97, 0.006050894765757597, Bool[0, 0, 1])\n(t, η, x) = (98, 0.005808858975126618, Bool[0, 0, 1])\n(t, η, x) = (99, 0.005576504616121802, Bool[0, 0, 1])\n(t, η, x) = (100, 0.005353444431476895, Bool[0, 0, 1])\n(t, η, x) = (101, 0.005139306654218245, Bool[0, 0, 1])\n(t, η, x) = (102, 0.004933734388049338, Bool[0, 0, 1])\n(t, η, x) = (103, 0.004736385012527045, Bool[0, 0, 1])\n(t, η, x) = (104, 0.004546929612025963, Bool[0, 0, 1])\n(t, η, x) = (105, 0.004365052427544924, Bool[0, 0, 1])\n(t, η, x) = (106, 0.004190450330443518, Bool[0, 0, 1])\n(t, η, x) = (107, 0.004022832317224889, Bool[0, 0, 1])\n(t, η, x) = (108, 0.0038619190245370305, Bool[0, 0, 1])\n(t, η, x) = (109, 0.0037074422635550164, Bool[0, 0, 1])\n(t, η, x) = (110, 0.0035591445730132065, Bool[0, 0, 1])\n(t, η, x) = (111, 0.0034167787900925006, Bool[0, 0, 1])\n(t, η, x) = (112, 0.0032801076384885164, Bool[0, 0, 1])\n(t, η, x) = (113, 0.00314890333294926, Bool[0, 0, 1])\n(t, η, x) = (114, 0.003022947199631254, Bool[0, 0, 1])\n(t, η, x) = (115, 0.0029020293116461815, Bool[0, 0, 1])\n(t, η, x) = (116, 0.0027859481391807606, Bool[0, 0, 1])\n(t, η, x) = (117, 0.0026745102136125354, Bool[0, 0, 1])\n(t, η, x) = (118, 0.002567529805068247, Bool[0, 0, 1])\n(t, η, x) = (119, 0.002464828612866121, Bool[0, 0, 1])\n(t, η, x) = (120, 0.002366235468350908, Bool[0, 0, 1])\n(t, η, x) = (121, 0.0022715860496171913, Bool[0, 0, 1])\n(t, η, x) = (122, 0.002180722607632468, Bool[0, 0, 1])\n(t, η, x) = (123, 0.0020934937033274537, Bool[0, 0, 1])\n(t, η, x) = (124, 0.0020097539551944266, Bool[0, 0, 1])\n(t, η, x) = (125, 0.0019293637969868271, Bool[0, 0, 1])\n(t, η, x) = (126, 0.0018521892451071054, Bool[0, 0, 1])\n(t, η, x) = (127, 0.001778101675302679, Bool[0, 0, 1])\n(t, η, x) = (128, 0.0017069776082907495, Bool[0, 0, 1])\n(t, η, x) = (129, 0.00163869850395848, Bool[0, 0, 1])\n(t, η, x) = (130, 0.0015731505638001408, Bool[0, 0, 1])\n(t, η, x) = (131, 0.001510224541248384, Bool[0, 0, 1])\n(t, η, x) = (132, 0.0014498155595985551, Bool[0, 0, 1])\n(t, η, x) = (133, 0.0013918229372151814, Bool[0, 0, 1])\n(t, η, x) = (134, 0.001336150019725757, Bool[0, 0, 1])\n(t, η, x) = (135, 0.001282704018937153, Bool[0, 0, 1])\n(t, η, x) = (136, 0.0012313958581797735, Bool[0, 0, 1])\n(t, η, x) = (137, 0.0011821400238529733, Bool[0, 0, 1])\n(t, η, x) = (138, 0.0011348544228981794, Bool[0, 0, 1])\n(t, η, x) = (139, 0.0010894602459821101, Bool[0, 0, 1])\n(t, η, x) = (140, 0.001045881836143181, Bool[0, 0, 1])\n(t, η, x) = (141, 0.0010040465626968142, Bool[0, 0, 1])\n(t, η, x) = (142, 0.0009638847001891548, Bool[0, 0, 1])\n(t, η, x) = (143, 0.0009253293121815886, Bool[0, 0, 1])\n(t, η, x) = (144, 0.0008883161396946448, Bool[0, 0, 1])\n(t, η, x) = (145, 0.0008527834941070012, Bool[0, 0, 1])\n(t, η, x) = (146, 0.0008186721543426145, Bool[0, 0, 1])\n(t, η, x) = (147, 0.0007859252681692297, Bool[0, 0, 1])\n(t, η, x) = (148, 0.0007544882574421763, Bool[0, 0, 1])\n(t, η, x) = (149, 0.0007243087271451287, Bool[0, 0, 1])\n(t, η, x) = (150, 0.0006953363780590749, Bool[0, 0, 1])\n(t, η, x) = (151, 0.0006675229229360369, Bool[0, 0, 1])\n(t, η, x) = (152, 0.000640822006019448, Bool[0, 0, 1])\n(t, η, x) = (153, 0.0006151891257779596, Bool[0, 0, 1])\n(t, η, x) = (154, 0.0005905815607469833, Bool[0, 0, 1])\n(t, η, x) = (155, 0.0005669582983172106, Bool[0, 0, 1])\n(t, η, x) = (156, 0.0005442799663848419, Bool[0, 0, 1])\n(t, η, x) = (157, 0.0005225087677294127, Bool[0, 0, 1])\n(t, η, x) = (158, 0.0005016084170197388, Bool[0, 0, 1])\n(t, η, x) = (159, 0.00048154408033962426, Bool[0, 0, 1])\n(t, η, x) = (160, 0.00046228231712586165, Bool[0, 0, 1])\n(t, η, x) = (161, 0.00044379102444036533, Bool[0, 0, 1])\n(t, η, x) = (162, 0.0004260393834636389, Bool[0, 0, 1])\n(t, η, x) = (163, 0.00040899780812431175, Bool[0, 0, 1])\n(t, η, x) = (164, 0.0003926378957999077, Bool[0, 0, 1])\n(t, η, x) = (165, 0.0003769323799680535, Bool[0, 0, 1])\n(t, η, x) = (166, 0.00036185508476904715, Bool[0, 0, 1])\n(t, η, x) = (167, 0.00034738088137853396, Bool[0, 0, 1])\n(t, η, x) = (168, 0.00033348564612278864, Bool[0, 0, 1])\n(t, η, x) = (169, 0.0003201462202779837, Bool[0, 0, 1])\n(t, η, x) = (170, 0.00030734037146729065, Bool[0, 0, 1])\n(t, η, x) = (171, 0.00029504675660785296, Bool[0, 0, 1])\n(t, η, x) = (172, 0.00028324488634368095, Bool[0, 0, 1])\n(t, η, x) = (173, 0.00027191509089075083, Bool[0, 0, 1])\n(t, η, x) = (174, 0.0002610384872543392, Bool[0, 0, 1])\n(t, η, x) = (175, 0.0002505969477644143, Bool[0, 0, 1])\n(t, η, x) = (176, 0.00024057306985358906, Bool[0, 0, 1])\n(t, η, x) = (177, 0.00023095014705987182, Bool[0, 0, 1])\n(t, η, x) = (178, 0.00022171214117783222, Bool[0, 0, 1])\n(t, η, x) = (179, 0.00021284365553064788, Bool[0, 0, 1])\n(t, η, x) = (180, 0.00020432990930885353, Bool[0, 0, 1])\n(t, η, x) = (181, 0.00019615671293671255, Bool[0, 0, 1])\n(t, η, x) = (182, 0.00018831044441913747, Bool[0, 0, 1])\n(t, η, x) = (183, 0.00018077802664251408, Bool[0, 0, 1])\n(t, η, x) = (184, 0.00017354690557702668, Bool[0, 0, 1])\n(t, η, x) = (185, 0.00016660502935383903, Bool[0, 0, 1])\n(t, η, x) = (186, 0.00015994082817982758, Bool[0, 0, 1])\n(t, η, x) = (187, 0.00015354319505256342, Bool[0, 0, 1])\n(t, η, x) = (188, 0.00014740146725067405, Bool[0, 0, 1])\n(t, η, x) = (189, 0.00014150540856050497, Bool[0, 0, 1])\n(t, η, x) = (190, 0.00013584519221776503, Bool[0, 0, 1])\n(t, η, x) = (191, 0.00013041138452951628, Bool[0, 0, 1])\n(t, η, x) = (192, 0.00012519492914808694, Bool[0, 0, 1])\n(t, η, x) = (193, 0.00012018713198269637, Bool[0, 0, 1])\n(t, η, x) = (194, 0.0001153796467034951, Bool[0, 0, 1])\n(t, η, x) = (195, 0.00011076446083446712, Bool[0, 0, 1])\n(t, η, x) = (196, 0.0001063338824014437, Bool[0, 0, 1])\n(t, η, x) = (197, 0.00010208052710503068, Bool[0, 0, 1])\n(t, η, x) = (198, 9.799730602111367e-5, Bool[0, 0, 1])\n(t, η, x) = (199, 9.407741378097967e-5, Bool[0, 0, 1])\n(t, η, x) = (200, 9.031431722927863e-5, Bool[0, 0, 1])\n(t, η, x) = (201, 8.670174454028512e-5, Bool[0, 0, 1])\n(t, η, x) = (202, 8.323367475870924e-5, Bool[0, 0, 1])\n(t, η, x) = (203, 7.990432776772138e-5, Bool[0, 0, 1])\n(t, η, x) = (204, 7.670815465754544e-5, Bool[0, 0, 1])\n(t, η, x) = (205, 7.363982847152784e-5, Bool[0, 0, 1])\n(t, η, x) = (206, 7.069423533234698e-5, Bool[0, 0, 1])\n(t, η, x) = (207, 6.78664659190531e-5, Bool[0, 0, 1])\n(t, η, x) = (208, 6.515180728250414e-5, Bool[0, 0, 1])\n(t, η, x) = (209, 6.254573499120397e-5, Bool[0, 0, 1])\n(t, η, x) = (210, 6.004390559155581e-5, Bool[0, 0, 1])\n(t, η, x) = (211, 5.764214936743173e-5, Bool[0, 0, 1])\n(t, η, x) = (212, 5.533646339284104e-5, Bool[0, 0, 1])\n(t, η, x) = (213, 5.312300485726951e-5, Bool[0, 0, 1])\n(t, η, x) = (214, 5.099808466368927e-5, Bool[0, 0, 1])\n(t, η, x) = (215, 4.895816127614694e-5, Bool[0, 0, 1])\n(t, η, x) = (216, 4.6999834825811604e-5, Bool[0, 0, 1])\n(t, η, x) = (217, 4.5119841431962016e-5, Bool[0, 0, 1])\n(t, η, x) = (218, 4.331504777521644e-5, Bool[0, 0, 1])\n(t, η, x) = (219, 4.158244586438542e-5, Bool[0, 0, 1])\n(t, η, x) = (220, 3.991914802981e-5, Bool[0, 0, 1])\n(t, η, x) = (221, 3.832238210854655e-5, Bool[0, 0, 1])\n(t, η, x) = (222, 3.678948682406258e-5, Bool[0, 0, 1])\n(t, η, x) = (223, 3.531790735156193e-5, Bool[0, 0, 1])\n(t, η, x) = (224, 3.390519105739287e-5, Bool[0, 0, 1])\n(t, η, x) = (225, 3.254898341431556e-5, Bool[0, 0, 1])\n(t, η, x) = (226, 3.124702407841795e-5, Bool[0, 0, 1])\n(t, η, x) = (227, 2.9997143115245706e-5, Bool[0, 0, 1])\n(t, η, x) = (228, 2.879725739024508e-5, Bool[0, 0, 1])\n(t, η, x) = (229, 2.764536709509713e-5, Bool[0, 0, 1])\n(t, η, x) = (230, 2.653955241083139e-5, Bool[0, 0, 1])\n(t, η, x) = (231, 2.547797031482446e-5, Bool[0, 0, 1])\n(t, η, x) = (232, 2.445885150237359e-5, Bool[0, 0, 1])\n(t, η, x) = (233, 2.348049744149705e-5, Bool[0, 0, 1])\n(t, η, x) = (234, 2.2541277544974037e-5, Bool[0, 0, 1])\n(t, η, x) = (235, 2.163962644274875e-5, Bool[0, 0, 1])\n(t, η, x) = (236, 2.077404138489669e-5, Bool[0, 0, 1])\n(t, η, x) = (237, 1.9943079729856095e-5, Bool[0, 0, 1])\n(t, η, x) = (238, 1.9145356541017122e-5, Bool[0, 0, 1])\n(t, η, x) = (239, 1.837954227923433e-5, Bool[0, 0, 1])\n(t, η, x) = (240, 1.7644360586821506e-5, Bool[0, 0, 1])\n(t, η, x) = (241, 1.693858616391708e-5, Bool[0, 0, 1])\n(t, η, x) = (242, 1.626104271768014e-5, Bool[0, 0, 1])\n(t, η, x) = (243, 1.5610601009186098e-5, Bool[0, 0, 1])\n(t, η, x) = (244, 1.4986176968712073e-5, Bool[0, 0, 1])\n(t, η, x) = (245, 1.4386729890070171e-5, Bool[0, 0, 1])\n(t, η, x) = (246, 1.3811260694218674e-5, Bool[0, 0, 1])\n(t, η, x) = (247, 1.3258810266592036e-5, Bool[0, 0, 1])\n(t, η, x) = (248, 1.272845785660337e-5, Bool[0, 0, 1])\n(t, η, x) = (249, 1.2219319541983964e-5, Bool[0, 0, 1])\n(t, η, x) = (250, 1.173054676062435e-5, Bool[0, 0, 1])\n(t, η, x) = (251, 1.1261324889488833e-5, Bool[0, 0, 1])\n(t, η, x) = (252, 1.0810871893696117e-5, Bool[0, 0, 1])\n(t, η, x) = (253, 1.037843701823249e-5, Bool[0, 0, 1])\n(t, η, x) = (254, 9.963299537396608e-6, Bool[0, 0, 1])\n(t, η, x) = (255, 9.564767555758635e-6, Bool[0, 0, 1])\n(t, η, x) = (256, 9.182176854416468e-6, Bool[0, 0, 1])\n(t, η, x) = (257, 8.814889779884538e-6, Bool[0, 0, 1])\n(t, η, x) = (258, 8.462294188937847e-6, Bool[0, 0, 1])\n(t, η, x) = (259, 8.123802420989534e-6, Bool[0, 0, 1])\n(t, η, x) = (260, 7.798850323759154e-6, Bool[0, 0, 1])\n(t, η, x) = (261, 7.48689631091537e-6, Bool[0, 0, 1])\n(t, η, x) = (262, 7.187420458798499e-6, Bool[0, 0, 1])\n(t, η, x) = (263, 6.899923640446559e-6, Bool[0, 0, 1])\n(t, η, x) = (264, 6.623926695148441e-6, Bool[0, 0, 1])\n(t, η, x) = (265, 6.358969627306976e-6, Bool[0, 0, 1])\n(t, η, x) = (266, 6.104610841717317e-6, Bool[0, 0, 1])\n(t, η, x) = (267, 5.860426408155206e-6, Bool[0, 0, 1])\n(t, η, x) = (268, 5.626009351722416e-6, Bool[0, 0, 1])\n(t, η, x) = (269, 5.400968977831155e-6, Bool[0, 0, 1])\n(t, η, x) = (270, 5.184930219392925e-6, Bool[0, 0, 1])\n(t, η, x) = (271, 4.9775330097645565e-6, Bool[0, 0, 1])\n(t, η, x) = (272, 4.7784316894450285e-6, Bool[0, 0, 1])\n(t, η, x) = (273, 4.587294422542243e-6, Bool[0, 0, 1])\n(t, η, x) = (274, 4.403802645214228e-6, Bool[0, 0, 1])\n(t, η, x) = (275, 4.227650539867511e-6, Bool[0, 0, 1])\n(t, η, x) = (276, 4.058544517349105e-6, Bool[0, 0, 1])\n(t, η, x) = (277, 3.896202737330157e-6, Bool[0, 0, 1])\n(t, η, x) = (278, 3.7403546278014232e-6, Bool[0, 0, 1])\n(t, η, x) = (279, 3.5907404427604206e-6, Bool[0, 0, 1])\n(t, η, x) = (280, 3.447110824339461e-6, Bool[0, 0, 1])\n(t, η, x) = (281, 3.309226392467224e-6, Bool[0, 0, 1])\n(t, η, x) = (282, 3.176857336306682e-6, Bool[0, 0, 1])\n(t, η, x) = (283, 3.0497830429965234e-6, Bool[0, 0, 1])\n(t, η, x) = (284, 2.9277917210634996e-6, Bool[0, 0, 1])\n(t, η, x) = (285, 2.8106800522564868e-6, Bool[0, 0, 1])\n(t, η, x) = (286, 2.6982528504859715e-6, Bool[0, 0, 1])\n(t, η, x) = (287, 2.5903227367507498e-6, Bool[0, 0, 1])\n(t, η, x) = (288, 2.486709827387301e-6, Bool[0, 0, 1])\n(t, η, x) = (289, 2.3872414338654835e-6, Bool[0, 0, 1])\n(t, η, x) = (290, 2.2917517767950812e-6, Bool[0, 0, 1])\n(t, η, x) = (291, 2.2000817052614252e-6, Bool[0, 0, 1])\n(t, η, x) = (292, 2.112078437477294e-6, Bool[0, 0, 1])\n(t, η, x) = (293, 2.027595299658458e-6, Bool[0, 0, 1])\n(t, η, x) = (294, 1.9464914879918638e-6, Bool[0, 0, 1])\n(t, η, x) = (295, 1.8686318279392822e-6, Bool[0, 0, 1])\n(t, η, x) = (296, 1.793886554857238e-6, Bool[0, 0, 1])\n(t, η, x) = (297, 1.7221310928405842e-6, Bool[0, 0, 1])\n(t, η, x) = (298, 1.6532458495532865e-6, Bool[0, 0, 1])\n(t, η, x) = (299, 1.5871160155001007e-6, Bool[0, 0, 1])\n(t, η, x) = (300, 1.5236313748445696e-6, Bool[0, 0, 1])\n(t, η, x) = (301, 1.462686118891554e-6, Bool[0, 0, 1])\n(t, η, x) = (302, 1.404178674668799e-6, Bool[0, 0, 1])\n(t, η, x) = (303, 1.348011528179427e-6, Bool[0, 0, 1])\n(t, η, x) = (304, 1.29409106630618e-6, Bool[0, 0, 1])\n(t, η, x) = (305, 1.2423274240447313e-6, Bool[0, 0, 1])\n(t, η, x) = (306, 1.1926343272961049e-6, Bool[0, 0, 1])\n(t, η, x) = (307, 1.144928954310842e-6, Bool[0, 0, 1])\n(t, η, x) = (308, 1.0991317962449898e-6, Bool[0, 0, 1])\n(t, η, x) = (309, 1.0551665239333374e-6, Bool[0, 0, 1])\n(t, η, x) = (310, 1.0129598635444381e-6, Bool[0, 0, 1])\n(t, η, x) = (311, 9.724414686829164e-7, Bool[0, 0, 1])\n(t, η, x) = (312, 9.335438102553439e-7, Bool[0, 0, 1])\n(t, η, x) = (313, 8.962020574543317e-7, Bool[0, 0, 1])\n(t, η, x) = (314, 8.603539756180112e-7, Bool[0, 0, 1])\n(t, η, x) = (315, 8.259398169840892e-7, Bool[0, 0, 1])\n(t, η, x) = (316, 7.929022238784e-7, Bool[0, 0, 1])\n(t, η, x) = (317, 7.611861354561711e-7, Bool[0, 0, 1])\n(t, η, x) = (318, 7.307386891142187e-7, Bool[0, 0, 1])\n(t, η, x) = (319, 7.015091414430685e-7, Bool[0, 0, 1])\n(t, η, x) = (320, 6.734487758564001e-7, Bool[0, 0, 1])\n(t, η, x) = (321, 6.46510825319524e-7, Bool[0, 0, 1])\n(t, η, x) = (322, 6.20650391525146e-7, Bool[0, 0, 1])\n(t, η, x) = (323, 5.958243756154502e-7, Bool[0, 0, 1])\n(t, η, x) = (324, 5.719914009105764e-7, Bool[0, 0, 1])\n(t, η, x) = (325, 5.491117454070604e-7, Bool[0, 0, 1])\n(t, η, x) = (326, 5.271472760526308e-7, Bool[0, 0, 1])\n(t, η, x) = (327, 5.060613839091843e-7, Bool[0, 0, 1])\n(t, η, x) = (328, 4.85818929085724e-7, Bool[0, 0, 1])\n(t, η, x) = (329, 4.663861723486207e-7, Bool[0, 0, 1])\n(t, η, x) = (330, 4.4773072449544316e-7, Bool[0, 0, 1])\n(t, η, x) = (331, 4.2982149572878825e-7, Bool[0, 0, 1])\n(t, η, x) = (332, 4.126286361483267e-7, Bool[0, 0, 1])\n(t, η, x) = (333, 3.9612349134188207e-7, Bool[0, 0, 1])\n(t, η, x) = (334, 3.8027855087108264e-7, Bool[0, 0, 1])\n(t, η, x) = (335, 3.650674091915107e-7, Bool[0, 0, 1])\n(t, η, x) = (336, 3.504647132501759e-7, Bool[0, 0, 1])\n(t, η, x) = (337, 3.3644612429384324e-7, Bool[0, 0, 1])\n(t, η, x) = (338, 3.229882796773609e-7, Bool[0, 0, 1])\n(t, η, x) = (339, 3.100687484547393e-7, Bool[0, 0, 1])\n(t, η, x) = (340, 2.9766599851654973e-7, Bool[0, 0, 1])\n(t, η, x) = (341, 2.8575935839825206e-7, Bool[0, 0, 1])\n(t, η, x) = (342, 2.7432898441759335e-7, Bool[0, 0, 1])\n(t, η, x) = (343, 2.63355825147471e-7, Bool[0, 0, 1])\n(t, η, x) = (344, 2.528215912178666e-7, Bool[0, 0, 1])\n(t, η, x) = (345, 2.427087277823148e-7, Bool[0, 0, 1])\n(t, η, x) = (346, 2.3300037899076642e-7, Bool[0, 0, 1])\n(t, η, x) = (347, 2.2368036400877145e-7, Bool[0, 0, 1])\n(t, η, x) = (348, 2.1473314948394773e-7, Bool[0, 0, 1])\n(t, η, x) = (349, 2.061438237888069e-7, Bool[0, 0, 1])\n(t, η, x) = (350, 1.9789807126358028e-7, Bool[0, 0, 1])\n(t, η, x) = (351, 1.8998214734722296e-7, Bool[0, 0, 1])\n(t, η, x) = (352, 1.82382861702024e-7, Bool[0, 0, 1])\n(t, η, x) = (353, 1.7508754801554005e-7, Bool[0, 0, 1])\n(t, η, x) = (354, 1.6808404534884858e-7, Bool[0, 0, 1])\n(t, η, x) = (355, 1.6136068392569314e-7, Bool[0, 0, 1])\n(t, η, x) = (356, 1.5490625671077396e-7, Bool[0, 0, 1])\n(t, η, x) = (357, 1.4871000608707163e-7, Bool[0, 0, 1])\n(t, η, x) = (358, 1.4276160609227873e-7, Bool[0, 0, 1])\n(t, η, x) = (359, 1.370511411025177e-7, Bool[0, 0, 1])\n(t, η, x) = (360, 1.3156909606237832e-7, Bool[0, 0, 1])\n(t, η, x) = (361, 1.2630633250410028e-7, Bool[0, 0, 1])\n(t, η, x) = (362, 1.2125407877761063e-7, Bool[0, 0, 1])\n(t, η, x) = (363, 1.1640391583966903e-7, Bool[0, 0, 1])\n(t, η, x) = (364, 1.1174775949029936e-7, Bool[0, 0, 1])\n(t, η, x) = (365, 1.0727784882647029e-7, Bool[0, 0, 1])\n(t, η, x) = (366, 1.029867346957758e-7, Bool[0, 0, 1])\n(t, η, x) = (367, 9.886726548558045e-8, Bool[0, 0, 1])\n(t, η, x) = (368, 9.491257468852154e-8, Bool[0, 0, 1])\n(t, η, x) = (369, 9.111607202072491e-8, Bool[0, 0, 1])\n(t, η, x) = (370, 8.747142921095019e-8, Bool[0, 0, 1])\n(t, η, x) = (371, 8.397257200698505e-8, Bool[0, 0, 1])\n(t, η, x) = (372, 8.061366862932573e-8, Bool[0, 0, 1])\n(t, η, x) = (373, 7.738912266574971e-8, Bool[0, 0, 1])\n(t, η, x) = (374, 7.429355797228254e-8, Bool[0, 0, 1])\n(t, η, x) = (375, 7.132181512048419e-8, Bool[0, 0, 1])\n(t, η, x) = (376, 6.846894251566482e-8, Bool[0, 0, 1])\n(t, η, x) = (377, 6.573018485056537e-8, Bool[0, 0, 1])\n(t, η, x) = (378, 6.310097777628698e-8, Bool[0, 0, 1])\n(t, η, x) = (379, 6.057693902050687e-8, Bool[0, 0, 1])\n(t, η, x) = (380, 5.815386039387249e-8, Bool[0, 0, 1])\n(t, η, x) = (381, 5.582770601364473e-8, Bool[0, 0, 1])\n(t, η, x) = (382, 5.359459809284317e-8, Bool[0, 0, 1])\n(t, η, x) = (383, 5.1450814275710854e-8, Bool[0, 0, 1])\n(t, η, x) = (384, 4.9392781420465326e-8, Bool[0, 0, 1])\n(t, η, x) = (385, 4.741707027022812e-8, Bool[0, 0, 1])\n(t, η, x) = (386, 4.5520387459419e-8, Bool[0, 0, 1])\n(t, η, x) = (387, 4.369957196104224e-8, Bool[0, 0, 1])\n(t, η, x) = (388, 4.195158886943773e-8, Bool[0, 0, 1])\n(t, η, x) = (389, 4.027352584756727e-8, Bool[0, 0, 1])\n(t, η, x) = (390, 3.866258513340881e-8, Bool[0, 0, 1])\n(t, η, x) = (391, 3.7116080875421176e-8, Bool[0, 0, 1])\n(t, η, x) = (392, 3.5631438244365654e-8, Bool[0, 0, 1])\n(t, η, x) = (393, 3.42061801106297e-8, Bool[0, 0, 1])\n(t, η, x) = (394, 3.283793326147588e-8, Bool[0, 0, 1])\n(t, η, x) = (395, 3.1524415966543984e-8, Bool[0, 0, 1])\n(t, η, x) = (396, 3.0263439754207866e-8, Bool[0, 0, 1])\n(t, η, x) = (397, 2.90529023061481e-8, Bool[0, 0, 1])\n(t, η, x) = (398, 2.7890785680995123e-8, Bool[0, 0, 1])\n(t, η, x) = (399, 2.6775154537972412e-8, Bool[0, 0, 1])\n(t, η, x) = (400, 2.5704148143290695e-8, Bool[0, 0, 1])\n(t, η, x) = (401, 2.4675982146504793e-8, Bool[0, 0, 1])\n(t, η, x) = (402, 2.3688943251443106e-8, Bool[0, 0, 1])\n(t, η, x) = (403, 2.274138477531551e-8, Bool[0, 0, 1])\n(t, η, x) = (404, 2.1831730201427035e-8, Bool[0, 0, 1])\n(t, η, x) = (405, 2.0958460744679996e-8, Bool[0, 0, 1])\n(t, η, x) = (406, 2.0120122457001344e-8, Bool[0, 0, 1])\n(t, η, x) = (407, 1.931531734555847e-8, Bool[0, 0, 1])\n(t, η, x) = (408, 1.8542705149116046e-8, Bool[0, 0, 1])\n(t, η, x) = (409, 1.7800996232608668e-8, Bool[0, 0, 1])\n(t, η, x) = (410, 1.7088956916211373e-8, Bool[0, 0, 1])\n(t, η, x) = (411, 1.6405397929020182e-8, Bool[0, 0, 1])\n(t, η, x) = (412, 1.574918240265788e-8, Bool[0, 0, 1])\n(t, η, x) = (413, 1.5119215213132975e-8, Bool[0, 0, 1])\n(t, η, x) = (414, 1.4514446533553382e-8, Bool[0, 0, 1])\n(t, η, x) = (415, 1.3933869169591162e-8, Bool[0, 0, 1])\n(t, η, x) = (416, 1.3376514118590421e-8, Bool[0, 0, 1])\n(t, η, x) = (417, 1.2841453234102573e-8, Bool[0, 0, 1])\n(t, η, x) = (418, 1.2327795673172659e-8, Bool[0, 0, 1])\n(t, η, x) = (419, 1.1834683455447248e-8, Bool[0, 0, 1])\n(t, η, x) = (420, 1.1361295904066537e-8, Bool[0, 0, 1])\n(t, η, x) = (421, 1.0906844316593833e-8, Bool[0, 0, 1])\n(t, η, x) = (422, 1.0470570188658712e-8, Bool[0, 0, 1])\n(t, η, x) = (423, 1.0051747878492279e-8, Bool[0, 0, 1])\n\n\n(V_U = [4.066009442589008, 4.066009442589008, 6.740345591111497], V_E = [-9.339396498834146, 0.9595072017084403, 7.743221646807431])",
    "crumbs": [
      "Tutorials",
      "McCall Model"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Macro: Numerical Methods",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\n\n\n\n\nFeb 6, 2025\n\n\nIntroduction\n\n\n\n\nFeb 20, 2025\n\n\nConvergence of Sequences\n\n\n\n\nMar 6, 2025\n\n\nPerturbation Analysis\n\n\n\n\nMar 21, 2025\n\n\nOptimization\n\n\n\n\nApr 3, 2025\n\n\nDiscrete Dynamic Programming\n\n\n\n\nApr 17, 2025\n\n\nDiscretization\n\n\n\n\nApr 17, 2025\n\n\nInterpolation\n\n\n\n\nApr 17, 2025\n\n\nTime Iteration\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#indicative-schedule",
    "href": "index.html#indicative-schedule",
    "title": "Advanced Macro: Numerical Methods",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\n\n\n\n\nFeb 6, 2025\n\n\nIntroduction\n\n\n\n\nFeb 20, 2025\n\n\nConvergence of Sequences\n\n\n\n\nMar 6, 2025\n\n\nPerturbation Analysis\n\n\n\n\nMar 21, 2025\n\n\nOptimization\n\n\n\n\nApr 3, 2025\n\n\nDiscrete Dynamic Programming\n\n\n\n\nApr 17, 2025\n\n\nDiscretization\n\n\n\n\nApr 17, 2025\n\n\nInterpolation\n\n\n\n\nApr 17, 2025\n\n\nTime Iteration\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#communication",
    "href": "index.html#communication",
    "title": "Advanced Macro: Numerical Methods",
    "section": "Communication",
    "text": "Communication\n\nZulip (best)\nEmail to pwinant@escp.eu starting with [mie37]\nGithub issues (PR also welcome)"
  },
  {
    "objectID": "index.html#assessments",
    "href": "index.html#assessments",
    "title": "Advanced Macro: Numerical Methods",
    "section": "Assessments",
    "text": "Assessments\n\ntutorials (optional) + projects (mandatory) (50%)\nfinal exam (50%)"
  },
  {
    "objectID": "slides/time_iteration.html#whats-new-today",
    "href": "slides/time_iteration.html#whats-new-today",
    "title": "Time Iteration",
    "section": "What’s new today?",
    "text": "What’s new today?\n\nThe nature of the problem:\n\nLast time we did discrete dynamic programming: \\(S\\) and \\(X\\) finite\nToday both are continuous: approximate dynamic programming\n\ntoday, we have continuous decision rules\nwe will need to discretize and interpolate\n\n\nThe representation of the model\n\nWe used the Bellman representation\nToday we use first order representation (Euler and co.)\n\nThe solution metod:\n\nWe will see the main time-iteration algorithms",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#whats-new-today-1",
    "href": "slides/time_iteration.html#whats-new-today-1",
    "title": "Time Iteration",
    "section": "What’s new today?",
    "text": "What’s new today?\n\nA few weeks ago, we did discrete dynamic programming\n\ntoday, we have continuous decision rules\nwe will need to interpolate\n\nWe were using Bellman representation\n\nwe’ll use first order representation (Euler and co.)\n\nWe will see the main time-iteration algorithms\n\nand mention some of its variants",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#generic-value-function-representation",
    "href": "slides/time_iteration.html#generic-value-function-representation",
    "title": "Time Iteration",
    "section": "Generic Value Function Representation",
    "text": "Generic Value Function Representation\n\nAll variables of the model are vectors:\n\nstates \\(s \\in \\mathcal{S} \\subset R^{n_s}\\)\ncontrols \\(x \\in \\mathcal{F}(\\mathcal{S}, R^{n_x})\\)\n\nwe assume bounds \\(a(s)\\leq x \\leq b(s)\\)\n\nshocks: \\(\\epsilon \\sim \\text{i.i.d. distrib}\\)\n\nTransition: \\[s_{t+1} = g(s_t, x_t, \\epsilon_{t+1})\\]\nValue function: \\[V(s) = E_0 \\sum_{t\\geq 0} \\beta^t \\left[ U(s_t, x_t)\\right]\\]\nSolution is a function \\(V()\\) (value) which is a fixed point of the Bellman-operator: \\[\\forall s, V(s) = \\max_{a(s)\\leq x \\leq b(s)} U(s,x) + \\beta E \\left[ V(g(s,x,\\epsilon)) \\right]\\]\nThe argmax, defines a decision rule function: \\(x = \\varphi(s)\\)",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#first-order-representation",
    "href": "slides/time_iteration.html#first-order-representation",
    "title": "Time Iteration",
    "section": "First order representation",
    "text": "First order representation\n\n\n\nAll variables of the model are vectors:\n\nstates \\(s_t\\)\ncontrols \\(x_t\\)\n\nwe assume bounds \\(a(s)\\leq x \\leq b(s)\\)\n\nshocks: \\(\\epsilon_t\\) (i.i.d. random law)\n\nTransition: \\[s_{t+1} = g(s_t, x_t, \\epsilon_{t+1})\\]\nDecision rule: \\[x_t = \\varphi(s_t)\\]\nArbitrage: \\[ E_t\\left[ f(s_t, x_t, s_{t+1}, x_{t+1}) \\right] = 0 \\perp a(s_t) \\leq x_t \\leq b(s_t) \\]\n\n\n\nThese equations must be true for any \\(s_t\\).\nRemark: time subscript are conventional. They are used to precise:\n\nwhen expectation is taken (w.r.t \\(\\epsilon_{t+1}\\))\nto avoid repeating \\(x_t=\\varphi(s_t)\\) and \\(x_{t+1} = \\varphi(s_t)\\)\n\nSometimes there are bounds on the controls\n\nwe encode them with complementarity constraints\nmore on it later",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#example-1-neoclassical-growth-model",
    "href": "slides/time_iteration.html#example-1-neoclassical-growth-model",
    "title": "Time Iteration",
    "section": "Example 1: neoclassical growth model",
    "text": "Example 1: neoclassical growth model\n\n\n\ncapital accumulation: \\[k_t = (1-\\delta)k_{t-1} + i_{t-1}\\]\nproduction: \\[y_t = k_t^\\alpha\\]\nconsumption: \\[c_t = (1-s_t) y_t\\] \\[i_t = s_t y_t\\]\noptimality: \\[\\beta E_t \\left[ \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_{t})} (1-\\delta + \\alpha k_{t+1}^{\\alpha-1}\\alpha) \\right]= 1\\]\n\n\n\nstates: \\(k_t\\), with one transition equation\ncontrols: \\(y_t, c_t, i_t, s_t\\), with four “arbitrage” equations\n\nit is possible but not mandatory to reduce the number of variables/equations by simple susbtitutions",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#example-2-consumption-savings-model",
    "href": "slides/time_iteration.html#example-2-consumption-savings-model",
    "title": "Time Iteration",
    "section": "Example 2: consumption-savings model",
    "text": "Example 2: consumption-savings model\n\n\nSimplest consumption/savings model:\n\nTransition: \\[w_t = \\exp(\\epsilon_t) + (w_{t-1} - c_{t-1}) \\overline{r}\\]\nObjective: \\[\\max_{0\\leq c_t \\leq w_t} E_0 \\left[ \\sum \\beta^t U(c_t) \\right]\\]\nFirst order conditions: \\[\\beta E_t \\left[  \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_t)} \\overline{r} \\right] - 1 \\perp 0 \\leq c_t \\leq w_t\\]\n\n\n\nF.O.C. reads as: \\[\\beta E_t \\left[  \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_t)} \\overline{r} \\right] - 1 \\leq 0 \\perp c_t \\leq w_t\\] and \\[0 \\leq \\beta E_t \\left[  \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_t)} \\overline{r} \\right] - 1  \\perp 0 \\leq c_t \\]\nFirst one reads: if my marginal utility of consumption today is higher than expected mg. utility of cons. tomorrow, I’d like to consume more, but I can’t because, consumption is bounded by income (and no-borrowing constraint).\nSecond one reads: only way I could tolerate higher utility in the present, than in the future, would be if I want dissave more than I can, or equivalently, consume less than zero. This is never happening.",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#example-3-new-keynesian-with-without-zlb",
    "href": "slides/time_iteration.html#example-3-new-keynesian-with-without-zlb",
    "title": "Time Iteration",
    "section": "Example 3: new-keynesian with / without ZLB",
    "text": "Example 3: new-keynesian with / without ZLB\n\n\nConsider the new keynesian model we have seen in the introduction:\n\nAssume \\(z_t\\) is an autocorrelated shock: \\[z_t = \\rho z_{t-1} + \\epsilon_t\\]\nNew philips curve (PC):\\[\\pi_t = \\beta \\mathbb{E}_t \\pi_{t+1} + \\kappa y_t\\]\ndynamic investment-saving equation (IS):\\[y_t = \\beta \\mathbb{E}_t y_{t+1} - \\frac{1}{\\sigma}(i_t - \\mathbb{E}_t(\\pi_{t+1}) ) - {\\color{green} z_t}\\]\nInterest Rate Setting (taylor rule): \\[i_t = \\alpha_{\\pi} \\pi_t + \\alpha_{y} y_t\\]\n\n\n\nThe model satisfies the same specification with:\n\none state \\(z_t\\) and one transition equation\nthree controls: \\(\\pi_t\\), \\(y_t\\) and \\(i_t\\) with three “arbitrage” equation\n\nThese are not real first order conditions as they are not derived from a maximization program\n\nunless one tries to microfound them…\n\nIt is possible to add a zero-lower bound constraint by replacing IRS with: \\[ \\alpha_{\\pi} \\pi_t + \\alpha_{y} y_t \\leq i_t \\perp 0 \\leq i_t\\]",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#time-iteration-1",
    "href": "slides/time_iteration.html#time-iteration-1",
    "title": "Time Iteration",
    "section": "Time iteration",
    "text": "Time iteration\n\nSo we have the equation, \\(\\forall s_t\\)\n\n\\[ E_t\\left[ f(s_t, x_t, s_{t+1}, x_{t+1}) \\right] = 0 \\perp a(s_t) \\leq x_t \\leq b(s_t)\\]\\[ E_t\\left[ f(s_t, x_t, s_{t+1}, x_{t+1}) \\right] = 0\\]\n\nwhere \\[s_{t+1} = g(s_t, x_t, \\epsilon_{t+1})\\] \\[x_t = \\varphi(s_t)\\] \\[x_{t+1} = \\tilde{\\varphi}(s_{t+1})\\]\nLet’s leave the complementarity conditions aside for now\nIn equilibrium \\(\\tilde{\\varphi} = {\\varphi}\\)",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#time-iteration-2",
    "href": "slides/time_iteration.html#time-iteration-2",
    "title": "Time Iteration",
    "section": "Time iteration",
    "text": "Time iteration\n\nWe can rewrite everything as one big functional equation: \\[\\forall s, \\Phi(\\varphi, \\tilde{\\varphi})(s) = E\\left[ f(s, \\varphi(s), g(s,\\varphi(s), \\epsilon), \\tilde{\\varphi}(g(s,\\varphi(s), \\epsilon)) \\right]\\]\nA solution is \\(\\varphi\\) such that \\(\\Phi(\\varphi, \\varphi) = 0\\)\nThe Coleman operator \\(\\mathcal{T}\\) is defined implicitly by: \\[\\Phi(\\mathcal{T}(\\varphi), \\varphi)=0\\]\nThe core of the time iteration algorithm, consists in the recursion: \\[\\varphi_{n+1} = \\mathcal{T}(\\varphi_n)\\]\nIt maps future decision rules to current decision rules\n\nsame as “linear time iterations”, remember?\n\nSounds fun but how do we implement it concretely?",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#practical-implementation",
    "href": "slides/time_iteration.html#practical-implementation",
    "title": "Time Iteration",
    "section": "Practical implementation",
    "text": "Practical implementation\n\nWe need to find a way to:\n\ncompute expectations\nrepresent decision rules \\(\\varphi\\) and \\(\\varphi\\) with a finite number of parameters",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#practical-implementation-2",
    "href": "slides/time_iteration.html#practical-implementation-2",
    "title": "Time Iteration",
    "section": "Practical implementation (2)",
    "text": "Practical implementation (2)\n\nComputing expectations:\n\ndiscretize shock \\(\\epsilon\\) with finite quantization \\((w_i, e_i)_{i=1:K}\\)\nreplace optimality condition with: \\[\\forall s, \\Phi(\\varphi, \\tilde{\\varphi})(s) = \\sum_i w_i f(s, \\varphi(s), g(s,\\varphi(s), e_i), \\tilde{\\varphi}(g(s,\\varphi(s), e_i)) \\]\n\n… but we still can’t compute all the \\(\\varphi\\)",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#approximating-decision-rules",
    "href": "slides/time_iteration.html#approximating-decision-rules",
    "title": "Time Iteration",
    "section": "Approximating decision rules",
    "text": "Approximating decision rules\n\nWe’ll limit ourselves to interpolating functional spaces\n\nWe define a finite grid \\(\\mathbf{s}=(s_1, ... s_N)\\) to approximate the state space (\\(\\mathbf{s}\\) is a finite vector of points)\nIf we know the vector of values \\(\\mathbf{x}=(x_1, ..., x_N)\\) a function \\(\\varphi\\) takes on \\(\\mathbf{s}\\), we approximate \\(\\varphi\\) at any \\(s\\) using an interpolation scheme \\(\\mathcal{I}\\): \\[\\varphi(s) \\approx \\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\]\n\nNow if we replace \\(\\varphi\\) by \\(\\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\) and \\(\\tilde{\\varphi}\\) by \\(\\mathcal{I}(s, \\mathbf{s}, \\mathbf{\\tilde{x}})\\) the functional equation becomes: \\[\\forall s,  \\Phi(\\varphi, \\tilde{\\varphi})(s) \\approx F( \\mathbf{x}, \\mathbf{\\tilde{x}} )(s) = \\sum_i w_i f(s, x, \\tilde{s}, \\tilde{x})\\] where \\[x = \\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\] \\[\\tilde{s} = g(s, x, e_i)\\] \\[\\tilde{x} = \\mathcal{I}(s, \\mathbf{s}, \\mathbf{\\tilde{x}})\\]",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#pinning-down-decision-rules",
    "href": "slides/time_iteration.html#pinning-down-decision-rules",
    "title": "Time Iteration",
    "section": "Pinning down decision rules",
    "text": "Pinning down decision rules\n\nNote that this equation must be statisfied \\(\\forall s\\).\nIn order to pin-down the \\(N\\) coefficients \\(\\mathbf{x}\\), it is enough to satisfy the equations at \\(N\\) different points.\nHence we solve the square system: \\[\\forall i\\in [1,N], F( \\mathbf{x}, \\mathbf{\\tilde{x}} )(s_i) = 0\\]\nIn vectorized form, this is just: \\[F( \\mathbf{x}, \\mathbf{\\tilde{x}} )(\\mathbf{s}) = 0\\]\nOr, since grid \\(\\mathbf{s}\\) is fixed: \\[F( \\mathbf{x}, \\mathbf{\\tilde{x}} ) = 0\\]\nNow the vector of decisions today, at each point of the grid, is determined as a function of the vector of decisions tomorrow, on the same grid.",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#recap",
    "href": "slides/time_iteration.html#recap",
    "title": "Time Iteration",
    "section": "Recap",
    "text": "Recap\n\nChoose a finite grid for states \\(\\mathbf{s} = (s_1, ..., s_N)\\)\nFor a given vector of controls tomorrow \\(\\mathbf{\\tilde{x}}\\), one can compute theoptimality of a vector of controls today by computing the value of :\\[F( \\mathbf{x}, \\mathbf{\\tilde{x}} ) = \\sum_i w_i f(\\mathbf{s}, \\mathbf{x}, \\tilde{\\mathbf{s}}, \\tilde{\\mathbf{x}})\\] \\[\\mathbf{\\tilde{s}} = g(\\mathbf{s}, \\mathbf{x}, e_i)\\] \\[\\mathbf{\\tilde{x}} = \\mathcal{I}(\\mathbf{\\tilde{s}}; \\mathbf{s}, \\mathbf{{x}})\\]\nNote that because we use interpolating approximation: \\(\\forall i, x_i = \\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\)\nWe have enough to define an approximated time-iteration operator: implicitly defined by \\[F(T(\\mathbf{x}), \\mathbf{x}))\\]\nWe can then implement time-iteration, but…\n\nhow do we compute \\(T(x)\\)?",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#computing-tmathbfx",
    "href": "slides/time_iteration.html#computing-tmathbfx",
    "title": "Time Iteration",
    "section": "Computing \\(T(\\mathbf{x})\\)",
    "text": "Computing \\(T(\\mathbf{x})\\)\n\nIn each step, we have a guess, for decision rule tomorrow \\(\\mathbf{\\tilde{x}}\\)\nWe can then find the decision rule today, by solving numerically for: \\(\\mathbf{x} \\mapsto  F(\\mathbf{x}, \\mathbf{\\tilde{x}})\\)\n\nusually with some variant of a Newton method\n\nIt is possible to solve for the values at each grid point separately…\n\nfor each \\(i\\), find optimal controls \\(x_i\\) in state \\(s_i\\) that satisfy \\(F(x_i, \\mathbf{\\tilde{x}}) = 0\\)\nall the problems are independent from each other\n\n…or to solve everything as a big system\n\nthe jacobian is block-diagonal: finding optimal value in state \\(i\\) or in state \\(j\\) today are two independent problems",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#time-iteration-algorithm",
    "href": "slides/time_iteration.html#time-iteration-algorithm",
    "title": "Time Iteration",
    "section": "Time iteration algorithm",
    "text": "Time iteration algorithm\n\nDiscretize state-space with grid \\(\\mathbf{s}=(s_1, ..., s_N)\\)\nChoose initial values, for the vector of controls on the grid \\(\\mathbf{x}=(x_1, ..., x_N)\\)\nSpecify tolerance levels \\(\\eta&gt;0\\) and \\(\\epsilon&gt;0\\)\nGiven an intial guess \\(\\mathbf{x_n}\\)\n\nfind the zero \\(\\mathbf{x_{n+1}}\\) of function \\(\\mathbf{u}\\mapsto F(u,\\mathbf{x_n})\\)\n\nthat is, such that controls on the grid are optimal given controls tomorrow\nnonlinear solver can use \\(\\mathbf{x_n}\\) as initial guess\n\ncompute norm \\(\\mathbf{\\eta_n} = |\\mathbf{x_n} - \\mathbf{x_{n+1}}|\\)\nif \\(\\eta_n&lt;\\eta\\), stop and return \\(\\mathbf{x_{n+1}}\\)\n\nelse, set \\(\\mathbf{x_n} \\leftarrow \\mathbf{x_{n+1}}\\) and continue\n\n\nLike usual, during the iterations, it is useful to look at \\(\\mathbf{\\epsilon_n}=|F(\\mathbf{x_n},\\mathbf{x_n})|\\) and \\(\\lambda_n = \\frac{\\eta_n}{\\eta_{n-1}}\\)",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#what-about-the-complementarities",
    "href": "slides/time_iteration.html#what-about-the-complementarities",
    "title": "Time Iteration",
    "section": "What about the complementarities ?",
    "text": "What about the complementarities ?\n\nWhen there aren’t any occasionally binding constraint, we look for the of zero \\(\\mathbf{x_{n+1}}\\) of function \\(\\mathbf{u}\\mapsto F(u,\\mathbf{x_n})\\).\nIf we define the vector of constraints on all grid points as \\(\\mathbf{a}=(a(s_1), ..., a(s_N))\\) and \\(\\mathbf{b}=(b(s_1), ..., b(s_N))\\), we can rewrite the system to solve as: \\[F(u) \\perp \\mathbf{a} \\leq u \\leq \\mathbf{b}\\]\nThen we can:\n\nfeed \\(F\\), \\(a\\) and \\(b\\) to an NCP solver (like nlsolve.jl)\nor transform this relation using Fisher-Burmeister function into a smooth nonlinear system",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/time_iteration.html#time-iteration-variants",
    "href": "slides/time_iteration.html#time-iteration-variants",
    "title": "Time Iteration",
    "section": "Time iteration variants",
    "text": "Time iteration variants\nYou can check out:\n\nendogenous grid points:\n\nmathematically equivalent to TI,\nmuch faster for models that have a particular structure (consumption saving models)\nno need for a nonlinear solver\n\nimproved time iterations:\n\nsame as policy iterations for value function iterations\nconvergence is equivalent to that of TI\nmuch faster but requires correct initial guess\n\nparameterized expectations\n\nrequires that all controls are determined as a function of expectations\n\n\nAnd Dolo.jl for a library that implements some of these algorithms.",
    "crumbs": [
      "Slides",
      "Time Iteration"
    ]
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#section",
    "href": "slides/zero_to_ayiagari.html#section",
    "title": "Time Iteration",
    "section": "",
    "text": "Consider the following problems:\n  \n\n\n\nMonopoly pricing:\n\\[\\max_{q} \\pi(q) - c(q)\\]\n\nShopping problem\n\\[\\max_{\\substack{c_1, c_2 \\\\ p_1 c_1 + p_2 c_2 \\leq B}} U(c_1,c_2)\\]\n\nConsumption Savings\n\\[\\max_{\\substack{c() \\\\ w_{t+1}=(w_t-c(w_t))(1+r)) + y_{t+1}}} E_0 \\sum_t \\beta^t U(c(w_t))\\]\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem\nobjective\naction\nstate\ntransition\ntype\n\n\n\n\nmonopoly pricing\nprofit\nchoose quantity to produce\n\n\noptimization\n\n\nshopping problem\nutility\nchoose consumption composition\nbudget \\(B\\)\n\ncomparative statics\n\n\nconsumption/savings\nexpected welfare\nsave or consume\navailable income\nevolution of wealth\ndynamic optimization"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#general-formulation",
    "href": "slides/zero_to_ayiagari.html#general-formulation",
    "title": "Time Iteration",
    "section": "General Formulation",
    "text": "General Formulation\nMarkov Decision Problem\n\n\n\n\nEnvironment\n\nstates: \\(s \\in S\\)\nactions: \\(x \\in X(s)\\)\ntransitions: \\(\\pi(s'| s, x) \\in S\\)\n\n\\(probability\\) of going to \\(s'\\) in state \\(s\\)…\n… given action \\(x\\)\n\n\n\n\n\n\nReward: \\(r(s,x) \\in R\\)\n\naka felicity, intratemporal utility\n\n\nPolicy: \\(x(): s \\rightarrow x\\in X(s)\\)\n\na.k.a. decision rule\nwe consider deterministic policy\ngiven \\(x()\\), the evolution of \\(s\\) is a Markov process\n\n\\(\\pi(. |s, x())\\) is a distribution for \\(s'\\) over \\(S\\)\nit depends only on \\(s\\)"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#objective",
    "href": "slides/zero_to_ayiagari.html#objective",
    "title": "Time Iteration",
    "section": "Objective",
    "text": "Objective\n\nexpected lifetime reward:\n\nvalue of following policy \\(x()\\) starting from \\(s\\): \\[R(s; x()) =  E_0 \\sum_t^T \\delta^t \\left[ r_t\\right]\\]\n\\(\\delta \\in [0,1[\\): discount factor\nhorizon: \\(T \\in \\\\{N, \\infty\\\\}\\)\n\nvalue of a state \\(s\\)\n\nvalue of following the optimal policy starting from \\(s\\) \\[V(s) = \\max_{ x()} R(s, x())\\]\n\\(V()\\) is the value function (t.b.d.)"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#classes-of-dynamic-optimization",
    "href": "slides/zero_to_ayiagari.html#classes-of-dynamic-optimization",
    "title": "Time Iteration",
    "section": "Classes of Dynamic Optimization",
    "text": "Classes of Dynamic Optimization\n\nThe formulation so far is very general. It encompasses several variants of the problem:\n\nfinite horizon vs infinite horizon\ndiscrete-space problem vs continuous-state space problem\nsome learning problems (reinforcement learning…)\n\nThere are also variants not included:\n\nnon time-separable problems\nnon time-homogenous problems\nsome learning problems (bayesian updating, …)"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#finite-horizon-vs-infinite-horizon",
    "href": "slides/zero_to_ayiagari.html#finite-horizon-vs-infinite-horizon",
    "title": "Time Iteration",
    "section": "Finite horizon vs infinite horizon",
    "text": "Finite horizon vs infinite horizon\n\nRecall objective: \\(V(s; x()) =  \\max E_0\\sum_{t=0}^T \\delta^t \\left[ r(s_t, x_t) \\right]\\)\nIf \\(T&lt;\\infty\\), the decision in the last periods, will be different from the periods before\n\none must find a decision rule \\(\\pi_t()\\) per period\nor, equivalently, add \\(t\\) to the state space: \\(\\tilde{S}=S\\times[0,T]\\)\n\nIf \\(T=\\infty\\), the continuation value of being in state \\(s_t\\) is independent from \\(t\\)\n\n\\[V(s; x()) = E_0 \\max \\sum_ {t=0}^{T_0} \\delta^t \\left[ r(s_t, x_t) \\right] + \\delta^{T_0} E_0  \\sum_ {t=T_0}^{\\infty} \\delta^t \\left[ r(s_t, x_t) \\right]\\]\n\\[ = E_0 \\left[ \\max \\sum_ {t=0}^{T_0} \\delta^t \\left[ r(s_t, x_t) \\right] +  \\delta^{T_0} V(s_ {T_0}; x()) \\right]\\]"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#continuous-vs-discrete",
    "href": "slides/zero_to_ayiagari.html#continuous-vs-discrete",
    "title": "Time Iteration",
    "section": "Continuous vs discrete",
    "text": "Continuous vs discrete\n\nDiscrete Dynamic Programming (today)\n\ndiscrete states: \\(s \\in {s_1, \\cdots, s_N}\\)\ndiscrete controls: \\(|X(s)|&lt;\\infty\\)\nthere is a finite number of policies, the can be represented exactly\nunless \\(|S|\\) is very large (cf go game)\n\nContinuous problem:\n\n\\(x(s)\\), \\(V(s; \\pi)\\) require an infinite number of coefficients\nsame general approach but different implementation\ntwo main variants:\n\ndiscretize the initial problem: back to DDP\nuse approximation techniques (i.e. interpolation)"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#non-time-separable-example",
    "href": "slides/zero_to_ayiagari.html#non-time-separable-example",
    "title": "Time Iteration",
    "section": "Non time separable example",
    "text": "Non time separable example\n\nFor instance Epstein-Zin preferences: \\[\\max V(;c())\\] where \\[V_t = (1-\\delta) \\frac{c_t^{1-\\sigma}}{1-\\sigma} + \\delta \\left[ E_t V_{t+1}^{\\alpha} \\right]^{\\frac{1}{\\alpha}}\\]\nWhy would you do that?\n\nto disentangle risk aversion and elasticity of intertemporal substitution\nrobust control\n\nYou can still use ideas from Dynamic Programming."
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#non-homogenous-preference",
    "href": "slides/zero_to_ayiagari.html#non-homogenous-preference",
    "title": "Time Iteration",
    "section": "Non homogenous preference",
    "text": "Non homogenous preference\n\nLook at the \\(\\alpha-\\beta\\) model. \\[V_t = \\max \\sum_t^{\\infty} \\beta_t U(c_t)\\] where \\(\\delta_0 = 1\\), \\(\\delta_1=\\alpha\\), \\(\\delta_k=\\alpha\\beta^{k-1}\\)\nMakes the problem time-inconsistent:\n\nthe optimal policy you would choose for the continuation value after \\(T\\) is not the same if you maximize it in expectation from \\(0\\) or at \\(T\\)."
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#learning-problems",
    "href": "slides/zero_to_ayiagari.html#learning-problems",
    "title": "Time Iteration",
    "section": "Learning problems",
    "text": "Learning problems\n\nBayesian learning: Uncertainty about some model parameters\n\nex: variance and return of a stock market\nagent models this uncertainty as a distribution\nagent updates his priors after observing the result of his actions\nactions are taken optimally taken into account the revelation power of some actions\n\nIs it good?\n\nclean: the rational thing to do with uncertainty\nsuper hard: the state-space should contain all possible priors\nmathematical cleanness comes with many assumptions\n\nUsed to estimate rather big (mostly linear) models"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#learning-problems-2",
    "href": "slides/zero_to_ayiagari.html#learning-problems-2",
    "title": "Time Iteration",
    "section": "Learning problems (2)",
    "text": "Learning problems (2)\n\nReinforcement learning\n\nmodel can be partially or totally unknown\ndecision rule is updated by observing the reward from actions\n\nno priors\n\nsolution does not derive directly from model\n\ncan be used to solve dynamic programming problems\n\n\nGood solutions maximize a criterion similar to lifetime reward but are usually not optimal:\n\nusually evaluated by replaying the game many times\ntradeoff exploration / exploitations"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#whats-new-today",
    "href": "slides/zero_to_ayiagari.html#whats-new-today",
    "title": "Time Iteration",
    "section": "What’s new today?",
    "text": "What’s new today?\n\nA few weeks ago, we did discrete dynamic programming\n\ntoday, we have continuous decision rules\nwe will need to interpolate\n\nWe were using Bellman representation\n\nwe’ll use first order representation (Euler and co.)\n\nWe will see the main time-iteration algorithms\n\nand mention some of its variants"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#generic-value-function-representation",
    "href": "slides/zero_to_ayiagari.html#generic-value-function-representation",
    "title": "Time Iteration",
    "section": "Generic Value Function Representation",
    "text": "Generic Value Function Representation\n\nAll variables of the model are vectors:\n\nstates \\(s \\in \\mathcal{S} \\subset R^{n_s}\\)\ncontrols \\(x \\in \\mathcal{F}(\\mathcal{S}, R^{n_x})\\)\n\nwe assume bounds \\(a(s)\\leq x \\leq b(s)\\)\n\nshocks: \\(\\epsilon \\sim \\text{i.i.d. distrib}\\)\n\nTransition: \\[s_{t+1} = g(s_t, x_t, \\epsilon_{t+1})\\]\nValue function: \\[V(s) = E_0 \\sum_{t\\geq 0} \\beta^t \\left[ U(s_t, x_t)\\right]\\]\nSolution is a function \\(V()\\) (value) which is a fixed point of the Bellman-operator: \\[\\forall s, V(s) = \\max_{a(s)\\leq x \\leq b(s)} U(s,x) + \\beta E \\left[ V(g(s,x,\\epsilon)) \\right]\\]\nThe argmax, defines a decision rule function: \\(x = \\varphi(s)\\)"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#first-order-representation",
    "href": "slides/zero_to_ayiagari.html#first-order-representation",
    "title": "Time Iteration",
    "section": "First order representation",
    "text": "First order representation\n\n\n\nAll variables of the model are vectors:\n\nstates \\(s_t\\)\ncontrols \\(x_t\\)\n\nwe assume bounds \\(a(s)\\leq x \\leq b(s)\\)\n\nshocks: \\(\\epsilon_t\\) (i.i.d. random law)\n\nTransition: \\[s_{t+1} = g(s_t, x_t, \\epsilon_{t+1})\\]\nDecision rule: \\[x_t = \\varphi(s_t)\\]\nArbitrage: \\[ E_t\\left[ f(s_t, x_t, s_{t+1}, x_{t+1}) \\right] = 0 \\perp a(s_t) \\leq x_t \\leq b(s_t) \\]\n\n\n\nThese equations must be true for any \\(s_t\\).\nRemark: time subscript are conventional. They are used to precise:\n\nwhen expectation is taken (w.r.t \\(\\epsilon_{t+1}\\))\nto avoid repeating \\(x_t=\\varphi(s_t)\\) and \\(x_{t+1} = \\varphi(s_t)\\)\n\nSometimes there are bounds on the controls\n\nwe encode them with complementarity constraints\nmore on it later"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#example-1-neoclassical-growth-model",
    "href": "slides/zero_to_ayiagari.html#example-1-neoclassical-growth-model",
    "title": "Time Iteration",
    "section": "Example 1: neoclassical growth model",
    "text": "Example 1: neoclassical growth model\n\n\n\ncapital accumulation: \\[k_t = (1-\\delta)k_{t-1} + i_{t-1}\\]\nproduction: \\[y_t = k_t^\\alpha\\]\nconsumption: \\[c_t = (1-s_t) y_t\\] \\[i_t = s_t y_t\\]\noptimality: \\[\\beta E_t \\left[ \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_{t})} (1-\\delta + \\alpha k_{t+1}^{\\alpha-1}\\alpha) \\right]= 1\\]\n\n\n\nstates: \\(k_t\\), with one transition equation\ncontrols: \\(y_t, c_t, i_t, s_t\\), with four “arbitrage” equations\n\nit is possible but not mandatory to reduce the number of variables/equations by simple susbtitutions"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#example-2-consumption-savings-model",
    "href": "slides/zero_to_ayiagari.html#example-2-consumption-savings-model",
    "title": "Time Iteration",
    "section": "Example 2: consumption-savings model",
    "text": "Example 2: consumption-savings model\n\n\nSimplest consumption/savings model:\n\nTransition: \\[w_t = \\exp(\\epsilon_t) + (w_{t-1} - c_{t-1}) \\overline{r}\\]\nObjective: \\[\\max_{0\\leq c_t \\leq w_t} E_0 \\left[ \\sum \\beta^t U(c_t) \\right]\\]\nFirst order conditions: \\[\\beta E_t \\left[  \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_t)} \\overline{r} \\right] - 1 \\perp 0 \\leq c_t \\leq w_t\\]\n\n\n\nF.O.C. reads as: \\[\\beta E_t \\left[  \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_t)} \\overline{r} \\right] - 1 \\leq 0 \\perp c_t \\leq w_t\\] and \\[0 \\leq \\beta E_t \\left[  \\frac{U^{\\prime}(c_{t+1})}{U^{\\prime}(c_t)} \\overline{r} \\right] - 1  \\perp 0 \\leq c_t \\]\nFirst one reads: if my marginal utility of consumption today is higher than expected mg. utility of cons. tomorrow, I’d like to consume more, but I can’t because, consumption is bounded by income (and no-borrowing constraint).\nSecond one reads: only way I could tolerate higher utility in the present, than in the future, would be if I want dissave more than I can, or equivalently, consume less than zero. This is never happening."
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#example-3-new-keynesian-with-without-zlb",
    "href": "slides/zero_to_ayiagari.html#example-3-new-keynesian-with-without-zlb",
    "title": "Time Iteration",
    "section": "Example 3: new-keynesian with / without ZLB",
    "text": "Example 3: new-keynesian with / without ZLB\n\n\nConsider the new keynesian model we have seen in the introduction:\n\nAssume \\(z_t\\) is an autocorrelated shock: \\[z_t = \\rho z_{t-1} + \\epsilon_t\\]\nNew philips curve (PC):\\[\\pi_t = \\beta \\mathbb{E}_t \\pi_{t+1} + \\kappa y_t\\]\ndynamic investment-saving equation (IS):\\[y_t = \\beta \\mathbb{E}_t y_{t+1} - \\frac{1}{\\sigma}(i_t - \\mathbb{E}_t(\\pi_{t+1}) ) - {\\color{green} z_t}\\]\nInterest Rate Setting (taylor rule): \\[i_t = \\alpha_{\\pi} \\pi_t + \\alpha_{y} y_t\\]\n\n\n\nThe model satisfies the same specification with:\n\none state \\(z_t\\) and one transition equation\nthree controls: \\(\\pi_t\\), \\(y_t\\) and \\(i_t\\) with three “arbitrage” equation\n\nThese are not real first order conditions as they are not derived from a maximization program\n\nunless one tries to microfound them…\n\nIt is possible to add a zero-lower bound constraint by replacing IRS with: \\[ \\alpha_{\\pi} \\pi_t + \\alpha_{y} y_t \\leq i_t \\perp 0 \\leq i_t\\]"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#time-iteration-1",
    "href": "slides/zero_to_ayiagari.html#time-iteration-1",
    "title": "Time Iteration",
    "section": "Time iteration",
    "text": "Time iteration\n\nSo we have the equation, \\(\\forall s_t\\)\n\n\\[ E_t\\left[ f(s_t, x_t, s_{t+1}, x_{t+1}) \\right] = 0 \\perp a(s_t) \\leq x_t \\leq b(s_t)\\]\\[ E_t\\left[ f(s_t, x_t, s_{t+1}, x_{t+1}) \\right] = 0\\]\n\nwhere \\[s_{t+1} = g(s_t, x_t, \\epsilon_{t+1})\\] \\[x_t = \\varphi(s_t)\\] \\[x_{t+1} = \\tilde{\\varphi}(s_{t+1})\\]\nLet’s leave the complementarity conditions aside for now\nIn equilibrium \\(\\tilde{\\varphi} = {\\varphi}\\)"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#time-iteration-2",
    "href": "slides/zero_to_ayiagari.html#time-iteration-2",
    "title": "Time Iteration",
    "section": "Time iteration",
    "text": "Time iteration\n\nWe can rewrite everything as one big functional equation: \\[\\forall s, \\Phi(\\varphi, \\tilde{\\varphi})(s) = E\\left[ f(s, \\varphi(s), g(s,\\varphi(s), \\epsilon), \\tilde{\\varphi}(g(s,\\varphi(s), \\epsilon)) \\right]\\]\nA solution is \\(\\varphi\\) such that \\(\\Phi(\\varphi, \\varphi) = 0\\)\nThe Coleman operator \\(\\mathcal{T}\\) is defined implicitly by: \\[\\Phi(\\mathcal{T}(\\varphi), \\varphi)=0\\]\nThe core of the time iteration algorithm, consists in the recursion: \\[\\varphi_{n+1} = \\mathcal{T}(\\varphi_n)\\]\nIt maps future decision rules to current decision rules\n\nsame as “linear time iterations”, remember?\n\nSounds fun but how do we implement it concretely?"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#practical-implementation",
    "href": "slides/zero_to_ayiagari.html#practical-implementation",
    "title": "Time Iteration",
    "section": "Practical implementation",
    "text": "Practical implementation\n\nWe need to find a way to:\n\ncompute expectations\nrepresent decision rules \\(\\varphi\\) and \\(\\varphi\\) with a finite number of parameters"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#practical-implementation-2",
    "href": "slides/zero_to_ayiagari.html#practical-implementation-2",
    "title": "Time Iteration",
    "section": "Practical implementation (2)",
    "text": "Practical implementation (2)\n\nComputing expectations:\n\ndiscretize shock \\(\\epsilon\\) with finite quantization \\((w_i, e_i)_{i=1:K}\\)\nreplace optimality condition with: \\[\\forall s, \\Phi(\\varphi, \\tilde{\\varphi})(s) = \\sum_i w_i f(s, \\varphi(s), g(s,\\varphi(s), e_i), \\tilde{\\varphi}(g(s,\\varphi(s), e_i)) \\]\n\n… but we still can’t compute all the \\(\\varphi\\)"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#approximating-decision-rules",
    "href": "slides/zero_to_ayiagari.html#approximating-decision-rules",
    "title": "Time Iteration",
    "section": "Approximating decision rules",
    "text": "Approximating decision rules\n\nWe’ll limit ourselves to interpolating functional spaces\n\nWe define a finite grid \\(\\mathbf{s}=(s_1, ... s_N)\\) to approximate the state space (\\(\\mathbf{s}\\) is a finite vector of points)\nIf we know the vector of values \\(\\mathbf{x}=(x_1, ..., x_N)\\) a function \\(\\varphi\\) takes on \\(\\mathbf{s}\\), we approximate \\(\\varphi\\) at any \\(s\\) using an interpolation scheme \\(\\mathcal{I}\\): \\[\\varphi(s) \\approx \\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\]\n\nNow if we replace \\(\\varphi\\) by \\(\\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\) and \\(\\tilde{\\varphi}\\) by \\(\\mathcal{I}(s, \\mathbf{s}, \\mathbf{\\tilde{x}})\\) the functional equation becomes: \\[\\forall s,  \\Phi(\\varphi, \\tilde{\\varphi})(s) \\approx F( \\mathbf{x}, \\mathbf{\\tilde{x}} )(s) = \\sum_i w_i f(s, x, \\tilde{s}, \\tilde{x})\\] where \\[x = \\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\] \\[\\tilde{s} = g(s, x, e_i)\\] \\[\\tilde{x} = \\mathcal{I}(s, \\mathbf{s}, \\mathbf{\\tilde{x}})\\]"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#pinning-down-decision-rules",
    "href": "slides/zero_to_ayiagari.html#pinning-down-decision-rules",
    "title": "Time Iteration",
    "section": "Pinning down decision rules",
    "text": "Pinning down decision rules\n\nNote that this equation must be statisfied \\(\\forall s\\).\nIn order to pin-down the \\(N\\) coefficients \\(\\mathbf{x}\\), it is enough to satisfy the equations at \\(N\\) different points.\nHence we solve the square system: \\[\\forall i\\in [1,N], F( \\mathbf{x}, \\mathbf{\\tilde{x}} )(s_i) = 0\\]\nIn vectorized form, this is just: \\[F( \\mathbf{x}, \\mathbf{\\tilde{x}} )(\\mathbf{s}) = 0\\]\nOr, since grid \\(\\mathbf{s}\\) is fixed: \\[F( \\mathbf{x}, \\mathbf{\\tilde{x}} ) = 0\\]\nNow the vector of decisions today, at each point of the grid, is determined as a function of the vector of decisions tomorrow, on the same grid."
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#recap",
    "href": "slides/zero_to_ayiagari.html#recap",
    "title": "Time Iteration",
    "section": "Recap",
    "text": "Recap\n\nChoose a finite grid for states \\(\\mathbf{s} = (s_1, ..., s_N)\\)\nFor a given vector of controls tomorrow \\(\\mathbf{\\tilde{x}}\\), one can compute theoptimality of a vector of controls today by computing the value of :\\[F( \\mathbf{x}, \\mathbf{\\tilde{x}} ) = \\sum_i w_i f(\\mathbf{s}, \\mathbf{x}, \\tilde{\\mathbf{s}}, \\tilde{\\mathbf{x}})\\] \\[\\mathbf{\\tilde{s}} = g(\\mathbf{s}, \\mathbf{x}, e_i)\\] \\[\\mathbf{\\tilde{x}} = \\mathcal{I}(\\mathbf{\\tilde{s}}; \\mathbf{s}, \\mathbf{{x}})\\]\nNote that because we use interpolating approximation: \\(\\forall i, x_i = \\mathcal{I}(s, \\mathbf{s}, \\mathbf{x})\\)\nWe have enough to define an approximated time-iteration operator: implicitly defined by \\[F(T(\\mathbf{x}), \\mathbf{x}))\\]\nWe can then implement time-iteration, but…\n\nhow do we compute \\(T(x)\\)?"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#computing-tmathbfx",
    "href": "slides/zero_to_ayiagari.html#computing-tmathbfx",
    "title": "Time Iteration",
    "section": "Computing \\(T(\\mathbf{x})\\)",
    "text": "Computing \\(T(\\mathbf{x})\\)\n\nIn each step, we have a guess, for decision rule tomorrow \\(\\mathbf{\\tilde{x}}\\)\nWe can then find the decision rule today, by solving numerically for: \\(\\mathbf{x} \\mapsto  F(\\mathbf{x}, \\mathbf{\\tilde{x}})\\)\n\nusually with some variant of a Newton method\n\nIt is possible to solve for the values at each grid point separately…\n\nfor each \\(i\\), find optimal controls \\(x_i\\) in state \\(s_i\\) that satisfy \\(F(x_i, \\mathbf{\\tilde{x}}) = 0\\)\nall the problems are independent from each other\n\n…or to solve everything as a big system\n\nthe jacobian is block-diagonal: finding optimal value in state \\(i\\) or in state \\(j\\) today are two independent problems"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#time-iteration-algorithm",
    "href": "slides/zero_to_ayiagari.html#time-iteration-algorithm",
    "title": "Time Iteration",
    "section": "Time iteration algorithm",
    "text": "Time iteration algorithm\n\nDiscretize state-space with grid \\(\\mathbf{s}=(s_1, ..., s_N)\\)\nChoose initial values, for the vector of controls on the grid \\(\\mathbf{x}=(x_1, ..., x_N)\\)\nSpecify tolerance levels \\(\\eta&gt;0\\) and \\(\\epsilon&gt;0\\)\nGiven an intial guess \\(\\mathbf{x_n}\\)\n\nfind the zero \\(\\mathbf{x_{n+1}}\\) of function \\(\\mathbf{u}\\mapsto F(u,\\mathbf{x_n})\\)\n\nthat is, such that controls on the grid are optimal given controls tomorrow\nnonlinear solver can use \\(\\mathbf{x_n}\\) as initial guess\n\ncompute norm \\(\\mathbf{\\eta_n} = |\\mathbf{x_n} - \\mathbf{x_{n+1}}|\\)\nif \\(\\eta_n&lt;\\eta\\), stop and return \\(\\mathbf{x_{n+1}}\\)\n\nelse, set \\(\\mathbf{x_n} \\leftarrow \\mathbf{x_{n+1}}\\) and continue\n\n\nLike usual, during the iterations, it is useful to look at \\(\\mathbf{\\epsilon_n}=|F(\\mathbf{x_n},\\mathbf{x_n})|\\) and \\(\\lambda_n = \\frac{\\eta_n}{\\eta_{n-1}}\\)"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#what-about-the-complementarities",
    "href": "slides/zero_to_ayiagari.html#what-about-the-complementarities",
    "title": "Time Iteration",
    "section": "What about the complementarities ?",
    "text": "What about the complementarities ?\n\nWhen there aren’t any occasionally binding constraint, we look for the of zero \\(\\mathbf{x_{n+1}}\\) of function \\(\\mathbf{u}\\mapsto F(u,\\mathbf{x_n})\\).\nIf we define the vector of constraints on all grid points as \\(\\mathbf{a}=(a(s_1), ..., a(s_N))\\) and \\(\\mathbf{b}=(b(s_1), ..., b(s_N))\\), we can rewrite the system to solve as: \\[F(u) \\perp \\mathbf{a} \\leq u \\leq \\mathbf{b}\\]\nThen we can:\n\nfeed \\(F\\), \\(a\\) and \\(b\\) to an NCP solver (like nlsolve.jl)\nor transform this relation using Fisher-Burmeister function into a smooth nonlinear system"
  },
  {
    "objectID": "slides/zero_to_ayiagari.html#time-iteration-variants",
    "href": "slides/zero_to_ayiagari.html#time-iteration-variants",
    "title": "Time Iteration",
    "section": "Time iteration variants",
    "text": "Time iteration variants\n\nYou can check out:\n\nendogenous grid points:\n\nmathematically equivalent to TI,\nmuch faster for models that have a particular structure (consumption saving models)\nno need for a nonlinear solver\n\nimproved time iterations:\n\nsame as policy iterations for value function iterations\nconvergence is equivalent to that of TI\nmuch faster but requires correct initial guess\n\nparameterized expectations\n\nrequires that all controls are determined as a function of expectations"
  },
  {
    "objectID": "slides/session_3/index.html#today",
    "href": "slides/session_3/index.html#today",
    "title": "Perturbation Analysis",
    "section": "Today",
    "text": "Today\nStudy Neoclassical Model of Growth with Deterministic Productivity Shocks\n\nDerive First Order Conditions\nComputing Derivatives Numerically\nSolution Method\n\nLinear Time Iteration\n\nImplementation",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#neoclassical-growth-model",
    "href": "slides/session_3/index.html#neoclassical-growth-model",
    "title": "Perturbation Analysis",
    "section": "Neoclassical Growth Model",
    "text": "Neoclassical Growth Model\n\n\n\nTransition Equation \\[\\begin{eqnarray}\nk_t & = & (1-\\delta) k_{t-1} + i_{t-1} \\\\\nz_t & = & \\rho z_{t-1}\n\\end{eqnarray}\n\\]\nDefinition: \\[c_t = \\exp(z_t) k_t^\\alpha - i_t\\]\nControl \\(i_t\\in[0, \\exp(z_t)k_t^\\alpha[\\)\n\nor equivalently \\(c_t \\in ]0, \\exp(z_t) k_t^{\\alpha}]\\)\n\nObjective: \\[\\max_{i_t} \\sum_{t\\geq0} \\beta^t U(c_t)\\]\n\n\n\nCalibration:\n\n\\(\\beta = 0.96\\)\n\\(\\delta = 0.1\\)\n\\(\\gamma = 4.0\\)\n\\(\\alpha = 0.3\\)\n\\(U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}\\)",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#deriving-first-order-conditions-1",
    "href": "slides/session_3/index.html#deriving-first-order-conditions-1",
    "title": "Perturbation Analysis",
    "section": "Deriving First Order Conditions",
    "text": "Deriving First Order Conditions\n\nTwo methods:\n\nBellman:\n\nOptimality Condition\nEnveloppe Condition\n\nLagrangian:\n\nWe will use the lagrangian version",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#lagrangian",
    "href": "slides/session_3/index.html#lagrangian",
    "title": "Perturbation Analysis",
    "section": "Lagrangian",
    "text": "Lagrangian\n\nInitial Conditions (predetermined states): \\(z_0\\), \\(k_0\\)\nProblem: \\[V(z_0, k_0) = \\max_{\\begin{matrix}i_0, i_1, i_2, \\cdots \\\\c_0, c_1, c_2 \\cdots \\\\ k_1, k_2, \\cdots\\end{matrix}} \\sum_{t \\geq 0}\\beta^t U(c_t)\\]\n\n\\[\\text{s.t.}\\forall t\\geq 0, \\; \\; \\begin{eqnarray}\n\\mu_t:\\quad &  0 & \\leq & i_t  \\\\\n\\nu_t:\\quad &  i_t & \\leq & \\exp(z_t) k_t^{\\alpha} \\\\\n\\lambda_t:\\quad &  i_t & = & \\exp(z_t) k_t^{\\alpha} - c_t\\\\\nq_t:\\quad &  k_{t+1} & = & (1-\\delta) k_{t} + i_{t}\n\\end{eqnarray}\\]\n\nLagrangian: \\[\n\\mathcal{L} (z_0, k_0) = \\sum_{t \\geq 0} \\beta^t\\left\n\\{ U(c_t) + \\mu_t \\left( i_t \\right) + \\nu_t \\left(\\exp(z_t)k_t^{\\alpha} - i_t \\right) + \\lambda_t \\left(\\exp(z_t) k_t^{\\alpha}  - i_t -c_t \\right)  + q_t \\left( (1-\\delta) k_{t} + i_{t} - k_{t+1} \\right) \\right\\}\n\\]",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#lagrangian-1",
    "href": "slides/session_3/index.html#lagrangian-1",
    "title": "Perturbation Analysis",
    "section": "Lagrangian",
    "text": "Lagrangian\n\n\n\nWe maximize the lagrangian to get:\n\n\\[\\begin{eqnarray}\n\\forall t\\geq0 & \\frac{\\partial \\mathcal{L}}{\\partial i_t} & = & 0 \\\\\n& \\frac{\\partial \\mathcal{L}}{\\partial c_t} & = & 0 \\\\\n& \\frac{\\partial \\mathcal{L}}{\\partial k_{t+1}} & = & 0\n\\end{eqnarray}\\]\n\nIt is important to note that we don’t differentiate with respect to a predetermined state\n\ncheck that you don’t differentiate w.r.t. \\(k_0\\)\n\nIt looks like the first order condition added four new variables \\(\\mu_t\\),\\(\\nu_t\\), \\(\\lambda_t\\), \\(q_t\\)\n\n\n\nLuckily these variables are associated to slackness conditions.\n\n\n\n\n\\(\\mu_t \\geq 0\\)\n\\(i_t \\geq 0\\)\n\n\n\\(\\nu_t \\geq 0\\)\n\\(\\exp(z_t) k_t^{\\alpha}-i_t \\geq 0\\)\n\n\n\\(q_t \\geq 0\\)\n\\((1-\\delta) k_{t} + i_{t} - k_{t+1} \\geq 0\\)\n\n\n\\(\\lambda_t \\geq 0\\)\n\\(\\exp(z_t) k_t^{\\alpha}  - i_t -c_t = 0\\)\n\n\n\n\nThe Karush-Kuhn-Tucker states, that for each slackness condition, at any time, either\n\nthe lagrangian is 0 and it disappears from the F.O.C.s\nor it is not 0 and the associated constraint adds another condition",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#eliminating-constraints",
    "href": "slides/session_3/index.html#eliminating-constraints",
    "title": "Perturbation Analysis",
    "section": "Eliminating constraints",
    "text": "Eliminating constraints\n\n\n\n\n\n\\(\\mu_t \\geq 0\\)\n\\(i_t \\geq 0\\)\n\n\n\\(\\nu_t \\geq 0\\)\n\\(\\exp(z_t) k_t^{\\alpha}-i_t \\geq 0\\)\n\n\n\\(q_t\\)\n\\((1-\\delta) k_{t} + i_{t} - k_{t+1} = 0\\)\n\n\n\\(\\lambda_t\\)\n\\(\\exp(z_t) k_t^{\\alpha}  - i_t -c_t = 0\\)\n\n\n\n\nIn general slackness conditions can be occasionally binding\nFor perturbation analysis, we need constraints to be always (or never binding)\n\n\nLet’s review them:\n\n\\(\\nu_t\\): it is equivalent to \\(c_t\\geq 0\\)\n\nwe necessarily have \\(c_t&gt;0\\) since \\(U^{\\prime}(0)=\\infty\\)\nhence \\(\\nu_t=0\\)\n\n\\(\\mu_t\\): it states \\(k_{t+1}\\geq 0\\)\n\nif \\(k_{t+1}=0\\), then \\(c_{t+1}\\). We can conclude \\(k_{t+1}&gt;0\\)\nhence \\(\\mu_t=0\\)\n\nfor multipliers associated to an equality constraint, we always keep the system\n\nmultiplier can have any sign\n\ninequality formulation is sometimes found too:\n\n\\(c_t \\leq \\exp(z_t) k_t^{\\alpha}  - i_t\\) ( you can destroy production insead of eating or investing it)\n\\(k_{t+1} \\leq (1-\\delta) k_{t} + i_{t}\\) (you can destroy capital instead of investing it)",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#first-order-model",
    "href": "slides/session_3/index.html#first-order-model",
    "title": "Perturbation Analysis",
    "section": "First order model",
    "text": "First order model\n\nOptimality Condition: \\[\\beta  \\left[ \\frac{\\left(c_{t+1}\\right)^{-\\gamma}}{\\left(c_t\\right)^{-\\gamma}} \\left( (1-\\delta + \\alpha exp(z_{t+1})k_{t+1}^{\\alpha -1}) \\right)\\right] = 1\\]\n\nTakes into account the fact that \\(c_t&gt;0\\).\n\nDefinition: \\[c_t = exp(z_t) k_t^\\alpha - i_t\\]\nTransition: \\[k_t = (1-\\delta) k_{t-1} + i_{t-1}\\] \\[z_t = \\rho z_{t-1}\\]",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#steady-state",
    "href": "slides/session_3/index.html#steady-state",
    "title": "Perturbation Analysis",
    "section": "Steady-State",
    "text": "Steady-State\n\n\n\nSteady-State: \\(\\overline{i}, \\overline{k}, \\overline{z}\\) such that:\n\n\\(z_{t+1}=z_t=\\overline{z}\\)\n\\(k_{t+1}=k_t=\\overline{k}\\)\n\\(i_{t+1}=i_t=\\overline{i}\\)\n\\(c_{t+1}=c_t=\\overline{c}\\)\n\n…satisfy the first order conditions\n…i.e.\n\n\\[\n\\begin{eqnarray}\n1 & = & \\beta   \\left( (1-\\delta + \\alpha {\\overline{k}}^{\\alpha -1}) \\right)  \\\\\n\\overline{k} & = & (1-\\delta) \\overline{k} + \\overline{i} \\\\\n\\overline{z} & = & \\rho \\overline{z} \\\\\n\\overline{c} & = & \\overline{k}^{\\alpha} - \\overline{i}\n\\end{eqnarray}\n\\]\n\n\nSolution?\n\nclosed-form\nnumerical\n\nHere we can get a closed form:\n\n\\[\\begin{eqnarray}\n\\overline{k} & = & \\left( \\frac{\\frac{1}{\\beta}-(1-\\delta)}{\\alpha} \\right)^{\\frac{1}{\\alpha - 1}} \\\\\n\\overline{i} & = & \\delta \\overline{k} \\\\\\\n\\overline{z} & = & 0 \\\\\n\\overline{c} & = & \\overline{k}^{\\alpha} - \\overline{i}\n\\end{eqnarray}\\]",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#perturbation-analysis",
    "href": "slides/session_3/index.html#perturbation-analysis",
    "title": "Perturbation Analysis",
    "section": "Perturbation Analysis",
    "text": "Perturbation Analysis\n\n\n\nWrite all variables in deviation to the steady-state: \\[z_{t}=\\overline{z} + \\Delta z_t\\] \\[k_{t}=\\overline{k} + \\Delta k_t\\] \\[i_{t}=\\overline{i} + \\Delta i_t\\] \\[c_{t}=\\overline{c} + \\Delta c_t\\]\n\nRemark: some smart economists use log-deviations (i.e. \\(x_t = \\overline{x} \\hat{x}_t\\) to make computations easier)\n\n\n\n\nReplace in the system \\[\\beta  \\left[ \\frac{\\left(\\overline{c}+ \\Delta c_{t+1}\\right)^{-\\gamma}}{\\left(\\overline{c} + \\Delta c_t\\right)^{-\\gamma}} \\left( (1-\\delta + \\alpha (\\overline{k} + \\Delta k_{t+1})^{\\alpha -1}) \\right)\\right] = 1\\] \\[\\overline{c} + \\Delta c_t = (\\overline{k}+ \\Delta k_t)^\\alpha - \\overline{i} - \\Delta i_t\\] \\[\\overline{k} + \\Delta k_t = (1-\\delta) (\\overline{k}+ \\Delta k_{t-1}) + \\overline{i }+ \\Delta i_{t-1}\\] \\[\\overline{z }+ \\Delta z_t = \\overline{z}+ \\Delta \\rho z_{t-1}\\]\nDifferentiate…\n(if we want to limit the number of equations, we can replace \\(c_t\\) by its value)",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#result",
    "href": "slides/session_3/index.html#result",
    "title": "Perturbation Analysis",
    "section": "Result:",
    "text": "Result:\n\nOptimality conditions \\[\\begin{bmatrix} . & . & . & . \\\\ \\end{bmatrix} \\begin{bmatrix} \\Delta i_t \\\\ \\Delta c_t  \\\\ \\Delta k_t \\\\ \\Delta z_t \\end{bmatrix} = \\begin{bmatrix} . & . & . \\\\ \\end{bmatrix} \\begin{bmatrix} \\Delta i_{t+1} \\\\  \\Delta c_{t+1} \\\\ \\Delta k_{t+1} \\\\ \\Delta z_{t+1} \\end{bmatrix} \\]\nTransition \\[ \\begin{bmatrix} \\Delta k_t \\\\ \\Delta z_t \\end{bmatrix} = \\begin{bmatrix} . & .  \\\\ . & . \\end{bmatrix} \\begin{bmatrix} \\Delta k_{t-1} \\\\ \\Delta z_{t-1} \\end{bmatrix}  + \\begin{bmatrix} . \\end{bmatrix} \\begin{bmatrix}\\Delta i_{t-1}\\end{bmatrix}\\]",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#julia-console",
    "href": "slides/session_3/index.html#julia-console",
    "title": "Perturbation Analysis",
    "section": "Julia Console",
    "text": "Julia Console\n\nAccessible:\n\nfrom a good terminal\nfrom VSCode panel\n\nFour modes:\n\n``: REPL (read-eval-print)\n?: Help\n]: Package Management\n;: System Console",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#julia-package-ecosystem",
    "href": "slides/session_3/index.html#julia-package-ecosystem",
    "title": "Perturbation Analysis",
    "section": "Julia package ecosystem",
    "text": "Julia package ecosystem\n\nLarge package ecosystem\nFairly good quality native code\nWrappers to low-level / foreign language libraries\n\nC: ccall\nFortran: fcall\nPython: PyCall",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#how-do-you-install-pckages",
    "href": "slides/session_3/index.html#how-do-you-install-pckages",
    "title": "Perturbation Analysis",
    "section": "How do you install pckages?",
    "text": "How do you install pckages?\n\nShort and wrong answer: ] add PackageName\nBetter answer:\n\na project environment specifies all dependencies for a project\n\ninformations are contained in Project.toml\n\nchange directory to the right project\n\n; cd path_to_the_right_project\nyou can check where you are ; pwd (print working directory)\n\nactivate environment:\n\n] activate . (. universally means current director)\n\nadd desired package:\n\n] add PackageName\n\nwhen you restart work on a project activate, it again, to ensure you have the right dependencies",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#main-approaches",
    "href": "slides/session_3/index.html#main-approaches",
    "title": "Perturbation Analysis",
    "section": "Main approaches",
    "text": "Main approaches\n\nBack to our problem, how to we differentiate the model?\nMain approaches:\n\nManual\nFinite Differences\nSymbolic Differentiation\nAutomatic Differentiation",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#manual-differentiation",
    "href": "slides/session_3/index.html#manual-differentiation",
    "title": "Perturbation Analysis",
    "section": "Manual Differentiation",
    "text": "Manual Differentiation\n\nTrick:\n\nnever use \\(\\frac{d}{dx} \\frac{u(x)}{v(x)} = \\frac{u'(x)v(x)-u(x)v'(x)}{v(x)^2}\\)\n\ntoo error prone\n\nuse instead \\[\\frac{d}{dx} {u(x)v(x)} = {u'(x)v(x)+u(x)v'(x)}\\] and \\[\\frac{d}{dx} \\frac{1}{u(x)} = -\\frac{u^{\\prime}}{u(x)^2}\\]\n\nYou can get easier calculations (in some cases) by using log-deviation rules",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#finite-differences",
    "href": "slides/session_3/index.html#finite-differences",
    "title": "Perturbation Analysis",
    "section": "Finite Differences",
    "text": "Finite Differences\n\n\n\n\nChoose small \\(\\epsilon&gt;0\\), typically \\(\\sqrt{ \\textit{machine eps}}\\)\n\ncheck eps()\n\nForward Difference scheme:\n\n\\(f'(x) \\approx \\frac{f(x+\\epsilon) - f(x)}{\\epsilon}\\)\nprecision: \\(O(\\epsilon)\\)\nbonus: if \\(f(x+\\epsilon)\\) can compute \\(f(x)-f(x-\\epsilon)\\) instead (Backward)\n\nCentral Difference scheme:\n\nFinite \\(f'(x) \\approx \\frac{f(x+\\epsilon) - f(x-\\epsilon)}{2\\epsilon}\\)\naverage of forward and backward\nprecision: \\(O(\\epsilon^2)\\)\n\n\n\n\nTwo packages FiniteDiff and FiniteDifferences.\nExample:\nusing FiniteDiff\n\ng(x) = [x[1]^2 x[2]^3]\nFiniteDiff.finite_difference_jacobian(g, [0.1, 0.2])",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#finite-differences-higher-order",
    "href": "slides/session_3/index.html#finite-differences-higher-order",
    "title": "Perturbation Analysis",
    "section": "Finite Differences: Higher order",
    "text": "Finite Differences: Higher order\n\nCentral formula: \\[\n\\begin{aligned}\nf''(x) & \\approx & \\frac{f'(x)-f'(x-\\epsilon)}{\\epsilon} \\approx \\frac{(f(x+\\epsilon))-f(x))-(f(x)-f(x-\\epsilon))}{\\epsilon^2} \\\\ & = & \\frac{f(x+\\epsilon)-2f(x)+f(x-\\epsilon)}{\\epsilon^2}\n\\end{aligned}\n\\]\n\nprecision: \\(o(\\epsilon)\\)\n\nGeneralizes to higher order but becomes more and more innacurate",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#symbolic-differentiation",
    "href": "slides/session_3/index.html#symbolic-differentiation",
    "title": "Perturbation Analysis",
    "section": "Symbolic Differentiation",
    "text": "Symbolic Differentiation\n\n\n\nmanipulate the tree of algebraic expressions\n\nimplements various simplification rules\n\nrequires mathematical expression\ncan produce mathematical insights\nsometimes inaccurate:\n\ncf: \\(\\left(\\frac{1+u(x)}{1+v(x)}\\right)^{100}\\)\n\n\n\nTwo main libraries:\n\nSymEngine.jl\n\nfast symbolic calculation\nmature C++ engine\n\nSymbolics.jl:\n\npure julia\nfinite difference\nsymbolic calculation\n\n\nExample using Symbolics:\nusing Symbolics\n@variables a x b y\neq = a*sin(x) + b*cos(y)\nSymbolics.derivative(eq, x)",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#automatic-differentiation",
    "href": "slides/session_3/index.html#automatic-differentiation",
    "title": "Perturbation Analysis",
    "section": "Automatic Differentiation",
    "text": "Automatic Differentiation\n\nAutomatic Differentiation\n\ndoes not provide mathematical insights but solves the other problems\ncan differentiate any piece of code\ntwo flavours\n\nforward accumulation\nreverse accumulation",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#automatic-source-code-rewrite",
    "href": "slides/session_3/index.html#automatic-source-code-rewrite",
    "title": "Perturbation Analysis",
    "section": "Automatic source code rewrite",
    "text": "Automatic source code rewrite\n\n\nConsider this simple function\nfunction f(x::Number)\n\n    a = x + 1\n    b = x^2\n    c = sin(a) \n    d = c + b\n\n    return d\n\nend\n\nWe can rewrite the code as follows:\nfunction f(x::Number)\n\n    # x is an argument\n    x_dx = 1.0\n\n    a = x + 1\n    a_dx = x_dx\n\n    b = x^2\n    b_dx = 2*x*x_dx\n\n    c = sin(a)\n    c_x = cos(a)*a_dx\n\n    d = c + b\n    d_x = c_dx + b_dx\n\n    return (d, d_x)\nend",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#dual-numbers-operator-overloading",
    "href": "slides/session_3/index.html#dual-numbers-operator-overloading",
    "title": "Perturbation Analysis",
    "section": "Dual numbers: operator overloading",
    "text": "Dual numbers: operator overloading\nInstead of rewriting source code, we can use dual numbers to perform exactly the same calculations.\nstruct DN&lt;:Number\n    x::Float64\n    dx::Float64\nend\n\n+(a::DN,b::DN) = DN(a.x+b.x, a.dx+b.dx)\n-(a::DN,b::DN) = DN(a.x-b.x, a.dx-b.dx)\n*(a::DN,b::DN) = DN(a.x*b.x, a.x*b.dx+a.dx*b.x)\n/(a::DN,b::DN) = DN(a.x/b.x, (a.dx*b.x-a.x*b.dx)/b.dx^2)\n\n...\nTry it on function f What do we miss ?",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#dual-numbers",
    "href": "slides/session_3/index.html#dual-numbers",
    "title": "Perturbation Analysis",
    "section": "Dual numbers",
    "text": "Dual numbers\nThis approach (and automatic differentiation in general) is compatible with control flow operations (if, while, …)\nLet’s see it with the dual numbers defined by ForwardDiff library:\nimport ForwardDiff: Dual\n\nx = Dual(1.0, 1.0)\na = 0.5*x\nb = sum([(x)^i/i*(-1)^(i+1) for i=1:5000])\n# compare with log(1+x)\n\ngeneralizes nicely to gradient computations\n\nx = Dual(1.0, 1.0, 0.0)\ny = Dual(1.0, 0.0, 1.0)\nexp(x) + log(y)",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#automatic-differentiation-2",
    "href": "slides/session_3/index.html#automatic-differentiation-2",
    "title": "Perturbation Analysis",
    "section": "Automatic differentiation",
    "text": "Automatic differentiation\nThere are many flavours of automatic differenation (check JuliaDiff.org)\n \n \n\n\nForward Accumulation Mode\n\nisomorphic to dual number calculation\ncompute values and derivatives at the same time\nefficient for \\(f: R^n\\rightarrow R^m\\), with \\(n&lt;&lt;m\\)\n\n(keeps lots of empty gradients when \\(n&gt;&gt;m\\))\n\n\n\nReverse Accumulation Mode\n\nReverse Accumulation / Back Propagation\n\nefficient for \\(f: R^n\\rightarrow R^m\\), with \\(n&gt;&gt;m\\)\nrequires data storage (to keep intermediate values)\ngraph / example\n\nVery good for machine learning:\n\n\\(\\nabla_{\\theta} F(x;\\theta)\\) where \\(F\\) is a scalar objective",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#libraries-for-autodiff",
    "href": "slides/session_3/index.html#libraries-for-autodiff",
    "title": "Perturbation Analysis",
    "section": "Libraries for AutoDiff",
    "text": "Libraries for AutoDiff\n\nSee JuliaDiff: http://www.juliadiff.org/\n\nForwardDiff.jl\nReverseDiff.jl\n\nZygote.jl\nDeep learning framework:\n\nhigher order diff w.r.t. any vector -&gt; tensor operations\nFlux.jl, MXNet.jl, Tensorflow.jl\n\n\n\n\n\n\n\n\n\nExample with ForwardDiff\n\n\nExample with ForwardDiff:\n  using ForwardDiff\nForwardDiff.jacobian(u-&gt;[u[1]^2, u[2]+u[1]], [0.1,0.2])",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#our-problem",
    "href": "slides/session_3/index.html#our-problem",
    "title": "Perturbation Analysis",
    "section": "Our problem",
    "text": "Our problem\n\n\nGeneral formulation of a linearized model: \\[ \\begin{eqnarray} A s_t + B x_t + C s_{t+1} + D x_{t+1} & = & 0_{n_x} \\\\\ns_{t+1} & = & E s_t + F x_t \\end{eqnarray}\\] where:\n\n\\(s_t \\in \\mathbb{R}^{n_s}\\) is a vector of states\n\\(x_t \\in \\mathbb{R}^{n_x}\\) is a vector of controls\n\nRemark:\n\nfirst equation is forward looking\nsecond equation is backward looking\n\n\nIn the neoclassical model: \\[\\begin{eqnarray}\ns_t & = & (\\Delta z_t, \\Delta k_t) \\\\\nx_t & = & (\\Delta i_t, \\Delta c_t)\n\\end{eqnarray}\\]\nThe linearized system is: \\[\\begin{eqnarray}\nA & = & ...\\\\\nB & = & ...\\\\\nC & = & ...\\\\\nD & = & ...\\\\\nE & = & ...\\\\\nF & = &\n\\end{eqnarray}\\]",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#solution",
    "href": "slides/session_3/index.html#solution",
    "title": "Perturbation Analysis",
    "section": "Solution",
    "text": "Solution\n\n\nWhat is the solution of our problem?\n\n\nAt date \\(t\\) controls must be chosen as a function of (predetermined) states\nMathematically speaking, the solution is a function \\(\\varphi\\) such that: \\[\\forall t, x_t = \\varphi(s_t)\\]\nSince the model is linear we look for un unknown matrix \\(X \\in \\mathbb{R}^{n_x} \\times \\mathbb{R}^{n_s}\\) such that: \\[\\Delta x_t = X \\Delta s_t\\]\n\n\n\nIn the neoclassical model\n\n\nThe states are \\(k_t\\) and \\(z_t\\)\nThe controls \\(i_t\\) and \\(c_t\\) must be a function of the states\n\nthere is a decision rule \\(i()\\), \\(c()\\) such that \\[i_t = i(z_t, k_t)\\] \\[c_t = c(z_t, k_t)\\]\n\nIn the linearized model: \\[\\Delta i_t =i_z \\Delta z_t + i_k \\Delta k_t\\] \\[\\Delta c_t =c_z \\Delta z_t + c_k \\Delta k_t\\]",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#optimality-condition",
    "href": "slides/session_3/index.html#optimality-condition",
    "title": "Perturbation Analysis",
    "section": "Optimality condition:",
    "text": "Optimality condition:\n\n\nReplacing in the system: \n\\[\\Delta x_t  =  X \\Delta s_t\\] \\[\\Delta s_{t+1}  =  E \\Delta s_t + F X \\Delta s_t\\] \\[\\Delta x_{t+1}  =  X \\Delta s_{t+1}\\] \\[A \\Delta s_t + B \\Delta x_t + C \\Delta s_{t+1} + D \\Delta x_{t+1}  =  0\\]\nIf we make the full substitution:\n\\[( (A + B X) + ( D X + C) ( E  + F X ) ) \\Delta s_t = 0\\]\n\nThis must be true for all \\(s_t\\). We get the special Ricatti equation:\n\\[(A + B {\\color{red}{X}} ) + ( D {\\color{red}{X}} + C) ( E  + F {\\color{red}X} ) = 0\\]\nThis is a quadratic, matrix ( \\(X\\) is 2 by 2 ) equation:\n\nrequires special solution method\nthere are multiple solutions: which should we choose?\ntoday: linear time iteration selects only one solution\n\nalternative: eigenvalues analysis",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#linear-time-iteration",
    "href": "slides/session_3/index.html#linear-time-iteration",
    "title": "Perturbation Analysis",
    "section": "Linear Time Iteration",
    "text": "Linear Time Iteration\n\nLet’s be more subtle: define\n\n\\(X\\): decision rule today and\n\\(\\tilde{X}\\): is decision rule tomorrow. \\[\\begin{eqnarray}\n\\Delta x_t & =&  X \\Delta s_t \\\\\n\\Delta s_{t+1} & = & E \\Delta  s_t + F X \\Delta s_t \\\\\n\\Delta x_{t+1} & = & \\tilde{X} \\Delta s_{t+1} \\\\\nA \\Delta s_t + B \\Delta x_t + C \\Delta s_{t+1} + D \\Delta x_{t+1} & = & 0\n\\end{eqnarray}\\]\n\nWe get, \\(\\forall s_t\\): \\[(A + B X) + (C + D \\tilde{X}) ( E  + F X ) ) \\Delta s_t = 0 \\]\nAgain, this must be zero in all states \\(\\Delta s_t\\).",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#linear-time-iteration-2",
    "href": "slides/session_3/index.html#linear-time-iteration-2",
    "title": "Perturbation Analysis",
    "section": "Linear Time Iteration (2)",
    "text": "Linear Time Iteration (2)\n\n\n\nWe get the equation: \\[\\begin{eqnarray}\nF(X, \\tilde{X}) & = & (A + B X) + ( C+ D \\tilde{X}) ( E  + F X ) \\\\&=& 0\n\\end{eqnarray}\\]\nConsider the linear time iteration algorithm\nWhen the model is well-specified it is guaranteed to converge to the right solution.\n\ncf linear time iteration by Pontus Rendahl (link)\n\nThere are simple criteria to check that the solution is right, and that the model is well specified\n\\(T\\) is the time iteration operator… for linear models\n\nit does forward iteration (\\(X_t\\) as a function of \\(X_{t+1}\\))\n\n\n\nAlgorithm:\n\nchoose stopping criteria: \\(\\epsilon_0\\) and \\(\\eta_0\\)\nchoose random \\(X_0\\)\ngiven \\(X_n\\):\n\ncompute \\(X_{n+1}\\) such that \\(F(X_{n+1}, X_{n}) = 0\\) \\[(B + (C+D X_{n})F)X_{n+1} + A  + (C+D X_n )E=0\\]\\[X_{n+1} = - (B + (C + D X_n) F)^{-1} (A + (C+DX_n)E)\\]\\[X_{n+1} = T(X_n)\\]\ncompute:\n\n\\(\\eta_n = |X_{n+1} - X_n|\\)\n\\(\\epsilon_n = F(X_{n+1}, X_{n+1})\\)\n\nif \\(\\eta_n&lt;\\eta_0\\) and \\(\\epsilon_n&lt;\\epsilon_0\\)\n\nstop and return \\(X_{n+1}\\)\notherwise iterate with \\(X_{n+1}\\)",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#simulating-the-model",
    "href": "slides/session_3/index.html#simulating-the-model",
    "title": "Perturbation Analysis",
    "section": "Simulating the model",
    "text": "Simulating the model\n\nSuppose we have found the solution \\(\\Delta x_t  = X \\Delta s_t\\)\nRecall the transition equation: \\(\\Delta s_{t+1} = F \\Delta s_t + G \\Delta x_t\\)\nWe can now compute the model evolution following initial deviation in the state: \\[\\Delta s_t = \\underbrace{(F + G X)}_{P} \\Delta s_{t-1}\\]\n\n\\(P\\) is the simulation operator\nit is a backward operator (TODO: example of a reaction to a shock)\n\nThe system is stable if the biggest eigenvalue of \\(P\\) is smaller than one…\n… or if its spectral radius is smaller than 1: \\[\\rho(P)&lt;1\\]\nThis condition is called backward stability\n\nit rules out explosive solutions\nif \\(\\rho(P)&gt;1\\) one can always find \\(s_0\\) such that the model simulation diverges",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#spectral-radius",
    "href": "slides/session_3/index.html#spectral-radius",
    "title": "Perturbation Analysis",
    "section": "Spectral radius",
    "text": "Spectral radius\n\n\n\nHow do you compute the spectral radius of matrix P?\n\nnaive approach: compute all eigenvalues, check the value of the biggest one…\n\nusing LinearAlgebra\nM = rand(2,2)\nmaximum(abs, eigvals(M))\n\nbecomes limited when size of matrix growth\nanother approach: power iteration method\n\nPower iteration method:\n\nworks for matrices and linear operators\ntake a linear operator \\(L\\) over a Banach Space \\(\\mathcal{B}\\) (vector space with a norm)\nuse the fact that for most \\(u_0\\in \\mathcal{B}\\), \\(\\frac{|L^{n+1} u_0|}{|L^n u_0|}\\rightarrow \\rho(L)\\)\n\n\n\nAlgorithm:\n\nchoose tolerance criterium: \\(\\eta&gt;0\\)\nchoose random initial \\(x_0\\) and define \\(u_0 = \\frac{x_0}{|x_0|}\\)\n\nby construction: \\(|u_0|=1\\)\n\ngiven \\(u_n\\), compute\n\n\\(x_{n+1} = L.u_n\\)\n\\(u_{n+1} = \\frac{x_{n+1}}{|x_{n+1}|}\\)\ncompute \\(\\eta_{n+1} = |u_{n+1} - u_n|\\)\nif \\(\\eta_{n+1}&lt;\\eta\\):\n\nstop and return \\(|x_{n+1}|\\)\nelse iterate with \\(u_{n+1}\\)",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#stability-of-the-backward-operator",
    "href": "slides/session_3/index.html#stability-of-the-backward-operator",
    "title": "Perturbation Analysis",
    "section": "Stability of the backward operator",
    "text": "Stability of the backward operator\nTo solve the model we use the backard operator: \\[T: \\begin{eqnarray} \\mathbb{R}^{n_x} \\times \\mathbb{R}^{n_s}  & \\rightarrow &  \\mathbb{R}^{n_x} \\times \\mathbb{R}^{n_s}  \\\\X_{t+1} & \\mapsto & X_t \\text{s.t.} F(X_t,X_{t+1})=0\\end{eqnarray}\\]\n\nWhat about its stability?\nRecall: fixed point \\(\\overline{z}\\) of recursive sequence \\(z_n=f(z_{n_1})\\) is stable if \\(|f^{\\prime}(\\overline{z})|&lt;1\\)\n\n\n\n\nWe need to study \\(T^{\\prime}\\) of (\\(X\\)).\n\nbut \\(T\\) maps a matrix to another matrix 🐉😓\nhow do we differentiate it?",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#differentials",
    "href": "slides/session_3/index.html#differentials",
    "title": "Perturbation Analysis",
    "section": "Differentials",
    "text": "Differentials\n\nConsider a Banach Space \\(\\mathcal{B}\\).\nConsider an operator (i.e. a function): \\(\\mathcal{T}: \\mathcal{B} \\rightarrow \\mathcal{B}\\).\nConsider \\(\\overline{x} \\in \\mathcal{B}\\).\n\\(\\mathcal{T}\\) is differentiable at \\(\\overline{x}\\) if there exists a bounded linear operator \\(L \\in \\mathcal{L}(\\mathcal{B})\\) such that: \\[\\mathcal{T}(x) = \\overline{x} + L.(x-\\overline{x}) + o(|x-\\overline{x}|)\\]\n\nwhen it exists we denote this operator by \\(\\mathcal{T}^{\\prime}(\\overline{x})\\)\n\nRemarks:\n\nBounded operator means: \\(\\sup_{|x|=1} |L.x|&lt;+\\infty\\)\nThis definition of a derivative is usually referred to as Fréchet-derivative",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#examples-of-linear-operators",
    "href": "slides/session_3/index.html#examples-of-linear-operators",
    "title": "Perturbation Analysis",
    "section": "Examples of linear operators",
    "text": "Examples of linear operators\n\n\\(x\\) vector, A a matrix, \\(T(x) = Ax\\)\n\nthen \\(T(x+u) = Ax + A.u + 0\\)\n\\(T^{\\prime}(x) = A\\) for all x\n\n\\(A\\) a matrix, B a matrix, X a matrix: \\(T(X) = A X B\\)\n\nthen \\(T(X+u) = A X B + A u B + 0\\)\n\\(T^{\\prime}(X).u = A u B\\)\n\n\\(A\\) a matrix, X a matrix: \\(T(X) = A X B\\)\n\nthen \\(T(X+u) = A X B + A u B\\)\n\\(T^{\\prime}(X).u = A u B\\)",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#back-to-the-time-iteration-operator",
    "href": "slides/session_3/index.html#back-to-the-time-iteration-operator",
    "title": "Perturbation Analysis",
    "section": "Back to the time iteration operator",
    "text": "Back to the time iteration operator\n\n\\(T(X)\\) is implicitly defined by \\(F(T(X), X)=0\\)\n\\(F(X,Y) = (A + B X) + ( C+ D Y) ( E  + F X )\\)\n\nit is linear in \\(X\\) and in \\(Y\\)\n\n\\(F^{\\prime}_X (X, Y).u = (B + (C+DY)F) u\\)\n\na regular matrix multiplication\nits inverse is: \\(F^{\\prime}_X (X, Y)^{-1} = (B + (C+DY)F)^{-1}\\)\n\n\\(F^{\\prime}_Y (X, Y).u = D u (E+FX)\\)\n\na linear operation on matrices",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#the-derivative-of-the-time-iteration-operator",
    "href": "slides/session_3/index.html#the-derivative-of-the-time-iteration-operator",
    "title": "Perturbation Analysis",
    "section": "The derivative of the time-iteration operator",
    "text": "The derivative of the time-iteration operator\n\nImplicit relation can be differentiated: \\[F^{\\prime}_X (T(X), X) T^{\\prime} (X) + F_Y^{\\prime}(T(X),X) = 0\\]\n\\(F^{\\prime}_X (T(X), X)\\) being a regular matrix, it is (conceptually) easy to invert: \\[T^{\\prime}(X) = -(F^{\\prime}_X (T(X), X))^{-1}F_Y^{\\prime}(T(X),X)\\]\nFinally, we get the explicit formula for the linear operator \\(T^{\\prime}\\) computed at the steady state: \\[T^{\\prime}(\\overline{X}).u = ((B + (C+D \\overline{X})F)^{-1})D u (E+F \\overline{X})\\]\nWe can compute the spectral radius of \\(T^{\\prime}(\\overline{X})\\) using the power iteration method",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_3/index.html#recap",
    "href": "slides/session_3/index.html#recap",
    "title": "Perturbation Analysis",
    "section": "Recap",
    "text": "Recap\n\nWe compute the derivatives of the model\nTime iteration algorithm, starting from an initial guess \\(X_0\\) and we repeat until convergence: \\[X_{n+1} = (B + (C + D X_n) F)^{-1} (A + (C+DX_n)E)\\]\nWe compute the spectral radius of two operators to ensure the model is well defined and that the solution is the right one.\nbackward stability: derivative of simulation operator \\[\\boxed{\\rho(F + H \\overline{X} )}\\]\nforward stability: derivative of time iteration operator \\[\\boxed{\\rho \\left( u\\mapsto ((B + (C+D \\overline{X})F)^{-1})D u (E+F \\overline{X}) \\right)}\\]",
    "crumbs": [
      "Slides",
      "Perturbation Analysis"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#introduction-1",
    "href": "slides/session_4/index.html#introduction-1",
    "title": "Optimization",
    "section": "Introduction",
    "text": "Introduction\nOptimization is everywhere in economics:\n\nto model agent’s behaviour: what would a rational agent do?\n\nconsumer maximizes utility from consumption\nfirm maximizes profit\n\nan economist tries to solve a model:\n\nfind prices that clear the market",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#two-kinds-of-optimization-problem",
    "href": "slides/session_4/index.html#two-kinds-of-optimization-problem",
    "title": "Optimization",
    "section": "Two kinds of optimization problem:",
    "text": "Two kinds of optimization problem:\n\nroot finding: \\(\\text{find  $x$ in $X$ such that $f(x)=0$}\\)\nminimization/maximization \\(\\min_{x\\in X} f(x)\\) or \\(\\max_{x\\in X} f(x)\\)\noften a minimization problem can be reformulated as a root-finding problem\n\\[x_0 = {argmin}_{x\\in X} f(x) \\overbrace{\\iff}^{??} f^{\\prime} (x_0) = 0\\]",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#plan",
    "href": "slides/session_4/index.html#plan",
    "title": "Optimization",
    "section": "Plan",
    "text": "Plan\n\ngeneral consideration about optimization problems\none-dimensional root-finding\none-dimensional optimization\nlocal root-finding\nlocal optimization\nconstrained optimization\nconstrained root-finding",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#optimization-tasks-come-in-many-flavours",
    "href": "slides/session_4/index.html#optimization-tasks-come-in-many-flavours",
    "title": "Optimization",
    "section": "Optimization tasks come in many flavours",
    "text": "Optimization tasks come in many flavours\n\ncontinuous versus discrete optimization\nconstrained and unconstrained optimization\nglobal and local\nstochastic and deterministic optimization\nconvexity",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#continuous-versus-discrete-optimization",
    "href": "slides/session_4/index.html#continuous-versus-discrete-optimization",
    "title": "Optimization",
    "section": "Continuous versus discrete optimization",
    "text": "Continuous versus discrete optimization\n\nChoice is picked from a given set (\\(x\\in X\\)) which can be:\n\ncontinuous: choose amount of debt \\(b_t \\in [0,\\overline{b}]\\), of capital \\(k_t \\in R^{+}\\)\ndiscrete: choose whether to repay or default \\(\\delta\\in{0,1}\\), how many machines to buy (\\(\\in N\\)), at which age to retire…\na combination of both: mixed integer programming",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#continuous-versus-discrete-optimization-2",
    "href": "slides/session_4/index.html#continuous-versus-discrete-optimization-2",
    "title": "Optimization",
    "section": "Continuous versus discrete optimization (2)",
    "text": "Continuous versus discrete optimization (2)\n\nDiscrete optimization requires a lot of combinatorial thinking\n\nWe don’t cover it today.\n…if needed, we just test all choices until we find the best one\n\nSometimes a discrete choice can be approximated by a mixed strategy (i.e. a random strategy).\n\nInstead of \\(\\delta\\in{0,1}\\) we choose \\(x\\) in \\(prob(\\delta=1)=\\sigma(x)\\)\nwith \\(\\sigma(x)=\\frac{2}{1+\\exp(-x)}\\)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#constrained-and-unconstrained-optimization",
    "href": "slides/session_4/index.html#constrained-and-unconstrained-optimization",
    "title": "Optimization",
    "section": "Constrained and Unconstrained optimization",
    "text": "Constrained and Unconstrained optimization\n\nUnconstrained optimization: \\(x\\in R\\)\nConstrained optimization: \\(x\\in X\\)\n\nbudget set: \\(p_1 c_1 + p_2 c_2 \\leq I\\)\npositivity of consumption: \\(c \\geq 0\\).\n\nIn good cases, the optimization set is convex…\n\npretty much always in this course",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#stochastic-vs-determinstic",
    "href": "slides/session_4/index.html#stochastic-vs-determinstic",
    "title": "Optimization",
    "section": "Stochastic vs Determinstic",
    "text": "Stochastic vs Determinstic\n\nCommon case, especially in machine learning \\[f(x) = E_{\\epsilon}[ \\xi (\\epsilon, x)]\\]\nOne wants to maximize (resp solve) w.r.t. \\(x\\) but it is costly to compute expectation precisely using Monte-Carlo draws (there are other methods).\nA stochastic optimization method allows to use noisy estimates of the expectation, and will still converge in expectation.\nFor now we focus on deterministic methods. Maybe later…",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#local-vs-global-algorithms",
    "href": "slides/session_4/index.html#local-vs-global-algorithms",
    "title": "Optimization",
    "section": "Local vs global Algorithms",
    "text": "Local vs global Algorithms\n\nIn principle, there can be many roots (resp maxima) within the optimization set.\nAlgorithms that find them all are called “global”. For instance:\n\ngrid search\nsimulated annealing\n\nWe will deal only with local algorithms, and consider local convergence properties.\n\n-&gt;then it might work or not\nto perform global optimization just restart from different points.",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#math-vs-practice",
    "href": "slides/session_4/index.html#math-vs-practice",
    "title": "Optimization",
    "section": "Math vs practice",
    "text": "Math vs practice\n\nThe full mathematical treatment will typically assume that \\(f\\) is smooth (\\(\\mathcal{C}_1\\) or \\(\\mathcal{C}_2\\) depending on the algorithm).\nIn practice we often don’t know about these properties\n\nwe still try and check thqt we have a local optimal\n\nSo: fingers crossed",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#math-vs-practice-1",
    "href": "slides/session_4/index.html#math-vs-practice-1",
    "title": "Optimization",
    "section": "Math vs practice",
    "text": "Math vs practice\nHere is the surface representing the objective that a deep neural network training algorithm tries to minimize.\n\nAnd yet, neural networks do great things!",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#what-do-you-need-to-know",
    "href": "slides/session_4/index.html#what-do-you-need-to-know",
    "title": "Optimization",
    "section": "What do you need to know?",
    "text": "What do you need to know?\n\nbe able to handcode simple algos (Newton, Gradient Descent)\nunderstand the general principle of the various algorithms to compare them in terms of\n\nrobustness\nefficiency\naccuracy\n\nthen you can just switch the various options, when you use a library…",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#bisection",
    "href": "slides/session_4/index.html#bisection",
    "title": "Optimization",
    "section": "Bisection",
    "text": "Bisection\n\nFind \\(x \\in [a,b]\\) such that \\(f(x) = 0\\). Assume \\(f(a)f(b) &lt;0\\).\nAlgorithm\n\nStart with \\(a_n, b_n\\). Set \\(c_n=(a_n+b_n)/2\\)\nCompute \\(f(c_n)\\)\n\n\nif \\(f(c_n)f(a_n)&lt;0\\) then set \\((a_{n+1},b_{n+1})=(a_n,c_n)\\)\nelse set \\((a_{n+1},b_{n+1})=(c_n,b_n)\\)\n\n\nIf \\(|f(c_n)|&lt;\\epsilon\\) and/or \\(\\frac{b-a}{2^n}&lt;\\delta\\) stop. Otherwise go back to 1.",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#bisection-2",
    "href": "slides/session_4/index.html#bisection-2",
    "title": "Optimization",
    "section": "Bisection (2)",
    "text": "Bisection (2)\n\nNo need for initial guess: globally convergent algorithm\n\nnot a global algorithm…\n… in the sense that it doesn’t find all solutions\n\n\\(\\delta\\) is a guaranteed accuracy on \\(x\\)\n\\(\\epsilon\\) is a measure of how good the solution is\nthink about your tradeoff: (\\(\\delta\\) or \\(\\epsilon\\) ?)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#newton-algorithm",
    "href": "slides/session_4/index.html#newton-algorithm",
    "title": "Optimization",
    "section": "Newton algorithm",
    "text": "Newton algorithm\n\nFind \\(x\\) such that \\(f(x) = 0\\). Use \\(x_0\\) as initial guess.\n\\(f\\) must be \\(\\mathcal{C_1}\\) and we assume we can compute its derivative \\(f^{\\prime}\\)\nGeneral idea:\n\nobserve that the zero \\(x^{\\star}\\) must satisfy \\[f(x^{\\star})=0=f(x_0)+f^{\\prime}(x_0)(x^{\\star}-x_0) + o(x-x_0)\\]\nHence a good approximation should be \\[x^{\\star}\\approx = x_0- f(x_0)/f^{\\prime}(x_0)\\]\nCheck it is good. otherwise, replace \\(x_0\\) by \\(x^{\\star}\\)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#newton-algorithm-2",
    "href": "slides/session_4/index.html#newton-algorithm-2",
    "title": "Optimization",
    "section": "Newton algorithm (2)",
    "text": "Newton algorithm (2)\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n- \\frac{f(x_n)}{f^{\\prime}(x_n)}=f^{\\text{newton}}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#quasi-newton",
    "href": "slides/session_4/index.html#quasi-newton",
    "title": "Optimization",
    "section": "Quasi-Newton",
    "text": "Quasi-Newton\n\nWhat if we can’t compute \\(f^{\\prime}\\) or it is expensive to do so?\n\nIdea: try to approximate \\(f^{\\prime}(x_n)\\) from the last iterates\n\nSecant method: \\[f^{\\prime}(x_n)\\approx \\frac{f(x_n)-f(x_{n-1})}{x_n-x_{n-1}}\\] \\[x_{n+1} = x_n- f(x_n)\\frac{x_n-x_{n-1}}{f(x_n)-f(x_{n-1})}\\]\n\nrequires two initial guesses: \\(x_1\\) and \\(x_0\\)\nsuperlinear convergence: \\(\\lim \\frac{x_t-x^{\\star}}{x_{t-1}-x^{\\star}}\\rightarrow 0\\)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#limits-of-newtons-method",
    "href": "slides/session_4/index.html#limits-of-newtons-method",
    "title": "Optimization",
    "section": "Limits of Newton’s method",
    "text": "Limits of Newton’s method\n\nHow could Newton method fail?\n\nbad guess\n\n-&gt; start with a better guess\n\novershoot\n\n-&gt; dampen the update (problem: much slower)\n-&gt; backtrack\n\nstationary point\n\n-&gt; if root of multiplicity \\(m\\) try \\(x_{n+1} = x_n- m \\frac{f(x_n)}{f^{\\prime}(x_n)}\\)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#backtracking",
    "href": "slides/session_4/index.html#backtracking",
    "title": "Optimization",
    "section": "Backtracking",
    "text": "Backtracking\n\nSimple idea:\n\nat stage \\(n\\) given \\(f(x_n)\\) compute Newton step \\(\\Delta_n=-\\frac{f(x_n)}{f^{\\prime}(x_n)}\\)\nfind the smallest \\(k\\) such that \\(|f(x_n-\\Delta/2^k)|&lt;|f(x_n)|\\)\nset \\(x_{n+1}=x_n-\\Delta/2^k\\)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#golden-section-search",
    "href": "slides/session_4/index.html#golden-section-search",
    "title": "Optimization",
    "section": "Golden section search",
    "text": "Golden section search\n\nMinimize \\(f(x)\\) for \\(x \\in [a,b]\\)\nChoose \\(\\Phi \\in [0,0.5]\\)\nAlgorithm:\n\nstart with \\(a_n &lt; b_n\\) (initially equal to \\(a\\) and \\(b\\))\ndefine \\(c_n = a_n+\\Phi(b_n-a_n)\\) and \\(d_n = a_n+(1-\\Phi)(b_n-a_n)\\)\n\nif \\(f(c_n)&lt;f(d_n)\\) set \\(a_{n+1},b_{n+1}=a_n, d_n\\)\nelse set \\(a_{n+1}, b_{n+1}= c_n, b_n\\)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#golden-section-search-2",
    "href": "slides/session_4/index.html#golden-section-search-2",
    "title": "Optimization",
    "section": "Golden section search (2)",
    "text": "Golden section search (2)\n\nThis is guaranteed to converge to a local minimum\nIn each step, the size of the interval is reduced by a factor \\(\\Phi\\)\nBy choosing \\(\\Phi=\\frac{\\sqrt{5}-1}{2}\\) one can save one evaluation by iteration.\n\nyou can check that either \\(c_{n+1} = d_n\\) or \\(d_{n+1} = c_n\\)\n\nRemark that bisection is not enough",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#gradient-descent",
    "href": "slides/session_4/index.html#gradient-descent",
    "title": "Optimization",
    "section": "Gradient Descent",
    "text": "Gradient Descent\n\nMinimize \\(f(x)\\) for \\(x \\in R\\) given initial guess \\(x_0\\)\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n (1-\\lambda)- \\lambda f^{\\prime}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f^{\\prime}(x_n)| &lt; \\epsilon\\)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#gradient-descent-2",
    "href": "slides/session_4/index.html#gradient-descent-2",
    "title": "Optimization",
    "section": "Gradient Descent (2)",
    "text": "Gradient Descent (2)\n\nUses local information\n\none needs to compute the gradient\nnote that gradient at \\(x_n\\) does not provide a better guess for the minimum than \\(x_n\\) itself\nlearning speed is crucial\n\nConvergence speed: linear\n\nrate depend on the learning speed\noptimal learning speed? the fastest for which there is convergence",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#newton-raphson-method",
    "href": "slides/session_4/index.html#newton-raphson-method",
    "title": "Optimization",
    "section": "Newton-Raphson method",
    "text": "Newton-Raphson method\n\nMinimize \\(f(x)\\) for \\(x \\in R\\) given initial guess \\(x_0\\)\nBuild a local model of \\(f\\) around \\(x_0\\) \\[f(x) = f(x_0) + f^{\\prime}(x_0)(x-x_0) + f^{\\prime\\prime}(x_0)\\frac{(x-x_0)^2}{2} + o(x-x_0)^2\\]\nAccording to this model, \\[ f(x{\\star}) = min_x f(x)\\iff \\frac{d}{d x} \\left[ f(x_0) + f^{\\prime}(x_0)(x-x_0) + f^{\\prime\\prime}(x_0)\\frac{(x-x_0)^2}{2} \\right] = 0\\] which yields: \\(x^{\\star} = x_0 - \\frac{f^{\\prime}(x_0)}{f^{\\prime\\prime}(x_0)}\\)\nthis is Newton applied to \\(f^{\\prime}(x)=0\\)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#newton-raphson-algorithm-2",
    "href": "slides/session_4/index.html#newton-raphson-algorithm-2",
    "title": "Optimization",
    "section": "Newton-Raphson Algorithm (2)",
    "text": "Newton-Raphson Algorithm (2)\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n-\\frac{f^{\\prime}(x_0)}{f^{\\prime\\prime}(x_0)}\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f^{\\prime}(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#unconstrained-problems",
    "href": "slides/session_4/index.html#unconstrained-problems",
    "title": "Optimization",
    "section": "Unconstrained problems",
    "text": "Unconstrained problems\n\nMinimize \\(f(x)\\) for \\(x \\in R^n\\) given initial guess \\(x_0 \\in R^n\\)\nMany intuitions from the 1d case, still apply\n\nreplace derivatives by gradient, jacobian and hessian\nrecall that matrix multiplication is not commutative\n\nSome specific problems:\n\nupdate speed can be specific to each dimension\nsaddle-point issues (for minimization)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#quick-terminology",
    "href": "slides/session_4/index.html#quick-terminology",
    "title": "Optimization",
    "section": "Quick terminology",
    "text": "Quick terminology\nFunction \\(f: R^p \\rightarrow R^q\\)\n\nJacobian: \\(J(x)\\) or \\(f^{\\prime}_x(x)\\), \\(p\\times q\\) matrix such that: \\[J(x)_{ij} = \\frac{\\partial f(x)_i}{\\partial x_j}\\]\nGradient: \\(\\nabla f(x) = J(x)\\), gradient when \\(q=1\\)\nHessian: denoted by \\(H(x)\\) or \\(f^{\\prime\\prime}_{xx}(x)\\) when \\(q=1\\): \\[H(x)_{jk} = \\frac{\\partial f(x)}{\\partial x_j\\partial x_k}\\]\nIn the following explanations, \\(|x|\\) denotes the supremum norm, but most of the following explanations also work with other norms.",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#multidimensional-newton-raphson",
    "href": "slides/session_4/index.html#multidimensional-newton-raphson",
    "title": "Optimization",
    "section": "Multidimensional Newton-Raphson",
    "text": "Multidimensional Newton-Raphson\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n- J(x_{n})^{-1}f(x_n)=f^{\\text{newton}}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#multidimensional-newton-root-finding-2",
    "href": "slides/session_4/index.html#multidimensional-newton-root-finding-2",
    "title": "Optimization",
    "section": "Multidimensional Newton root-finding (2)",
    "text": "Multidimensional Newton root-finding (2)\n\nwhat matters is the computation of the step \\(\\Delta_n = {\\color{\\red}{J(x_{n})^{-1}}} f(x_n)\\)\ndon’t compute \\(J(x_n)^{-1}\\)\n\nit takes less operations to compute \\(X\\) in \\(AX=Y\\) than \\(A^{-1}\\) then \\(A^{-1}Y\\)\nin Julia: X = A \\ Y\n\nstrategies to improve convergence:\n\ndampening: \\(x_n = (1-\\lambda)x_{n-1} - \\lambda \\Delta_n\\)\nbacktracking: choose \\(k\\) such that \\(|f(x_n-2^{-k}\\Delta_n)|\\)&lt;\\(|f(x_{n-1})|\\)\nlinesearch: choose \\(\\lambda\\in[0,1]\\) so that \\(|f(x_n-\\lambda\\Delta_n)|\\) is minimal",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#multidimensional-gradient-descent",
    "href": "slides/session_4/index.html#multidimensional-gradient-descent",
    "title": "Optimization",
    "section": "Multidimensional Gradient Descent",
    "text": "Multidimensional Gradient Descent\n\nMinimize \\(f(x) \\in R\\) for \\(x \\in R^n\\) given \\(x_0 \\in R^n\\)\nAlgorithm\n\nstart with \\(x_n\\) \\[x_{n+1} = (1-\\lambda) x_n - \\lambda \\nabla f(x_n)\\]\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nComments:\n\nlots of variants\nautomatic differentiation software makes gradient easy to compute\nconvergence is typically linear",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#gradient-descent-variants",
    "href": "slides/session_4/index.html#gradient-descent-variants",
    "title": "Optimization",
    "section": "Gradient descent variants",
    "text": "Gradient descent variants",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#multidimensional-newton-minimization",
    "href": "slides/session_4/index.html#multidimensional-newton-minimization",
    "title": "Optimization",
    "section": "Multidimensional Newton Minimization",
    "text": "Multidimensional Newton Minimization\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n-{\\color{\\red}{H(x_{n})^{-1}}}\\color{\\green}{ J(x_n)'}\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic\nProblem:\n\n\\(H(x_{n})\\) hard to compute efficiently\nrather unstable",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#quasi-newton-method-for-multidimensional-minimization",
    "href": "slides/session_4/index.html#quasi-newton-method-for-multidimensional-minimization",
    "title": "Optimization",
    "section": "Quasi-Newton method for multidimensional minimization",
    "text": "Quasi-Newton method for multidimensional minimization\n\nRecall the secant method:\n\n\\(f(x_{n-1})\\) and \\(f(x_{n-2})\\) are used to approximate \\(f^{\\prime}(x_{n-2})\\).\nIntuitively, \\(n\\) iterates would be needed to approximate a hessian of size \\(n\\)….\n\nBroyden method: takes \\(2 n\\) steps to solve a linear problem of size \\(n\\)\n\nuses past information incrementally",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#quasi-newton-method-for-multidimensional-minimization-1",
    "href": "slides/session_4/index.html#quasi-newton-method-for-multidimensional-minimization-1",
    "title": "Optimization",
    "section": "Quasi-Newton method for multidimensional minimization",
    "text": "Quasi-Newton method for multidimensional minimization\n\nConsider the approximation: \\[f(x_n)-f(x_{n-1}) \\approx J(x_n) (x_n - x_{n-1})\\]\n\n\\(J(x_n)\\) is unknown and cannot be determined directly as in the secant method.\nidea: \\(J(x_n)\\) as close as possible to \\(J(x_{n-1})\\) while solving the secant equation\nformula: \\[J_n = J_{n-1} + \\frac{(f(x_n)-f(x_{n-1})) - J_{n-1}(x_n-x_{n-1})}{||x_n-x_{n-1}||^2}(x_n-x_{n-1})^{\\prime}\\]",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#gauss-newton-minimization",
    "href": "slides/session_4/index.html#gauss-newton-minimization",
    "title": "Optimization",
    "section": "Gauss-Newton Minimization",
    "text": "Gauss-Newton Minimization\n\nRestrict to least-square minimization: \\(min_x \\sum_i f(x)_i^2 \\in R\\)\nThen up to first order, \\(H(x_n)\\approx J(x_n)^{\\prime}J(x_n)\\)\nUse the step: \\(({J(x_n)^{\\prime}J(x_n)})^{-1}\\color{\\green}{ J(x_n)}\\)\nConvergence:\n\ncan be quadratic at best\nlinear in general",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#levenberg-marquardt",
    "href": "slides/session_4/index.html#levenberg-marquardt",
    "title": "Optimization",
    "section": "Levenberg-Marquardt",
    "text": "Levenberg-Marquardt\n\nLeast-square minimization: \\(min_x \\sum_i f(x)_i^2 \\in R\\)\nreplace \\({J(x_n)^{\\prime}J(x_n)}^{-1}\\) by \\({J(x_n)^{\\prime}J(x_n)}^{-1} +\\mu I\\)\n\nadjust \\(\\lambda\\) depending on progress\n\nuses only gradient information like Gauss-Newton\nequivalent to Gauss-Newton close to the solution (\\(\\mu\\) small)\nequivalent to Gradient far from solution (\\(\\mu\\) high)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#consumption-optimization",
    "href": "slides/session_4/index.html#consumption-optimization",
    "title": "Optimization",
    "section": "Consumption optimization",
    "text": "Consumption optimization\nConsider the optimization problem: \\[\\max U(x_1, x_2)\\]\nunder the constraint \\(p_1 x_1 + p_2 x_2 \\leq B\\)\nwhere \\(U(.)\\), \\(p_1\\), \\(p_2\\) and \\(B\\) are given.\nHow do you find a solution by hand?",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#consumption-optimization-1",
    "href": "slides/session_4/index.html#consumption-optimization-1",
    "title": "Optimization",
    "section": "Consumption optimization (1)",
    "text": "Consumption optimization (1)\n\nCompute by hand\nEasy:\n\nsince the budget constraint must be binding, get rid of it by stating \\(x_2 = B - p_1 x_1\\)\nthen maximize in \\(x_1\\), \\(U(x_1, B - p_1 x_1)\\) using the first order conditions.\n\nIt works but:\n\nbreaks symmetry between the two goods\nwhat if there are other constraints: \\(x_1\\geq \\underline{x}\\)?\nwhat if constraints are not binding?\nis there a better way to solve this problem?",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#consumption-optimization-2",
    "href": "slides/session_4/index.html#consumption-optimization-2",
    "title": "Optimization",
    "section": "Consumption optimization (2)",
    "text": "Consumption optimization (2)\n\nAnother method, which keeps the symmetry. Constraint is binding, trying to minimize along the budget line yields an implicit relation between \\(d x_1\\) and \\(d x_2\\) \\[p_1 d {x_1} + p_2 d {x_2} = 0\\]\nAt the optimal: \\(U^{\\prime}_{x_1}(x_1, x_2)d {x_1} + U^{\\prime}_{x_2}(x_1, x_2)d {x_2} = 0\\)\nEliminate \\(d {x_1}\\) and \\(d {x_2}\\) to get one condition which characterizes optimal choices for all possible budgets. Combine with the budget constraint to get a second condition.",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#penalty-function",
    "href": "slides/session_4/index.html#penalty-function",
    "title": "Optimization",
    "section": "Penalty function",
    "text": "Penalty function\n\nTake a penalty function \\(p(x)\\) such that \\(p(x)=K&gt;0\\) if \\(x&gt;0\\) and \\(p(x)=0\\) if \\(x \\leq 0\\). Maximize: \\(V(x_1, x_2) = U(x_1, x_2) - p( p_1 x_1 + p_2 x_2 - B)\\)\nClearly, \\(\\min U \\iff \\min V\\)\nProblem: \\(\\nabla V\\) is always equal to \\(\\nabla U\\).\nSolution: use a smooth solution function like \\(p(x) = x^2\\)\nProblem: distorts optimization\n\nSolution: adjust weight of barrier and minimize \\(U(x_1, x_2) - \\kappa p(x)\\)\n\nPossible but hard to choose the weights/constraints.",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#penalty-function-1",
    "href": "slides/session_4/index.html#penalty-function-1",
    "title": "Optimization",
    "section": "Penalty function",
    "text": "Penalty function\n\nAnother idea: is there a canonical way to choose \\(\\lambda\\) such that at the minimum it is equivalent to minimize the original problem under constraint or to minimize \\[V(x_1, x_2) = U(x_1, x_2) - \\lambda (p_1 x_1 + p_2 x_2 - B)\\]\nClearly, when the constraint is not binding we must have \\(\\lambda=0\\). What should be the value of \\(\\lambda\\) when the constraint is binding ?",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#karush-kuhn-tucker-conditions",
    "href": "slides/session_4/index.html#karush-kuhn-tucker-conditions",
    "title": "Optimization",
    "section": "Karush-Kuhn-Tucker conditions",
    "text": "Karush-Kuhn-Tucker conditions\n\nIf \\((x^{\\star},y^{\\star})\\) is optimal there exists \\(\\lambda\\) such that:\n\n\\((x^{\\star},y^{\\star})\\) maximizes lagrangian \\(\\mathcal{L} = U(x_1, x_2) + \\lambda (B- p_1 x_1 - p_2 x_2)\\)\n\\(\\lambda \\geq 0\\)\n\\(B- p_1 x_1 - p_2 x_2 \\geq 0\\)\n\\(\\lambda  (B - p_1 x_1 - p_2 x_2 ) = 0\\)\n\nThe three latest conditions are called “complementarity” or “slackness” conditions\n\nthey are equivalent to \\(\\min(\\lambda, B - p_1 x_1 - p_2 x_2)=0\\)\nwe denote \\(\\lambda \\geq 0 \\perp B- p_1 x_1 + p_2 x_2  \\geq 0\\)\n\n\\(\\lambda\\) can be interpreted as the welfare gain of relaxing the constraint.",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#karush-kuhn-tucker-conditions-1",
    "href": "slides/session_4/index.html#karush-kuhn-tucker-conditions-1",
    "title": "Optimization",
    "section": "Karush-Kuhn-Tucker conditions",
    "text": "Karush-Kuhn-Tucker conditions\n\nWe can get first order conditions that factor in the constraints:\n\n\\(U^{\\prime}_x - \\lambda p_1 = 0\\)\n\\(U^{\\prime}_y - \\lambda p_2 = 0\\)\n\\(\\lambda \\geq 0 \\perp B-p_1 x_1 -p_2 x_2 \\geq 0\\)\n\nIt is now a nonlinear system of equations with complementarities (NCP)\n\nthere are specific solution methods to deal with it",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#solution-strategies-for-ncp-problems",
    "href": "slides/session_4/index.html#solution-strategies-for-ncp-problems",
    "title": "Optimization",
    "section": "Solution strategies for NCP problems",
    "text": "Solution strategies for NCP problems\n\nGeneral formulation for vector-valued functions \\[f(x)\\geq 0 \\perp g(x)\\geq 0\\] means \\[\\forall i, f_i(x)\\geq 0 \\perp g_i(x)\\geq 0\\]\n\nNCP do not necessarily arise from a single optimization problem\n\nThere are robust (commercial) solvers for NCP problems (PATH, Knitro) for that\nHow do we solve it numerically?\n\nassume constraint is binding then non-binding then check which one is good\n\nOK if not too many constraints\n\nreformulate it as a smooth problem\napproximate the system by a series of linear complementarities problems (LCP)",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#smooth-method",
    "href": "slides/session_4/index.html#smooth-method",
    "title": "Optimization",
    "section": "Smooth method",
    "text": "Smooth method\n\nConsider the Fisher-Burmeister function \\[\\phi(a,b) = a+b-\\sqrt{a^2+b^2}\\]\nIt is infinitely differentiable, except at \\((0,0)\\)\nShow that \\(\\phi(a,b) = 0 \\iff \\min(a,b)=0 \\iff a\\geq 0 \\perp b \\geq 0\\)\nAfter substitution in the original system one can use regular non-linear solver\n\nfun fact: the formulation with a \\(\\min\\) is nonsmooth but also works quite often",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/session_4/index.html#optimization-libraries",
    "href": "slides/session_4/index.html#optimization-libraries",
    "title": "Optimization",
    "section": "Optimization libraries",
    "text": "Optimization libraries\n\nRobust optimization code is contained in the following libraries:\n\nRoots.jl: one-dimensional root finding\nNLSolve.jl: multidimensional root finding (+complementarities)\nOptim.jl: minimization\n\nThe two latter libraries have a somewhat peculiar API, but it’s worth absorbing it.\n\nin particular they provide non-allocating algorithms for functions that modify arguments in place\nthey are compatible with automatic differentiation\n\n\njulia&gt; f(x) = [x[1] - x[2] - 1, x[1] + x[2]]\nf (generic function with 1 method)\n\njulia&gt; NLsolve.nlsolve(f, [0., 0.0])\nResults of Nonlinear Solver Algorithm\n * Algorithm: Trust-region with dogleg and autoscaling\n * Starting Point: [0.0, 0.0]\n * Zero: [0.5000000000009869, -0.5000000000009869]\n * Inf-norm of residuals: 0.000000       \n * Iterations: 1                       \n * Convergence: true\n   * |x - x'| &lt; 0.0e+00: false\n   * |f(x)| &lt; 1.0e-08: true                           \n * Function Calls (f): 2\n * Jacobian Calls (df/dx): 2",
    "crumbs": [
      "Slides",
      "Optimization"
    ]
  },
  {
    "objectID": "slides/interpolation.html#basics",
    "href": "slides/interpolation.html#basics",
    "title": "Interpolation",
    "section": "Basics",
    "text": "Basics\nTwo continuous sets \\(X\\in R^p\\), \\(Y \\in R^q\\).\nData set: \\((x_i, y_i)_{i\\in[1,N]} \\in X \\times Y\\)\nTake \\(\\tilde{x} \\in X \\setminus \\{x_i\\}_{i\\in[1,N]}\\). What should be the matching \\(\\tilde{y}\\) ?\nDiscover implicit relation \\(y=f(x)\\) (the model) then compute \\(\\tilde{y}=f(\\tilde{x})\\).\n\\(f\\) is chosen from a family \\(\\mathcal{F}\\) of functions parameterized by a parameter \\(\\theta\\), the approximation family.",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#interpolation-vs.-regression",
    "href": "slides/interpolation.html#interpolation-vs.-regression",
    "title": "Interpolation",
    "section": "Interpolation vs. Regression",
    "text": "Interpolation vs. Regression\n\nInterpolation: \\(f\\) is chosen such that \\(\\forall n, y_n=f(x_n)\\) \nRegression: \\(f\\) is chosen so as to minimize a fitness criterium such as\n\n\\(\\min_f \\sum_n \\left( y_n-f(x_n) \\right)^2\\)\nor \\(\\min_{\\theta} \\sum_n \\left( y_n-f(x_n;\\theta) \\right)^2 + \\lambda  || \\theta ||^2\\) with \\(\\lambda&gt;0\\)\n\nRemarks:\n\nsome applied mathematicians tend to mix the two (interpolate=evaluate f outside of X)",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#examples-1-linear-interpolation",
    "href": "slides/interpolation.html#examples-1-linear-interpolation",
    "title": "Interpolation",
    "section": "Examples (1): Linear Interpolation",
    "text": "Examples (1): Linear Interpolation\n1d Graph. Join the dots. Linear/Spline\n2d Graph: Regression\nConclusion: interpolate only if \\(f\\) is known precisely on \\(X\\)",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#example-2",
    "href": "slides/interpolation.html#example-2",
    "title": "Interpolation",
    "section": "Example (2)",
    "text": "Example (2)\n\n\n\\(X\\) and \\(Y\\): large databases of low and high resolutions images\n\\(\\mathcal{F}\\): neural network",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#why-do-we-need-it",
    "href": "slides/interpolation.html#why-do-we-need-it",
    "title": "Interpolation",
    "section": "Why do we need it?",
    "text": "Why do we need it?\n\nIn economics, we often solve a problem \\(\\Phi(f)=0\\) where \\(f\\) is a function: \\(\\forall s, \\Phi(f)(s) = 0\\)\nIf we approximate \\(f\\) by some element \\(f(;\\theta)\\in\\mathcal{F}\\) we just need to identify a finite set of parameters \\(\\theta \\in R^n\\)\nHow do we identify \\(\\theta\\)?\n\nchoose a finite set of \\(n\\) criteria that must be met\n\n\\(f\\) is pin down uniquely\nexample: colocation, choose \\(s_1, ..., s_n\\). Find \\(f\\) such that \\(\\forall i=1:n, \\Phi(f)(s_i) = 0\\)\n\nchoose higher number of objectives (\\(p&gt;n\\)) that must be minimized:\n\nexample: regression, choose \\(s_1, ..., s_p\\). Find \\(f\\) such that minimize \\(\\sum_i \\Phi(f)(s_i)^2 = 0\\)",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#several-interpolation-flavours",
    "href": "slides/interpolation.html#several-interpolation-flavours",
    "title": "Interpolation",
    "section": "Several interpolation flavours",
    "text": "Several interpolation flavours\n\nlocal vs spectral:\n\nlocal: functions in \\(f\\) have compact support\nspectral: noncompact support\n\nlinear vs nonlinear:\n\n\\(\\mathcal{F}\\) is a vector space: \\(f(x) \\approx \\sum_{i=1}^N \\theta_n b_n(x)\\) where \\(b_n\\) is a base of \\(\\mathcal{F}\\)\nnonlinear: wavelets, neural networks, ….",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#linear",
    "href": "slides/interpolation.html#linear",
    "title": "Interpolation",
    "section": "Linear",
    "text": "Linear\n\nTake function \\(f\\) defined on an interval \\([a,b]\\). Suppose the value is known at \\((a=x_1, ... x_N=b)\\). Denote \\(y_i = f(x_i)\\).\nJoin the dots: define a piecewise linear function as \\[\\forall x \\in [x_i, x_{i+1}], \\tilde{f}(x) = y_i + \\underbrace{\\frac{x-x_i}{x_{i+1}-x_i}}_{\\text{barycentric coordinate}} (y_{i+1} - y_i)\\]",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#linear-1",
    "href": "slides/interpolation.html#linear-1",
    "title": "Interpolation",
    "section": "Linear",
    "text": "Linear\n\nAlternate view: \\[\\tilde{f}(x) = \\sum_{i=1}^N y_i B^i_1(x)\\] where \\(b_1^i(x)=\\frac{x-x_{i-1}}{x_i-x_{i-1}}.1_{x\\in[x_{i-1},x_i]} + (1-\\frac{x-x_{i}}{x_{i+1}-x_{i}}).1_{x\\in [x_i, x_{i+1}]}\\)\n\\((B^i)\\) is an interpolation basis",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#splines-1",
    "href": "slides/interpolation.html#splines-1",
    "title": "Interpolation",
    "section": "Splines",
    "text": "Splines\n\n\\(n\\)-th order spline : piecewise polynomial function that is \\(n\\) times differentiable except on a finite set of break points (aka knots), where it is \\((n-1)\\) times differentiable.\nin practice the data points are the breakpoints\nexample: order 2\n\nsuppose \\(\\tilde{f}(x_i)\\) and \\(\\tilde{f}^{\\prime}(x_i)\\) are known, choose the coefficients for the patch \\(p_{i+1}(x) = a_{i+1}x^2+b_{i+1}x + c_{i+1}\\)\nAlready two constraints. Condition \\(p_{i+1}(x_{i+1})=\\tilde{f}(x_{i+1})\\) supplies another one.\nDo it for every patch. Note that it requires to set \\(f^{\\prime}(a)\\) beforehand.",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#basis-splines-much-better",
    "href": "slides/interpolation.html#basis-splines-much-better",
    "title": "Interpolation",
    "section": "Basis Splines (much better)",
    "text": "Basis Splines (much better)\n\nDefine \\[B_{i,1}(x) = 1_{x \\in [x_i, x_{i+1}]}\\] \\[B_{i,k+1}(x) = \\frac{x-x_i}{x_{i+k}-x_i}B_{i,k}(x) +\n\\frac{x_{i+k+1}-x}{x_{i+k+1}-x_{i+1}}B_{i+1,k}(x)\\]\nTheorem: Any spline of order \\(k\\) on the knots \\((x_i)\\) can be expressed as a linear combination of the basis splines \\((B_{i,k})\\).\nAll basis splines have compact support.\nIf grid is regularly spaced there is \\(B_k\\) such that \\(B_{i,k}(x) = B_k(x-x_i)\\)",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#basis-splines",
    "href": "slides/interpolation.html#basis-splines",
    "title": "Interpolation",
    "section": "Basis splines",
    "text": "Basis splines\n\nBasis Splines",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#basis-splines-are-not-interpolating",
    "href": "slides/interpolation.html#basis-splines-are-not-interpolating",
    "title": "Interpolation",
    "section": "Basis splines are not interpolating",
    "text": "Basis splines are not interpolating\n\nUnfortunately basis splines are not “interpolating” in the sense that in general \\[f(x_i) \\neq \\sum_{n} f(x_n) B_{n,k} (x_i)\\]\nOne must choose other coefficients \\((c_n)\\) which satisfy:\n\\[y_i = \\sum_n c_n B_{n,k} (x_i)\\]\n\nthere are more coefficients than data points: requires boundary conditions\n\nf’’=0: natural spline\n\ngoing from \\(y_n\\) to \\(c_n\\) is called prefiltering",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#in-practice-interpolations",
    "href": "slides/interpolation.html#in-practice-interpolations",
    "title": "Interpolation",
    "section": "In practice: Interpolations",
    "text": "In practice: Interpolations\nf(x) = log(x)\nxs = 1:0.2:5\nA = [f(x) for x in xs]\n\n# linear interpolation\ninterp_linear = LinearInterpolation(xs, A)\ninterp_linear(1.3) # interpolate\n\n# cubic spline interpolation\ninterp_cubic = CubicSplineInterpolation(xs, A)\ninterp_cubic(1.3) # interpolate",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#in-practice-interpolations-2",
    "href": "slides/interpolation.html#in-practice-interpolations-2",
    "title": "Interpolation",
    "section": "In practice: Interpolations (2)",
    "text": "In practice: Interpolations (2)\nNote that in \\(y_i = \\sum_n c_n B_{n,k} (x_i)\\), \\(y_i\\) and \\(c_n\\) could perfectly well be vectors. If we use a Vector type which implements all operations (zeros, *, …) we can interpolate them with the same operations\nusing StaticArrays\n\nf(x) = SVector(log(x), exp(x))\nxs = 1:0.2:5\nA = [f(x) for x in xs]\n\n# linear interpolation\ninterp_linear = LinearInterpolation(xs, A)\ninterp_linear(1.3) # returns a 2d SVector",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#matrix-conditioning",
    "href": "slides/interpolation.html#matrix-conditioning",
    "title": "Interpolation",
    "section": "Matrix conditioning",
    "text": "Matrix conditioning\n\nSuppose you want to solve vector equation \\(A x=y\\). Will a small error in \\(y\\) affect a lot the value of \\(x\\)? (in particular round-off errors)\n\ncondition number: \\(\\lim_{\\epsilon\\rightarrow 0} \\sup_{\\delta y\\leq \\epsilon} \\frac{\\delta x}{\\delta y}\\)\nor \\(\\kappa(A) = ||A^{-1}|| || A||\\) where \\(|| ||\\) is a subordonate norm.\nif very-large: the matrix is ill conditioned\n\nWhat makes a matrix ill-conditioned?\n\nsome rows/columns are very small, others are gigantic\nrows/columns are almost colinear",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#fitting-polynomials",
    "href": "slides/interpolation.html#fitting-polynomials",
    "title": "Interpolation",
    "section": "Fitting polynomials",
    "text": "Fitting polynomials\n\nLet’s approximate: \\(f(;\\theta) = \\sum_{n=0}^K \\theta_k x^k\\).\nWe need \\((K+1)\\) points to fit a polynomial of order \\(K\\). Let’s take grid points \\((x_0, ... x_{K})\\) and denote \\(y_k=f(x_k)\\)\nWe need to solve in \\((\\theta_k)_{k=[0,K]}\\):\n\n\\[\\forall n \\in[0,K],  \\underbrace{\\sum_k \\theta_k (x_n)^{k}}_{M \\theta} = y_k\\]",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#vandermonde-matrix",
    "href": "slides/interpolation.html#vandermonde-matrix",
    "title": "Interpolation",
    "section": "Vandermonde Matrix",
    "text": "Vandermonde Matrix\n\n\\(M\\) has a special structure, a Vandermode matrix: \\[\nM =\n\\begin{bmatrix}\n1 & x_0 & x_0^2 \\cdots & x_0^K \\\\\\\\\n1 & x_1 & x_1^2  \\cdots  & x_1^K \\\\\\\\\n1 & x_2 & x_2^2  \\cdots  & x_2^K \\\\\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\\\\\n1 & x_K & x_K^2  \\cdots & x_K^K\n\\end{bmatrix}\n\\]\nVandermonde matrix is ill-conditioned if points are too close or if \\(K\\) is high.",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#orthogonal-polynomials",
    "href": "slides/interpolation.html#orthogonal-polynomials",
    "title": "Interpolation",
    "section": "Orthogonal polynomials",
    "text": "Orthogonal polynomials\n\nDefine a scalar product over functions on the domain \\([a,b]\\) by choosing a positive weight function \\(w(x)\\). \\[&lt;P,Q&gt; = \\int_a^b w(x) P(x)Q(x) dx\\]\nConstruct an orthogonal base \\((T_n)_{n=[1,K]}\\).\nApproximate \\[f(x)\\approx f(x; \\theta) = \\sum_{n=0}^K \\theta_n T_n(x)=\\sum_{n=0}^K &lt;f|T_n&gt; T_n(x)\\]\n\nthis is optimal for the norm associated to \\(&lt;&gt;\\) (projection on the orthogonal base)",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#vandermonde-matrix-1",
    "href": "slides/interpolation.html#vandermonde-matrix-1",
    "title": "Interpolation",
    "section": "Vandermonde matrix",
    "text": "Vandermonde matrix\nCoefficients can still be identified by inverting: \\[\\forall n \\in[0,K] \\underbrace{\\sum_k \\theta_k T_k(x_n)}_{M \\theta} = y_n\\]\n\\[\nM =\n\\begin{bmatrix}\nT_0(x_0) & T_1(x_0) & \\cdots & T_K(x_0) \\\\\\\\\nT_0(x_1) & T_1(x_1) &  \\cdots  & T_K(x_1) \\\\\\\\\nT_0(x_2) & T_1(x_2) &  \\cdots  & T_K(x_2) \\\\\\\\\n\\vdots & \\vdots & \\ddots & \\vdots \\\\\nT_0(x_K) & T_1(x_K) &  \\cdots & T_K(x_K)\n\\end{bmatrix}\n\\]",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#problem-runge-error",
    "href": "slides/interpolation.html#problem-runge-error",
    "title": "Interpolation",
    "section": "Problem: Runge error",
    "text": "Problem: Runge error\n\n\n\nRed: Runge function \\(f(x)=\\frac{1}{1+25x^2}\\)\nBlue: interpolates at 6, regularly-spaced, points\nGreen: interpolates at 10, regularly-spaced, points\nWhat happens when interpolation order increases?\n\noscillations increase.\n\nDoes it contradict Stone-Weierstrass theorem ? No.\nSolutions:\n\nuse regression method instead\nchoose the interpolation points wisely",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#chebychev-nodes",
    "href": "slides/interpolation.html#chebychev-nodes",
    "title": "Interpolation",
    "section": "Chebychev Nodes",
    "text": "Chebychev Nodes\n\nThere is an optimal way to choose the interpolation points:\n\nthe roots of \\(cos(\\frac{2 k - 1}{2n} \\pi)\\) for [-1,1]\nrescale for a finite interval [a,b]\n\nfor the interpolating polynomial: \\[|f(x) - P_n(x)|  \\leq \\frac{1}{2^n (n+1)!} \\max_{\\xi \\in [-1,1]} |f^n(\\xi)|\\]",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#chebychev-polynomials",
    "href": "slides/interpolation.html#chebychev-polynomials",
    "title": "Interpolation",
    "section": "Chebychev polynomials",
    "text": "Chebychev polynomials\n\nChebychev polynomials (of the first kind) have their zeros on the nodes.\nDefinitions:\n\n\\(T_n(x) = \\cos(n  \\arccos(x))\\) (in [0,1])\nrecursive: \\(T_0(x)=1\\), \\(T_1(x)=x\\), \\(T_n(x)=2 x T_{n-1}(x)-T_{n-2}(x)\\)\n\nVery good choice:\n\nmatrix \\(M\\) is well conditioned: \\(\\sqrt{2}\\)",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#chebychev-polynomial",
    "href": "slides/interpolation.html#chebychev-polynomial",
    "title": "Interpolation",
    "section": "Chebychev Polynomial",
    "text": "Chebychev Polynomial",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#multidimensional-interpolation",
    "href": "slides/interpolation.html#multidimensional-interpolation",
    "title": "Interpolation",
    "section": "Multidimensional interpolation",
    "text": "Multidimensional interpolation\n\nConsider a function \\(f\\) defined on a space \\(X_1 \\times X_d\\)\nTake \\(d\\) grids \\(\\mathcal{G}_1\\subset X_1, ..., \\mathcal{G}_d\\subset X_d\\) with linear approximation bases \\(\\mathcal{B}_1=(b_1^1, ... b_1^{N_1}),..., \\mathcal{B}_d=(b_d^1, ... b_d^{N_d})\\).\nThen \\(f\\) can be approximated by \\(f(x_1, ... x_d ; \\theta) = \\sum_{i_1=1}^{N_1} ... \\sum_{i_d=1}^{N_d} \\theta_{i_1, ... i_d} \\underbrace{b_{i_1}^1(x_1) ...  b_{i_d}^d(x_d)}_{\\text{Product Base}}\\)\nMorality:\n\nlinear appoximation along each dimension induces a natural (multi)-linear in many dimensions\nCoefficients are still the solution of a linear system: \\[M \\theta = y\\]\nbut \\(M\\) has a special structure (tensor product)\n\nProblem: number of coefficients to determine increases exponentially with number of dimensions:\n\n“Curse of Dimensionality”",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#multidimensional-interpolation-2",
    "href": "slides/interpolation.html#multidimensional-interpolation-2",
    "title": "Interpolation",
    "section": "Multidimensional interpolation (2)",
    "text": "Multidimensional interpolation (2)\n\nWays to mitigate the curse of dimensionality\nRemedies:\n\nsparse grids\nadaptive approximation\nneural networks\n…\n\nNo black-magic theorem: there is no solution to the curse of dimensionality\n\n.. but there are methods to adapt to problem whose intrinsic dimension is smaller than the actual number of variables",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/interpolation.html#in-practice",
    "href": "slides/interpolation.html#in-practice",
    "title": "Interpolation",
    "section": "In Practice:",
    "text": "In Practice:\n\nInterpolations.jl can interpolate on multi-dim grids\nIf you want to construct basis matrices yourself, BasisMatrices.jl:",
    "crumbs": [
      "Slides",
      "Interpolation"
    ]
  },
  {
    "objectID": "slides/discretization.html#several-kinds-of-discretization",
    "href": "slides/discretization.html#several-kinds-of-discretization",
    "title": "Discretization",
    "section": "Several kinds of Discretization",
    "text": "Several kinds of Discretization\n\napproximate operator with a finite number of iterations:\n\ncompute \\(\\int_a^b f(x) dx\\)\ncompute \\(E_\\omega f(\\omega)\\)\n\nrepresent an infinite dimensional object with a finite set of parameters:\n\n\\(f \\equiv (f(x_i))_{i=1:N}\\) with \\(x_i=a+\\frac{i-1}{N-1}(b-a)\\)\n\ndiscretize arguments\n\n\\(\\omega \\equiv (\\mu_i, \\omega_i)_{i=1:N}\\) such that \\(E_\\omega f(\\omega) \\approx \\sum_i \\mu_i f(\\omega_i)\\) (quantization)\n\ndiscretize continous process by a discrete one:\n\ncontinuous markov chain to discrete markov Chain",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#discretizing-an-ar1-1",
    "href": "slides/discretization.html#discretizing-an-ar1-1",
    "title": "Discretization",
    "section": "Discretizing an AR1",
    "text": "Discretizing an AR1\n\nTake \\(AR1\\) process \\[x_t = \\rho x_{t-1} + \\epsilon_t\\]\n\nwith \\(|\\rho| &lt;1\\) and \\(\\epsilon \\sim N(0,\\sigma)\\)\n\nCan we replace \\((x_t)\\) by a discrete markov chain?\n\napproximate version:\n\ngood time \\(x^g\\) and bad time \\(x^b\\). Probability \\(\\pi\\) of staying in the same, \\(1-\\pi\\) of switching.\n\ntwo systematic methods (available in QuantEcon.jl)\n\nTauchen\nRouwenhorst",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#ar1-tauchen",
    "href": "slides/discretization.html#ar1-tauchen",
    "title": "Discretization",
    "section": "AR1: Tauchen",
    "text": "AR1: Tauchen\n\nThe unconditional distribution of an AR1 is a normal law \\(\\mathcal{N}(0,\\frac{\\sigma}{\\sqrt{1-\\rho^2}})\\)\nChoose \\(m&gt;0\\), typically \\(m=3\\)\nBound the process: \\(\\underline{x} = -m \\frac{\\sigma}{\\sqrt{1-\\rho^2}}\\) and \\(\\overline{x} = m \\frac{\\sigma}{\\sqrt{1-\\rho^2}}\\)\nDefine the \\(N\\) discretized points (\\(i\\in[1,n]\\)): \\(y_i = \\underline{x} + \\frac{i-1}{N-1}(\\overline{x}-\\underline{x})\\)\nDefine the transitions:\n\n\\[\\begin{eqnarray}\n\\pi_{ij} & = & prob \\left( y_{t+1}=y_j|y_t=y_i\\right)\\\\\n         & = & prob \\left( |y_{t+1}-x_j| = \\inf_k |y_{t+1}-x_k| \\left| y_t=y_i \\right. \\right)\n\\end{eqnarray}\\]",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#ar1-tauchen-2",
    "href": "slides/discretization.html#ar1-tauchen-2",
    "title": "Discretization",
    "section": "AR1: Tauchen (2)",
    "text": "AR1: Tauchen (2)\n\nFormulas \\(\\delta=\\frac{\\overline{x}-\\underline{x}}{N}\\):\n\nif \\(1&lt;k&lt;N-1\\)\n\\[\\pi_{jk} = F(\\frac{y_k + \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) - F(y_k + \\delta/2-\\rho y_j)\\]\nif \\(k=1\\)\n\\[\\pi_{j} = F(\\frac{y_k + \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) \\]\nif \\(k=N\\)\n\\[\\pi_{j} = 1- F(\\frac{y_k - \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) \\]",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#how-to-assess-the-quality-of-approximation",
    "href": "slides/discretization.html#how-to-assess-the-quality-of-approximation",
    "title": "Discretization",
    "section": "How to assess the quality of approximation ?",
    "text": "How to assess the quality of approximation ?\n\ncompare generated stationary moments between discretized process and true AR1:\n\nE(), Var(), ACor()\n\nby looking at the exact ergodic distribution or by doing some simulations\nnot very precise when then process is very persistent \\(\\rho\\approx 1\\)",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#rouvenhorst-method-1",
    "href": "slides/discretization.html#rouvenhorst-method-1",
    "title": "Discretization",
    "section": "Rouvenhorst method (1)",
    "text": "Rouvenhorst method (1)\n\nN = 2\n\nchoose \\(y_1=-\\psi\\), \\(y_2=\\psi\\)\ndefine transition matrix: \\[\\Theta_2 = \\begin{bmatrix}\np & 1-p\\\\\\\\\n1-q & q\n\\end{bmatrix}\\]\nchoose \\(p\\), \\(q\\) and \\(\\psi\\) to match some moments: \\(E()\\), \\(Var()\\), \\(ACor()\\)\n\nthey can be computed analytically for AR1 and for discretized version.",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#rouvenhorst-method-2",
    "href": "slides/discretization.html#rouvenhorst-method-2",
    "title": "Discretization",
    "section": "Rouvenhorst method (2)",
    "text": "Rouvenhorst method (2)\n\nN &gt;2 \\[\\Theta_N =\np \\begin{bmatrix}  \n\\Theta_{N-1}  & 0\\\\\\\\\n0 & 0\n\\end{bmatrix} +\n(1-p) \\begin{bmatrix}  \n0 & \\Theta_{N-1} \\\\\\\\\n0 & 0\n\\end{bmatrix} +\n(1-q) \\begin{bmatrix}  \n0 & 0\\\\\\\\\n\\Theta_{N-1} & 0\n\\end{bmatrix} +\nq \\begin{bmatrix}  \n0 & 0\\\\\\\\\n0 & \\Theta_{N-1}\n\\end{bmatrix}\n\\]\nNormalize all lines",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#rouvenhorst-method-3",
    "href": "slides/discretization.html#rouvenhorst-method-3",
    "title": "Discretization",
    "section": "Rouvenhorst method (3)",
    "text": "Rouvenhorst method (3)\n\nProcedure converges to Bernouilli distribution.\nMoments can be computed in closed form:\n\n\\(E() = \\frac{(q-p)\\psi}{2-(p+q)}\\)\n\\(Var() = \\psi^2 \\left[ 1-4 s (1-s) + \\frac{4s(1-s)}{N-1}\\right]\\)\n\\(Acor()= p+q-1\\)\n\nRouwenhorst method performs better for highly correlated processes",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#common-problem",
    "href": "slides/discretization.html#common-problem",
    "title": "Discretization",
    "section": "Common problem:",
    "text": "Common problem:\n\nGiven \\(f\\), and an iid process \\(\\epsilon \\sim N(0,\\sigma^2)\\), how to approximate \\(E_{\\epsilon} f(\\epsilon)\\) ?\nIdeas:\n\ndraw lots of random \\((\\epsilon\\_n)\\_{n=1:N}\\) and compute \\[\\frac{1}{N}\\sum_{n=1}^N f(\\epsilon_n)\\]\n\naka Monte-Carlo simulations\n\ngiven a method to approximate integrals, compute \\[\\int_{u=-\\infty}^{\\infty} f(u) \\mu(u) du\\] with \\(\\mu(u)=\\frac{1}{\\sigma\\sqrt{2 \\pi}}e^{-\\frac{u^2}{2\\sigma^2}}\\)\ndiscretize (or quantize) the signal \\(\\epsilon\\) as \\((w_i, \\epsilon_i)_{i=1:N}\\) and compute:\n\n\n\\[\\frac{1}{N} \\sum_n w_n f(\\epsilon_n)\\]",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#whats-wrong-with-monte-carlo-simulations",
    "href": "slides/discretization.html#whats-wrong-with-monte-carlo-simulations",
    "title": "Discretization",
    "section": "What’s wrong with Monte-Carlo Simulations?",
    "text": "What’s wrong with Monte-Carlo Simulations?\n\nLet’s take an exemple:\n\nconsumption is \\(C(\\epsilon)=U(e^{\\epsilon})\\)\nwith \\({\\sigma}\\_{\\epsilon}=0.05\\) and \\(U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}\\) and \\(\\gamma=40\\).\n\nLet’s compute \\(E_{\\epsilon}(C(\\epsilon))\\) precisely.\nDiscuss value of \\(\\gamma\\): is it crazy? (risk return)",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#whats-wrong-with-monte-carlo-simulations-1",
    "href": "slides/discretization.html#whats-wrong-with-monte-carlo-simulations-1",
    "title": "Discretization",
    "section": "What’s wrong with Monte-Carlo Simulations?",
    "text": "What’s wrong with Monte-Carlo Simulations?\nCompute expectation\n# imports:\nusing Distributions: Normal\n\n# define the model\nσ = 0.05; γ = 40\nU(x)=(x^(-γ))/(-γ)\nC(e) = U(exp(e))\n\n# create distributions\ndis = Normal(0,σ)      \nE_ϵ(f;N=1000) = sum(f(rand(dis)) for i=1:N)/N\n\nNVec = [1000, 5000, 10000, 15000, 20000]\nvals = [E_ϵ(C; N=i) for i=NVec]\njulia&gt; vals = [E_ϵ(C; N=i) for i=NVec\n5-element Array{Float64,1}:\n -0.17546927855215824\n -0.2906119630309043\n -0.17924501776041424\n -0.1826805612086024\n -0.181184208323609",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#whats-wrong-with-monte-carlo-simulations-2",
    "href": "slides/discretization.html#whats-wrong-with-monte-carlo-simulations-2",
    "title": "Discretization",
    "section": "What’s wrong with Monte-Carlo Simulations?",
    "text": "What’s wrong with Monte-Carlo Simulations?\nusing Statistics: std\n\n#computes estimates for various N\nstdev(f; N=100, K=100) = std(E_ϵ(f; N=N) for k=1:K)\nsdvals = [stdev(C; N=n, K=10000) for n=NVec]\njulia&gt; @time sdvals = [stdev(C; N=n, K=10000) for n=NVec]      \n 99.558940 seconds (2.55 G allocations: 38.011 GiB, 0.81% gc time)\n5-element Array{Float64,1}:                                       \n 0.04106466473642666                                              \n 0.018296399941889575                                             \n 0.013174287295527257                                             \n 0.01086721462174894                                              \n 0.009383218078206898",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#quick-theory-1",
    "href": "slides/discretization.html#quick-theory-1",
    "title": "Discretization",
    "section": "Quick theory (1)",
    "text": "Quick theory (1)\n\nFact: the sum of several independent gaussian variables is a gaussian variable\nSo \\(T_N =\\frac{1}{N}\\sum_{n=1}^N \\epsilon_n\\) is gaussian variable. Its mean is 0 (unbiased). Let’s compute its variance: \\[E(T_N^2) = \\frac{1}{N^2} \\sum_{n=1}^N E\\left[ \\epsilon_n^2 \\right]\\]\nThe standard deviation is: \\[s_N = \\sigma(T_N^2) = \\frac{1}{\\sqrt{\\color{red} N}} \\sigma_{\\epsilon}\\]\nConclusion: the precision of (basic) Monte-Carlo decreases only as a square root of the number of experiments.",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#quick-theory-2",
    "href": "slides/discretization.html#quick-theory-2",
    "title": "Discretization",
    "section": "Quick theory (2)",
    "text": "Quick theory (2)\n\nIn the general case, the Monte-Carlo estimator is: \\[T^{MC}\\_N =\\frac{1}{N}\\sum\\_{n=1}^N f(\\epsilon_n)\\]\nIt is unbiased: \\[E(T_N^{MC}) = E\\left[f(\\epsilon) \\right]\\]\nIt’s variance is \\[E(T_N^{MC}) \\propto \\frac{1}{\\sqrt{N}}\\]\n\nslow\non the plus side: rate independent of the dimension of \\(\\epsilon\\)",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#quantization-using-quantiles",
    "href": "slides/discretization.html#quantization-using-quantiles",
    "title": "Discretization",
    "section": "Quantization using quantiles",
    "text": "Quantization using quantiles\n\n\n\nEquiprobable discretization\nWorks for any distribution with pdf and cdf\nSplit the space into equal \\(N\\) quantiles: \\[(I_i=[a_i,a_{i+1}])_{i=1:N}\\] such that \\[prob(\\epsilon \\in I_i)=\\frac{1}{N}\\]\nChoose the nodes as the median of each interval: \\[prob(\\epsilon\\in[a_i,x_i]) = prob(\\epsilon\\in[x_i,a_{i+1}])\\]\nThe quantization is \\((1/N, x_i)_{i=1:N}\\)\n\n\n\n[graph]",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#gauss-hermite",
    "href": "slides/discretization.html#gauss-hermite",
    "title": "Discretization",
    "section": "Gauss-Hermite",
    "text": "Gauss-Hermite\n\n\\(f\\in \\mathcal{F}\\) a Banach space (or \\(\\mathbb{R}^n\\)), \\(\\epsilon\\) a gaussian variable\n\n\\(I: f\\rightarrow E_{\\epsilon} f(\\epsilon)\\) is a linear application\n\nsuppose there is a dense family of polynomials \\(P_n\\), spanning \\(\\mathcal{F}_n\\)\n\n\\(I\\) restricted to \\(\\mathcal{F}_N\\) is a \\(N\\)-dimensional linear form\n\nGauss quadrature magic\n\na way to choose \\(\\\\epsilon_i\\) and \\(w_i\\) such that \\[\\left(f\\rightarrow\\sum\\_{n=1}^N w_n f(\\epsilon_i) \\right)= \\left.I\\right|\\_{\\mathcal{F}_{2N}}\\]",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#gauss-hermite-1",
    "href": "slides/discretization.html#gauss-hermite-1",
    "title": "Discretization",
    "section": "Gauss-Hermite",
    "text": "Gauss-Hermite\n\nVery accurate if a function can be approximated by polynomials\nBad:\n\nimprecise if function \\(f\\) has kinks or non local behaviour\n\npoints \\(\\epsilon_n\\) can be very far from the origin (TODO: graph)\n\nnot super easy to commute weights and nodes (but there are good libraries)",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#gauss-",
    "href": "slides/discretization.html#gauss-",
    "title": "Discretization",
    "section": "Gauss-*",
    "text": "Gauss-*\n\nSame logic can be applied to compute integration with weight function \\(w(x)\\): \\[\\int_a^b f(x) w(x)\\]\nGauss-Hermite:\n\n\\(w(x) = e^{-x^2}\\), \\([a,b] = [-\\infty, \\infty]\\)\n\nGauss-Legendre:\n\n\\(w(x) = 1\\)\n\nGauss-Chebychev:\n\n\\(w(x)=\\sqrt{1-x^2}\\), \\([a,b] = [-1, 1]\\)\nfor periodic functions",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "slides/discretization.html#in-practice",
    "href": "slides/discretization.html#in-practice",
    "title": "Discretization",
    "section": "In practice",
    "text": "In practice\nBeware that weight is not the density of the normal law:\n\\[\\frac{1}{\\sqrt{2 \\pi \\sigma^2}}\\int f(x) e^{-\\frac{x^2}{2\\sigma^2}}dx = {\\frac{1}{\\sqrt{\\pi}}}\\int f(u {\\sigma \\sqrt{2}}) e^{-{u^2}}du \\] \\[{\\frac{1}{\\sqrt{\\pi}}}\\sum_n w_n f(\\epsilon_n {\\sigma \\sqrt{2}})\\]\nusing FastGaussQuadrature\n\nx, w = gausslegendre( 10 );\nx = x.*σ*sqrt(2) # renormalize nodes\ns = sum( w_*U(exp(x_)) for (w_,x_) in zip(x,w))\ns /= sqrt(\\pi) # renormalize output",
    "crumbs": [
      "Slides",
      "Discretization"
    ]
  },
  {
    "objectID": "homework/2025/coursework_2.html",
    "href": "homework/2025/coursework_2.html",
    "title": "Coursework 2025 - Consumption Saving",
    "section": "",
    "text": "Name:\nSurname:\nAfter completing the following questions, send the edited notebook to pablo.winant@ensae.fr. You can work in (small) teams but are not allowed to copy/paste any code. Don’t forget to comment your code and take any initiative you find relevant.",
    "crumbs": [
      "Coursework",
      "Coursework 2025 - Consumption Saving"
    ]
  },
  {
    "objectID": "homework/2025/coursework_2.html#general-problem",
    "href": "homework/2025/coursework_2.html#general-problem",
    "title": "Coursework 2025 - Consumption Saving",
    "section": "General Problem",
    "text": "General Problem\nWe seek to solve numerically the following consumption-saving problem using the time-iteration algorithm.\nIncome is an iid normally distributed process with standard deviation \\(\\sigma\\). Interest rate is \\(r\\in [1,\\frac{1}{\\beta}[\\) where \\(\\beta\\in]0,1[\\) is the discount factor.\nAvailable income is \\(w_t\\) and follows the law of motion:\n\\[w_{t+1} = e^ {\\epsilon_{t+1}} +  (w_{t} - c_{t}) r\\]\nwhere \\(c_t \\in ]0,w_t]\\) is consumption chosen at date \\(t\\) (which includes an implicit no borrowing constraint).",
    "crumbs": [
      "Coursework",
      "Coursework 2025 - Consumption Saving"
    ]
  },
  {
    "objectID": "homework/2025/coursework_2.html#calibration",
    "href": "homework/2025/coursework_2.html#calibration",
    "title": "Coursework 2025 - Consumption Saving",
    "section": "Calibration",
    "text": "Calibration\nWe will use the following calibration:\n\\(\\sigma = 0.01\\)\n\\(\\beta = 0.96\\)\n\\(r = 1.03\\)\nChoose a structure model to represent the model parameters.\n\n\n# model = ...",
    "crumbs": [
      "Coursework",
      "Coursework 2025 - Consumption Saving"
    ]
  },
  {
    "objectID": "homework/2025/coursework_2.html#representing-the-decision-function",
    "href": "homework/2025/coursework_2.html#representing-the-decision-function",
    "title": "Coursework 2025 - Consumption Saving",
    "section": "Representing the decision function",
    "text": "Representing the decision function\nThe solution of the model is a decision rule \\(c(w)\\).\nIn what follows, we will approximate it by a function defined over \\([0,w_{max}[\\), pinned down by the values it takes on \\(N\\) linearly spaced grid points.\nIn our solutions algorithm, we will use the initial guess \\(\\varphi_0(w) = min(w, p_0+p_1(w-p_0))\\).\nCreate a structure approx to represent the approximation space. This structure should contain the parameters, as well as a points::Vector{Float64} array coontaining the (regularly spaced) list of grid points.\nTo start with you can take \\(w_{max}=5\\), \\(N=20\\), \\(p_0=0.95, p_1=0.03\\) but don’t hesitate to change these values later if needed.\n\n# approx = ...\n\nDefine a method φ_0(w::Float64)::Float64 for the initial guess. Plot it against \\(w\\) in the approximation space.\nCompute the values c_0::{Float64}of φ_0() on the grid points\nUse the Interpolations.jl library to define a function φ(w::Float64) defined for any w using piecewise linear interpolation in such a way that it takes values c_0 on the grid points.\nCreate a single plot with:\n\nthe function φ_0()\nthe interpolated function \\(φ\\)\nits values c_0 on the grid points\n\nBonus: add to the graph the function obtained using cubic spline interpolation. What could be the problem?",
    "crumbs": [
      "Coursework",
      "Coursework 2025 - Consumption Saving"
    ]
  },
  {
    "objectID": "homework/2025/coursework_2.html#discretizing-epsilon_t1",
    "href": "homework/2025/coursework_2.html#discretizing-epsilon_t1",
    "title": "Coursework 2025 - Consumption Saving",
    "section": "Discretizing \\(\\epsilon_{t+1}\\)",
    "text": "Discretizing \\(\\epsilon_{t+1}\\)\nRepresent the shock \\(\\epsilon\\) by two vectors \\((e_1, ... e_q)\\) and \\((l_1, ..., l_q)\\) with \\(q=10\\) such that for a suitable function \\(g\\) we can approximate \\(E_{\\epsilon} (g(\\epsilon))\\) by \\(\\sum_{i=1}^q l_i e_i\\) .\n(choose the method you want)\n\n# e = ...\n# w = ...\n\nTest that it works by computing \\(E_{\\epsilon} \\left[ \\epsilon^2 \\right]\\).\nRedefine approx so as to include the discretized shock",
    "crumbs": [
      "Coursework",
      "Coursework 2025 - Consumption Saving"
    ]
  },
  {
    "objectID": "homework/2025/coursework_2.html#euler-equation",
    "href": "homework/2025/coursework_2.html#euler-equation",
    "title": "Coursework 2025 - Consumption Saving",
    "section": "Euler equation",
    "text": "Euler equation\nWrite down the Euler equation, paying attention to the slackness condition.\nIt should be of the form \\[0 \\leq \\underbrace{E_t \\left[ f(w_t, c_t, w_{t+1}, c_{t+1}, \\epsilon_{t+1}) \\right]}_{\\Phi_t} \\perp c_t \\leq w_t\\]\nwhere \\(f\\) is a function to be explicited.\nDefine the function Phi(w::Float64,c::Float64,φ::Fun, model, approx) which approximates the residuals of the euler equation given the available income today, the consumption choice today, the consumption function tomorrow and the model/approx structures.\nOverload Phi function with another method Phi(w::Float64,c::Float64,φ::Fun, model, approx, slackness=true) which uses the Fisher-Burmeister transform to incorporate the credit constraint.\nPlot the optization residuals (i.e. values of \\(\\Phi_t\\)) corresponding to the initial guess function with and without the complementarity constraints.",
    "crumbs": [
      "Coursework",
      "Coursework 2025 - Consumption Saving"
    ]
  },
  {
    "objectID": "homework/2025/coursework_2.html#time-iteration",
    "href": "homework/2025/coursework_2.html#time-iteration",
    "title": "Coursework 2025 - Consumption Saving",
    "section": "Time Iteration",
    "text": "Time Iteration\n(prep): Assuming the initial guess \\(φ_0()\\) is the decision rule followed tomorrow, determine, for a given value w in the state-space, the optimal consumption choice made today. This can be achieved by feeding the appropriate function into the right nonlinear root-finder.\n(prep): Find the vector of all the optimal consumption choices on the grid today, given the decision rule tomorrow.\nPlot the optimization residuals (i.e. values of \\(\\Phi_t\\)) for the initial guess function\nWrite down the time-iteration algorithm.\nYou can use the course as reference and/or repeat the recurrence steps below:\n\ngiven an initial guess for the consumption vector c0\ncreate a function defined φ on [0,wmax] which interpolates c0 on the grid\nfor each grid point w in the grid, solve the system u-&gt;Phi(w,u,φ, model, approx, slackness=true)\n\nstore the result as a vector c1\n\ncheck whether c1 is close to c0\n\nyes: check the system is indeed solved and return\nno: start again with c1 as c0\n\n\n\n# here is a placeholder implementation to help you structure your program.\n#  feel free to modify or discard\n\n\n\"\"\"\nφ: Float64-&gt;Float64 Initial guess for the consumption function\nmodel: parameters representing the model\napprox: parameters defining the approximation and solution method\nK: max number of iterations\n... other parameters for you to choose\n\"\"\"\nfunction time_iteration(φ0, model, approx; K=200, ... )\n\n    # ...\n\n    # convert initial function φ0 into a consumption vector by evaluating φ on the grid\n    # c0 = ... :: Vector{Float64}\n\n    for k=1:K\n\n        # convert consumption vector c0 into a function φ\n        # φ = ...\n\n        # solve for the optimal consumption for all grid points\n        # ...\n        # c1  :: Vector{Float64}\n\n        # check distance between c0 and c1\n\n        # η = ...\n\n        # if distance is small return function `varphi`\n\n    end\n\n\n\n\nend\n\nCheck that the value returned by time_iteration is actually a solution to the system. How fast is the convergence? Graphical representation.",
    "crumbs": [
      "Coursework",
      "Coursework 2025 - Consumption Saving"
    ]
  },
  {
    "objectID": "homework/2025/coursework_2.html#bonuses",
    "href": "homework/2025/coursework_2.html#bonuses",
    "title": "Coursework 2025 - Consumption Saving",
    "section": "Bonuses",
    "text": "Bonuses\n(easy): perform some sensitivity analysis on the model to explain the effect of the main parameters\n(medium): Give the solution to the above problem, simulate the law of motion for the available income. Find a way to plot the distriution of that income over a long period of time.\n(hard): Propose and implement some ideas to speed up the solution process.\nOne promising avenue consists in solving for all consumption values at all grid points as one single system of equation after recognizing that the jacobian of this particular system has a specific structure.",
    "crumbs": [
      "Coursework",
      "Coursework 2025 - Consumption Saving"
    ]
  },
  {
    "objectID": "homework/2025/coursework_1.html",
    "href": "homework/2025/coursework_1.html",
    "title": "Coursework 2025 - Deep Learning",
    "section": "",
    "text": "Name:\nSurname:\nAfter completing the following questions, send the edited notebook to pablo.winant@ensae.fr. You can work in (small) teams but are not allowed to copy/paste any code. Don’t forget to comment your code and take any initiative you find relevant.",
    "crumbs": [
      "Coursework",
      "Coursework 2025 - Deep Learning"
    ]
  },
  {
    "objectID": "homework/2025/coursework_1.html#learning-the-consumption-rule",
    "href": "homework/2025/coursework_1.html#learning-the-consumption-rule",
    "title": "Coursework 2025 - Deep Learning",
    "section": "Learning the Consumption Rule",
    "text": "Learning the Consumption Rule\nThis exercise is inspired from Individual learning about consumption by Todd Allen and Chris Carroll link and from Deep Learning for Solving Economic models by Maliar, Maliar and Winant link\nWe consider the following consumption saving problem. An agent receives random income \\(y_t = \\exp(\\epsilon_t)\\) where \\(\\epsilon_t\\sim \\mathcal{N}(\\sigma)\\) (\\(\\sigma\\) is the standard deviation.)\nConsumer starts the period with available income \\(w_t\\). The law of motion for available income is:\n\\[w_t = \\exp(\\epsilon_t) + (w_{t-1}-c_{t-1}) r\\]\nwhere consumption \\(c_t \\in ]0,w_t]\\) is chosen in each period in order to maximize:\n\\[E_t \\sum_{t=0}^T \\beta^t U(c_t)\\]\ngiven initial available income \\(w_0\\).\nIn the questions below, we will use the following calibration:\n\n\\(\\beta = 0.9\\)\n\\(\\sigma = 0.1\\)\n\\(T=100\\)\n\\(U(x) = \\frac{x^{1-\\gamma}}{1-\\gamma}\\) with \\(\\gamma=2\\)\n\\(w_0 = 1.1\\) (alternatively, consider values 0.5 and 1)\n\nThe theoretical solution to this problem is a concave function \\(\\varphi\\) such that \\(\\varphi(x)\\in ]0,x]\\) and \\(\\forall t,  c_t=\\varphi(w_t)\\). Qualitatively, agents accumulate savings, up to a certain point (a buffer stock), beyond which wealth is not increasing any more (in expectation).\nCarroll and Allen have noticed that the true solution can be approximated very well by a simple rule:\n\\(\\psi(x) = \\min(x, \\theta_0 + \\theta_1 (x - \\theta_0) )\\)\nThe main question they ask in the aforementioned paper is whether it is realistic that agents would learn good values of \\(\\theta_0\\) and \\(\\theta_1\\) by observing past experiences.\nWe would like to examine this result by checking convergence of speed of stochastic gradient algorithm.\n\nLifetime reward\nDefine a NamedTuple to hold the parameter values\nDefine simple rule fonction consumption(w::Number, θ_0::Number, θ_1::Number, p::NamedTuple) which compute consumption using a simple rule. What is the meaning of \\(\\theta_0\\) and \\(\\theta_1\\)? Make a plot in the space \\(w,c\\), including consumption rule and the line where \\(w_{t+1} = w_t\\).\n(remark for later: Number type is compatible with ForwardDiff.jl 😉)\nWrite a function lifetime_reward(w_0::Number, θ_0::Number, θ_1::Number, p::NamedTuple) which computes one realization of \\(\\sum \\beta^t U(c_t)\\) for initial wealth w_0 and simple rule θ_0, θ_1. Mathematically, we denote it by \\(\\xi(\\omega; \\theta_0, \\theta_1)\\), where \\(\\omega\\) represents the succession of random income draws.\nWrite a function expected_lifetime_reward(w_0::Number, θ_0::Number, θ_1::Number,  p::NamedTuple; N=1000) which computes expected lifetime reward using N Monte-Carlo draws. Mathematically, we write it \\(\\Xi^{N}(\\theta_0, \\theta_1) =\\frac{1}{N} \\sum_1^N {\\xi(\\omega_N; \\theta_0, \\theta_1)}\\). Check empirically that standard deviation of these draws decrease proportionally to \\(\\frac{1}{\\sqrt{N}}\\) .\n__Using a high enough number for N, compute optimal values for \\(\\theta_0\\) and \\(\\theta_1\\). What is the matching value for the objective function converted into an equivalent stream of deterministic consumption ? That is if V is the approximated value computed above, what is \\(\\bar{c}\\in \\R\\) such that $ V= _{t=0}^T ^t U({c})$ ?__\nUsing a high enough number for N, make contour plots of lifetime rewards as a function of θ_0 and θ_1. Ideally, represent lines with \\(1\\%\\) consumption loss, \\(5\\%\\) and \\(10\\%\\) deterministic consumption loss w.r.t. to maximum.\n\n\nLearning to save\nWe now focus on the number of steps it takes to optimize \\(\\theta_0\\), \\(\\theta_1\\).\nImplement a function ∇(θ::Vector; N=1000)::Vector which computes the gradient of the objective w.r.t. θ==[θ_0,θ_1]. (You need to use automatic differentiation, otherwise you might get incorrect results).\nImplement a gradient descent algorithm to maximize \\(\\Xi^N(\\theta_0, \\theta_1)\\) using learning rate \\(\\lambda \\in ]0,1]\\). Stop after a predefined number of iterations. Compare convergence speed for different values of \\(\\lambda\\) and plot them on the \\(\\theta_0, \\theta_1\\) plan. How many steps does it take to enter the 1% error zone? The 5% and the 10% error zone?\nEven for big N, the evaluated value of ∇ are stochastic, and always slightly inaccurate. In average, they are non-biased and the algorithm converges in expectation (it fluctuates around the maximum). This is called the stochastic gradient method.\nWhat are the values of \\(N\\) and \\(\\lambda\\) which minimize the number of iterations before reaching the target zones (at 1%, 2%, etc…)? How many simulations periods does it correspond to? Would you say it is realistic that consumers learn from their own experience?",
    "crumbs": [
      "Coursework",
      "Coursework 2025 - Deep Learning"
    ]
  },
  {
    "objectID": "exam/2025/exam_mie37_2025.html",
    "href": "exam/2025/exam_mie37_2025.html",
    "title": "MIE 37 - Final Exam 2025",
    "section": "",
    "text": "Come back later"
  },
  {
    "objectID": "exam/2023/Exam_mie37_2023.html",
    "href": "exam/2023/Exam_mie37_2023.html",
    "title": "MIE 37 - Final Exam 2023",
    "section": "",
    "text": "Name:\nSurname:\nAfter completing the following questions, send the edited notebook to pablo.winant@ensae.fr.\nYou are allowed to use any online available resource, even to install Julia packages, but not to copy/paste any code.\nAlso, don’t forget to comment your code and take any initiative you find relevant.",
    "crumbs": [
      "Exams",
      "MIE 37 - Final Exam 2023"
    ]
  },
  {
    "objectID": "exam/2023/Exam_mie37_2023.html#power-iteration-method",
    "href": "exam/2023/Exam_mie37_2023.html#power-iteration-method",
    "title": "MIE 37 - Final Exam 2023",
    "section": "Power iteration method",
    "text": "Power iteration method\nIn this exercise, we implement a power iteration method power_iteration(M::Matrix) to compute the biggest eigenvalue of a given matrix M.\nDefine a random 3 times 3 matrix M. Compute its biggest eigenvalue using LinearAlgebra: eigvals.\nDefine a norm2 function, which computes the euclidean norm of any vector. Test it on some simple cases.\n\n\n\nWrite a function iteration_step(M::Matrix, u::Vector)::Tuple{Float64, Vector} which takes a random vector \\(u\\) with norm 1 and returns \\(M u\\) and \\(\\frac{M u}{|M u|}\\).\nWrite a function power_iteration(M::Matrix)::Float64, which computes the spectral radius of M using the power iteration method (spectral radius: absolute value of biggest eigenvalue)\nCheck the result is correct on matrix \\(M\\).",
    "crumbs": [
      "Exams",
      "MIE 37 - Final Exam 2023"
    ]
  },
  {
    "objectID": "exam/2023/Exam_mie37_2023.html#doubling-algorithm",
    "href": "exam/2023/Exam_mie37_2023.html#doubling-algorithm",
    "title": "MIE 37 - Final Exam 2023",
    "section": "Doubling algorithm",
    "text": "Doubling algorithm\nLet \\(M\\) be a square matrix with spectral radius smaller than 1. Our goal here to approximate the infinite sum \\(\\sum_{t\\geq 0} M^t\\) (whose result is a matrix).\nDefine a (non-trivial) 3x3 matrix M with spectral radius smaller than 1.\nPropose an algorithm and a function infinite_sum(M::Matrix) to approximate this sum by computing the limit of \\(S_T = \\sum_{t=0}^{T} M^t\\) when \\(T\\) goes to \\(\\infty\\).\nWe now consider the doubling algorithm. Consider the sum \\(D_N = \\sum_{t\\geq 0}^{2^N} M^t\\). Find a recursive relation between \\(D_N\\) and \\(D_{N+1}\\). Why is \\(D_N\\) less expensive to compute than \\(S^{2 N}\\) ?\nImplement a function infinite_sum_doubling(M::Matrix) which computes the infinite sum using the doubling algorithm. Check the result and time it against the other implementation.",
    "crumbs": [
      "Exams",
      "MIE 37 - Final Exam 2023"
    ]
  },
  {
    "objectID": "exam/2023/Exam_mie37_2023.html#reduced-form-new-keyesian-model",
    "href": "exam/2023/Exam_mie37_2023.html#reduced-form-new-keyesian-model",
    "title": "MIE 37 - Final Exam 2023",
    "section": "Reduced-form New Keyesian model",
    "text": "Reduced-form New Keyesian model\nWe consider the reduced-form New Keynesian Model\n\\[\\pi_t = \\alpha E_t \\pi_{t+1} + y_t\\]\n\\[y_t = \\beta E_t y_{t+1} + \\gamma (i_t-\\pi_t) + \\delta z_t\\]\n\\[i_t = \\alpha_{y} y_t + \\alpha_{\\pi} \\pi_t\\]\nwhere \\(\\pi_t\\) is inflation, \\(y_t\\) the output gap (i.e, the gap to full employment), and \\(z_t\\) an AR1 process given by:\n\\[z_t = \\rho z_{t-1} + \\epsilon_t\\]\nwher \\(\\epsilon_t\\) is a random gaussian process with standard deviation \\(\\sigma_{\\epsilon}\\).\nWe’ll take \\(\\alpha=0.9\\), \\(\\beta=0.9\\), \\(\\gamma=0.1\\), \\(\\alpha_{\\pi}=0.5\\), \\(\\alpha_y=0.5\\), \\(\\rho=0.9\\) and \\(\\sigma=0.01\\).\n\nModel Solution\nDefine a specialized structure to hold all model parameters.\nDefine matrices \\(A\\) (2x2) and \\(B\\) (2x1) such that:\n\\[\\begin{bmatrix}\\pi_t\\\\y_t\\end{bmatrix} = A E_t \\begin{bmatrix}\\pi_{t+1}\\\\y_{t+1}\\end{bmatrix} + B z_t\\]\n\n# text\n\n\n# code\nfunction create_matrices(parameters)\n#     A = ...\n#     B = ...\n    return A, B\nend\n\nAssume the sequence \\(z_0, z_1, ...\\) is known, show that we can write \\(\\begin{bmatrix}\\pi_t\\\\y_t\\end{bmatrix}=\\sum_{s\\geq0} \\rho^s A^s B z_s\\). At which condition on \\(A\\) is this sum absolutely converging?\nCheck that this condition is met for the baseline calibration.\nBonus: find conditions on \\(\\alpha_y\\) and \\(\\alpha_{\\pi}\\) for the sum to be convergent. When it is, in this context, we say that inflation is anchored.\nCompute the solution to the system, that is find two sacalars \\(x_y\\) and \\(x_{\\pi}\\) such that \\(y_t(z) = x_{y} z_t\\) and \\(\\pi_t(z)= x_{\\pi} z_t\\) solve the system.\nCompute matrices \\(P\\) and \\(Q\\) such that \\(\\begin{bmatrix}\\pi_t\\\\y_t\\\\z_t\\end{bmatrix} =  P \\begin{bmatrix}\\pi_{t-1}\\\\y_{t-1}\\\\z_{t-1}\\end{bmatrix} + Q \\epsilon_t\\).\nSimulate variables \\(\\pi_t, y_t, z_t\\) when \\(\\pi_0 =  y_0 = 0, z_0=0.1\\) and \\(\\forall t, \\epsilon_t = 0\\).\nMake \\(N=1000\\) stochastic simulations for \\(T=200\\) periods. Find a way to compute the standard deviation of the ergodic distribution.",
    "crumbs": [
      "Exams",
      "MIE 37 - Final Exam 2023"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "exam/2024/Exam_mie37_2024.html",
    "href": "exam/2024/Exam_mie37_2024.html",
    "title": "MIE 37 - Final Exam 2024",
    "section": "",
    "text": "Name:\nSurname:\nAfter completing the following questions, send the edited notebook to pablo.winant@ensae.fr.\nYou are allowed to use any online available resource, even to install Julia packages, but not to copy/paste any code.\nAlso, don’t forget to comment your code and take any initiative you find relevant.",
    "crumbs": [
      "Exams",
      "MIE 37 - Final Exam 2024"
    ]
  },
  {
    "objectID": "exam/2024/Exam_mie37_2024.html#part-i---linear-regression-and-stochastic-gradient-descent",
    "href": "exam/2024/Exam_mie37_2024.html#part-i---linear-regression-and-stochastic-gradient-descent",
    "title": "MIE 37 - Final Exam 2024",
    "section": "Part I - Linear Regression and Stochastic Gradient Descent",
    "text": "Part I - Linear Regression and Stochastic Gradient Descent\nWe consider the following data generation process:\n\\[y=0.4+2.5 x + \\epsilon\\]\nwhere \\(x_i\\) is uniformly distributed between 0 and 1 and \\(\\epsilon\\) is drawn from a normal distribution with standard deviation \\(\\sigma=0.5\\).\n\nWrite a function draw(a::Number, b::Number)::Tuple{Float64, Float64} which generates one random draw for a pair \\((x,y)\\).\n\n\n# you code here\n\n\nGenerate a sample \\(d=(x_i, y_i)_{i=[1,N]}\\) of \\(N=100000\\) different observations. Justify your choice for how to represent this data.\n\n\n# you code here\n\n\nWrite the loss function \\(L(d,a,b)=\\frac{1}{N}\\sum_{i=1}^N ( a x_i + b-y_i)^2\\). Find the values of \\(a\\) and \\(b\\) minimizing this function by implementing the gradient descent algorithm (do not use any library). What is the best learning rate?\n\n\n# you code here\n\n\nWrite another function ξ(a::Number, b::Number)::Tuple{Float64, Float64, Float64} which returns a random realization of \\(( a x + b - y)^2\\) as well as its derivatives w.r.t. a and b (make sure the derivatives are computed for the same realization of \\(\\epsilon\\)). We call ξ the empirical loss.\n\n(hint: here you can either compute the derivatives by hand, or use an automatic differentiation library)\n\n# you code here\n\n5. Stochastic gradient algorithm.\nThe stochastic gradient algorithm minimizes \\[E\\xi(a,b)\\] with the following steps:\n\nstart with an initial guess \\(a_0,b_0\\)\ngiven a guess \\(a_k, b_k\\)\n\ncompute \\(\\xi, \\xi^{prime}_a, \\xi^{prime}_b\\) using the function from the last function\nmake a new guess \\((a_{k+1}, b_{k+1}) = (1-\\lambda) (a_{k}, b_{k}) - \\lambda (\\xi^{\\prime}_a, \\xi^{\\prime}_b)\\)\n\n\nImplement the SGD algorithm. How many iterations does one needs to get a good approximation of \\(a,b\\)? What value of $ $ works better? Compare with question 3.\n\n# you code here\n\n6. (bonus) Illustrate the convergence by plotting the empirical loss for each step \\(k\\) in the above alogorithm, as well as the validation loss in the same step. (Given \\(a,b\\), the validation loss is the empirical mean of \\(\\xi(a,b)\\) computed using \\(N=1000\\) observations.)\n\n# you code here",
    "crumbs": [
      "Exams",
      "MIE 37 - Final Exam 2024"
    ]
  },
  {
    "objectID": "exam/2024/Exam_mie37_2024.html#part-ii---endogenous-exit",
    "href": "exam/2024/Exam_mie37_2024.html#part-ii---endogenous-exit",
    "title": "MIE 37 - Final Exam 2024",
    "section": "Part II - Endogenous Exit",
    "text": "Part II - Endogenous Exit\n\nDiscretization of an AR1\nThe following code, taken from Quantecon.jl approximates an AR1 process \\[y_t = \\mu + \\rho (y_{t-1}-\\mu) + \\epsilon_t\\] (where \\(\\nu\\) is the standard deviation of normal process \\(\\epsilon\\)), using a finite markov chain with \\(N\\) different values.\nThe output is a transition matrix and a vector containing discretized values \\(y_1, y_2, ... y_p\\)\n\n# uncomment the following line if \"SpecialFunctions\" is not on your system\n# import Pkg; Pkg.add(\"SpecialFunctions\")\n\n\nusing SpecialFunctions: erfc\n\nstd_norm_cdf(x::T) where {T &lt;: Real} = 0.5 * erfc(-x/sqrt(2))\nstd_norm_cdf(x::Array{T}) where {T &lt;: Real} = 0.5 .* erfc(-x./sqrt(2))\n\nfunction tauchen(N::Integer, ρ::T1, σ::T2, μ=zero(promote_type(T1, T2)), n_std::T3=3) where {T1 &lt;: Real, T2 &lt;: Real, T3 &lt;: Real}\n    # Get discretized space\n    a_bar = n_std * sqrt(σ^2 / (1 - ρ^2))\n    y = range(-a_bar, stop=a_bar, length=N)\n    d = y[2] - y[1]\n\n    # Get transition probabilities\n    Π = zeros(promote_type(T1, T2), N, N)\n    for row = 1:N\n        # Do end points first\n        Π[row, 1] = std_norm_cdf((y[1] - ρ*y[row] + d/2) / σ)\n        Π[row, N] = 1 - std_norm_cdf((y[N] - ρ*y[row] - d/2) / σ)\n\n        # fill in the middle columns\n        for col = 2:N-1\n            Π[row, col] = (std_norm_cdf((y[col] - ρ*y[row] + d/2) / σ) -\n                           std_norm_cdf((y[col] - ρ*y[row] - d/2) / σ))\n        end\n    end\n\n    yy = y .+ μ / (1 - ρ) # center process around its mean (wbar / (1 - rho)) in new variable\n\n    (;transitions=Π, values=yy)\n\nend\n\ntauchen (generic function with 3 methods)\n\n\n1. Take \\(\\rho=0.95, \\mu=0.1, \\nu=0.1\\). Approximate the AR1 with 200 discrete states, using the tauchen function above. Check that all rows sum to 1. Compute and plot the steady-state distribution.\n\n# you code here\n\nConsider a firm whose productivity \\(y_t\\) is exogenous and evolves according to the markov chain above.\nProfits are given by \\(\\pi(y_t) = y_t\\).\nAt the start of each period, the firm decides whether to remain in operation and receive current profit \\(\\pi_t\\) or to exit and receive scrap value \\(s&gt;0\\) for the sale of physical assets.\nTime is discounted using interest rate, that is \\(\\beta=\\frac{1}{1+r} \\in [0,1[\\).\nThe following code creates a parameterization of the firm’s problem:\n\n\"Creates an instance of the firm exit model.\"\nfunction create_exit_model(;\n    n=200, # productivity grid size\n    ρ=0.95, μ=0.1, ν=0.1, # persistence, mean and volatility\n    β=0.98, s=100.0 # discount factor and scrap value\n    )\n    mc = tauchen(n, ρ, ν, μ)\n    z_vals, Q = mc.state_values, mc.p\n    return (; n, z_vals, Q, β, s)\nend\n\ncreate_exit_model\n\n\n2. What are the states of the problem? The controls? The rewards? What equation defines the value of the firm? How would you represent numerically the value function and the decision rule?\n\n# you code here\n\n3. Solve for the optimal exit decision using value function iteration. Plot the results.\n\n# you code here\n\n4. (bonus) Taking into account the specific nature of this problem, propose a more efficient algorithm.\n\n# you code here",
    "crumbs": [
      "Exams",
      "MIE 37 - Final Exam 2024"
    ]
  },
  {
    "objectID": "homework/2024/Coursework_mie37_2024.html",
    "href": "homework/2024/Coursework_mie37_2024.html",
    "title": "Homework 2024",
    "section": "",
    "text": "Name:\nSurname:\nAfter completing the following questions, send the edited notebook to pablo.winant@ensae.fr. You can work in (small) teams but are not allowed to copy/paste any code. Don’t forget to comment your code and take any initiative you find relevant."
  },
  {
    "objectID": "homework/2024/Coursework_mie37_2024.html#general-problem",
    "href": "homework/2024/Coursework_mie37_2024.html#general-problem",
    "title": "Homework 2024",
    "section": "General Problem",
    "text": "General Problem\nWe seek to solve numerically the following consumption-saving problem using the time-iteration algorithm.\nIncome is an iid normally distributed process with standard deviation \\(\\sigma\\). Interest rate is \\(r\\in [1,\\frac{1}{\\beta}[\\) where \\(\\beta\\in]0,1[\\) is the discount factor.\nAvailable income is \\(w_t\\) and follows the law of motion:\n\\[w_{t+1} = e^ {\\epsilon_{t+1}} +  (w_{t} - c_{t}) r\\]\nwhere \\(c_t \\in ]0,w_t]\\) is consumption chosen at date \\(t\\) (which includes an implicit no borrowing constraint)."
  },
  {
    "objectID": "homework/2024/Coursework_mie37_2024.html#calibration",
    "href": "homework/2024/Coursework_mie37_2024.html#calibration",
    "title": "Homework 2024",
    "section": "Calibration",
    "text": "Calibration\nWe will use the following calibration:\n\\(\\sigma = 0.01\\)\n\\(\\beta = 0.96\\)\n\\(r = 1.03\\)\nChoose a structure model to represent the model parameters.\n\n\n# model = ..."
  },
  {
    "objectID": "homework/2024/Coursework_mie37_2024.html#representing-the-decision-function",
    "href": "homework/2024/Coursework_mie37_2024.html#representing-the-decision-function",
    "title": "Homework 2024",
    "section": "Representing the decision function",
    "text": "Representing the decision function\nThe solution of the model is a decision rule \\(c(w)\\).\nIn what follows, we will approximate it by a function defined over \\([0,w_{max}[\\), pinned down by the values it takes on \\(N\\) linearly spaced grid points.\nIn our solutions algorithm, we will use the initial guess \\(\\varphi_0(w) = min(w, p_0+p_1(w-p_0))\\).\nCreate a structure approx to represent the approximation space. This structure should contain the parameters, as well as a points::Vector{Float64} array coontaining the (regularly spaced) list of grid points.\nTo start with you can take \\(w_{max}=5\\), \\(N=20\\), \\(p_0=0.95, p_1=0.03\\) but don’t hesitate to change these values later if needed.\n\n# approx = ...\n\nDefine a method φ_0(w::Float64)::Float64 for the initial guess. Plot it against \\(w\\) in the approximation space.\nCompute the values c_0::{Float64}of φ_0() on the grid points\nUse the Interpolations.jl library to define a function φ(w::Float64) defined for any w using piecewise linear interpolation in such a way that it takes values c_0 on the grid points.\nCreate a single plot with:\n\nthe function φ_0()\nthe interpolated function \\(φ\\)\nits values c_0 on the grid points\n\nBonus: add to the graph the function obtained using cubic spline interpolation. What could be the problem?"
  },
  {
    "objectID": "homework/2024/Coursework_mie37_2024.html#discretizing-epsilon_t1",
    "href": "homework/2024/Coursework_mie37_2024.html#discretizing-epsilon_t1",
    "title": "Homework 2024",
    "section": "Discretizing \\(\\epsilon_{t+1}\\)",
    "text": "Discretizing \\(\\epsilon_{t+1}\\)\nRepresent the shock \\(\\epsilon\\) by two vectors \\((e_1, ... e_q)\\) and \\((l_1, ..., l_q)\\) with \\(q=10\\) such that for a suitable function \\(g\\) we can approximate \\(E_{\\epsilon} (g(\\epsilon))\\) by \\(\\sum_{i=1}^q l_i e_i\\) .\n(choose the method you want)\n\n# e = ...\n# w = ...\n\nTest that it works by computing \\(E_{\\epsilon} \\left[ \\epsilon^2 \\right]\\).\nRedefine approx so as to include the discretized shock"
  },
  {
    "objectID": "homework/2024/Coursework_mie37_2024.html#euler-equation",
    "href": "homework/2024/Coursework_mie37_2024.html#euler-equation",
    "title": "Homework 2024",
    "section": "Euler equation",
    "text": "Euler equation\nWrite down the Euler equation, paying attention to the slackness condition.\nIt should be of the form \\[0 \\leq \\underbrace{E_t \\left[ f(w_t, c_t, w_{t+1}, c_{t+1}, \\epsilon_{t+1}) \\right]}_{\\Phi_t} \\perp c_t \\leq w_t\\]\nwhere \\(f\\) is a function to be explicited.\nDefine the function Phi(w::Float64,c::Float64,φ::Fun, model, approx) which approximates the residuals of the euler equation given the available income today, the consumption choice today, the consumption function tomorrow and the model/approx structures.\nOverload Phi function with another method Phi(w::Float64,c::Float64,φ::Fun, model, approx, slackness=true) which uses the Fisher-Burmeister transform to incorporate the credit constraint.\nPlot the optization residuals (i.e. values of \\(\\Phi_t\\)) corresponding to the initial guess function with and without the complementarity constraints."
  },
  {
    "objectID": "homework/2024/Coursework_mie37_2024.html#time-iteration",
    "href": "homework/2024/Coursework_mie37_2024.html#time-iteration",
    "title": "Homework 2024",
    "section": "Time Iteration",
    "text": "Time Iteration\n(prep): Assuming the initial guess \\(φ_0()\\) is the decision rule followed tomorrow, determine, for a given value w in the state-space, the optimal consumption choice made today. This can be achieved by feeding the appropriate function into the right nonlinear root-finder.\n(prep): Find the vector of all the optimal consumption choices on the grid today, given the decision rule tomorrow.\nPlot the optimization residuals (i.e. values of \\(\\Phi_t\\)) for the initial guess function\nWrite down the time-iteration algorithm.\nYou can use the course as reference and/or repeat the recurrence steps below:\n\ngiven an initial guess for the consumption vector c0\ncreate a function defined φ on [0,wmax] which interpolates c0 on the grid\nfor each grid point w in the grid, solve the system u-&gt;Phi(w,u,φ, model, approx, slackness=true)\n\nstore the result as a vector c1\n\ncheck whether c1 is close to c0\n\nyes: check the system is indeed solved and return\nno: start again with c1 as c0\n\n\n\n# here is a placeholder implementation to help you structure your program.\n#  feel free to modify or discard\n\n\n\"\"\"\nφ: Float64-&gt;Float64 Initial guess for the consumption function\nmodel: parameters representing the model\napprox: parameters defining the approximation and solution method\nK: max number of iterations\n... other parameters for you to choose\n\"\"\"\nfunction time_iteration(φ0, model, approx; K=200, ... )\n\n    # ...\n\n    # convert initial function φ0 into a consumption vector by evaluating φ on the grid\n    # c0 = ... :: Vector{Float64}\n\n    for k=1:K\n\n        # convert consumption vector c0 into a function φ\n        # φ = ...\n\n        # solve for the optimal consumption for all grid points\n        # ...\n        # c1  :: Vector{Float64}\n\n        # check distance between c0 and c1\n\n        # η = ...\n\n        # if distance is small return function `varphi`\n\n    end\n\n\n\n\nend\n\nCheck that the value returned by time_iteration is actually a solution to the system. How fast is the convergence? Graphical representation."
  },
  {
    "objectID": "homework/2024/Coursework_mie37_2024.html#bonuses",
    "href": "homework/2024/Coursework_mie37_2024.html#bonuses",
    "title": "Homework 2024",
    "section": "Bonuses",
    "text": "Bonuses\n(easy): perform some sensitivity analysis on the model to explain the effect of the main parameters\n(medium): Give the solution to the above problem, simulate the law of motion for the available income. Find a way to plot the distriution of that income over a long period of time.\n(hard): Propose and implement some ideas to speed up the solution process.\nOne promising avenue consists in solving for all consumption values at all grid points as one single system of equation after recognizing that the jacobian of this particular system has a specific structure."
  },
  {
    "objectID": "homework/2025/coursework_3.html",
    "href": "homework/2025/coursework_3.html",
    "title": "Coursework 2025 - Ayiagari Model",
    "section": "",
    "text": "Consider the function \\(f(x)=\\frac{sin(|x|)}{|x|+0.0001}\\) defined on \\([a,b]\\) with \\(a=-2\\) and \\(b=2\\).\nConsider the grid points \\(x_i=a+\\frac{i}{N-1}(b-a)\\) for \\(i\\in[0,N]\\).\n\nDefine in julia a, b, N and the function f . Compute the vector of grid points s (a vector of size N) then the values y (a vector of size N)that f takes at these grid points.\n\n# your code here\n\nDefine a function interp(s,y,x) which approximates the original function f at any \\(x\\in[-2,2]\\) but is defined using only s and y (or if you prefer a,b, N and y). (hint: you can use the library Interpolations.jl)\n\n# your code here\n\nOn the same plot, represent (s,y) as a scatter plot, the function f and the interpolated values using interp. For the \\(x\\)-axis choose \\([a-0.1, b+0.1]\\). How does interp behave outside of \\([a,b]\\) (i.e. when it extrtapolates). Can you find a way to make it exptrapolate linearly?\n\n# your code here\n\n\n\nConsider a random shock \\(\\epsilon\\) that follows a normal law with standard deviation \\(\\sigma\\).\nThe goal here is just to compute numerically the integral\n\\[\\mathbb{E} f(\\epsilon)\\]\n\nDefine a variable \\(\\sigma\\). Choose a function f so that you can compute the above integral in closed form.\n\n# your code here\n\n\nTake an integer \\(K&gt;0\\).\n\nTry to evaluate the integral above by running \\(K\\) random draws i.e. by using the formula \\(f^{MC, K} = \\frac{1}{K}\\sum_{i=1}^K f(\\epsilon_i)\\) where \\(\\epsilon_i\\) is a random draw. Ths is the Monte-Carlo approach.\n\n# your code here\n\nEvaluate the standard deviation in \\(f^{MC, K}\\) by evaluating this function repeatedly. How does the standard deviation depend on \\(K\\) ?\n\n# your code here\n\n\n\nDiscretizing the shock consists in finding real numbers \\((x_1, ... x_K)\\) and positive real numbers \\((w_1, ... w_K)\\) such that for a “suitable” function \\(f(\\epsilon)\\) we can write:\n\\[\\mathbb{E} f(\\epsilon) \\approx \\sum_{i=1}^K w_i f(e_i)\\]\nThe Gauss-Hermite quadrature is such a discretization scheme. It is widely documented and there are good Julia libraries for it.\n\nApproximate the expectation above using Gauss-Hermite nodes and weights. What is the error? How does it depend on \\(K\\) for the function you have chosen?\n\n# your code here"
  },
  {
    "objectID": "homework/2025/coursework_3.html#part-i-approximations",
    "href": "homework/2025/coursework_3.html#part-i-approximations",
    "title": "Coursework 2025 - Ayiagari Model",
    "section": "",
    "text": "Consider the function \\(f(x)=\\frac{sin(|x|)}{|x|+0.0001}\\) defined on \\([a,b]\\) with \\(a=-2\\) and \\(b=2\\).\nConsider the grid points \\(x_i=a+\\frac{i}{N-1}(b-a)\\) for \\(i\\in[0,N]\\).\n\nDefine in julia a, b, N and the function f . Compute the vector of grid points s (a vector of size N) then the values y (a vector of size N)that f takes at these grid points.\n\n# your code here\n\nDefine a function interp(s,y,x) which approximates the original function f at any \\(x\\in[-2,2]\\) but is defined using only s and y (or if you prefer a,b, N and y). (hint: you can use the library Interpolations.jl)\n\n# your code here\n\nOn the same plot, represent (s,y) as a scatter plot, the function f and the interpolated values using interp. For the \\(x\\)-axis choose \\([a-0.1, b+0.1]\\). How does interp behave outside of \\([a,b]\\) (i.e. when it extrtapolates). Can you find a way to make it exptrapolate linearly?\n\n# your code here\n\n\n\nConsider a random shock \\(\\epsilon\\) that follows a normal law with standard deviation \\(\\sigma\\).\nThe goal here is just to compute numerically the integral\n\\[\\mathbb{E} f(\\epsilon)\\]\n\nDefine a variable \\(\\sigma\\). Choose a function f so that you can compute the above integral in closed form.\n\n# your code here\n\n\nTake an integer \\(K&gt;0\\).\n\nTry to evaluate the integral above by running \\(K\\) random draws i.e. by using the formula \\(f^{MC, K} = \\frac{1}{K}\\sum_{i=1}^K f(\\epsilon_i)\\) where \\(\\epsilon_i\\) is a random draw. Ths is the Monte-Carlo approach.\n\n# your code here\n\nEvaluate the standard deviation in \\(f^{MC, K}\\) by evaluating this function repeatedly. How does the standard deviation depend on \\(K\\) ?\n\n# your code here\n\n\n\nDiscretizing the shock consists in finding real numbers \\((x_1, ... x_K)\\) and positive real numbers \\((w_1, ... w_K)\\) such that for a “suitable” function \\(f(\\epsilon)\\) we can write:\n\\[\\mathbb{E} f(\\epsilon) \\approx \\sum_{i=1}^K w_i f(e_i)\\]\nThe Gauss-Hermite quadrature is such a discretization scheme. It is widely documented and there are good Julia libraries for it.\n\nApproximate the expectation above using Gauss-Hermite nodes and weights. What is the error? How does it depend on \\(K\\) for the function you have chosen?\n\n# your code here"
  },
  {
    "objectID": "homework/2025/coursework_3.html#part-ii-the-ayiagari-model",
    "href": "homework/2025/coursework_3.html#part-ii-the-ayiagari-model",
    "title": "Coursework 2025 - Ayiagari Model",
    "section": "Part II : The Ayiagari Model",
    "text": "Part II : The Ayiagari Model\nIn this exercise, we try to solve the Ayiagari model.\nThe Ayiagari model features a continuum of households indexed by \\(i\\in[0,1]\\), who take wage rate \\(\\color{red} w\\) and interest rate \\(\\color{red} r\\) as given.\nEach households \\(i\\) is hit by a random productivity shock (\\(\\color{green}e^i_t\\)), normally distributed, with variance \\(\\sigma\\) and mean \\(1\\) so that, at the aggregate, the average productivity is \\(1\\).\nEach household supplies \\(\\color{green}e^i_t\\) units of work, and can decide to consume \\(c^i_t\\) or save her available income \\(a^i_{t}\\).\nAvailable income \\(a^i_t\\) thus follows the law of motion:\n\\[a^i_{t+1} = {\\color{red}w } {\\color{green}e^i_{t+1}} +  (a^i_{t} - c^i_{t}) {\\color{red}r}\\]\nThere is no borrowing so that \\(0&lt;c^i_t\\leq a^i_{t}\\). The household choooses consumption optimally in order to maximize:\n\\[\\mathbb{E}_0 \\sum_t \\beta^t U(c^i_t)\\]\nwith \\(U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}\\) and \\(\\beta=0.96\\), \\(\\gamma=4.0\\).\nAggregate savings are turned into productive capital:\n\\[K = \\int_i a^i_t \\]\nNote that in equilibrium the distribution of savings is invariant, hence the absence of a time-subscript for aggregate capital.\nAlso, the ergodicity property implies that the invariant distribution across all agents is identical to the distribution of asset levels reached across time by any single agent \\(i\\) so that we also have:\n\\[K = \\mathbb{E} [ a^i_t ]\\]\nCapital is rented by competitive firms that all produce with the same Cobb-Douglas technology. Total production is:\n\\[Y = K^{\\alpha} L^{1-\\alpha}\\]\nwith \\(L=\\overline{L}=1\\) and \\(\\alpha=0.3\\).\nWage rate and interest rate are then determined by marginal conditions:\n\\[{\\color{red}r}=\\alpha \\frac{Y}{K}\\] \\[{\\color{red}w}=(1-\\alpha) \\frac{Y}{L}\\]\nFrom the structure of the whole model, it is clear that capital \\(\\overline{K}\\) determines the whole equilibrium.\n\n\n\n\n\n\nNote\n\n\n\nBecause there is no depreciation, the rental rate determined by the marginal conditions, equals the returns on savings when they are turned into productive capital.\n\n\n\nAggregate production\n\nCreate a namedtuple (or a structure) m to hold all the model informations.\n\n# your code here\n\nCreate a function rates(K,m)::Tuple{Float64,Float64} that takes aggregate capital and return the rental rate of capital and the wage rate.\n\n# your code here\n\nChoose an initial level of capital \\(K_0\\) and corresponding rates \\(p_0=(r_0,w_0)\\) so that \\(\\beta &lt; \\beta r_0 &lt; 1\\). Define the corresponding varaibles K_0 and p_0.\n\n\n\n\n\n\n\nNote\n\n\n\nThe second part of this inequality ensures that wealth distribution is well defined – agents don’t want to accumulate assets until they have unbounded wealth.\n\n\n\n\nConsumption-Savings Problem\nWe now solve the individual problem given the vector of rates p. This can be done using any solution method (any version of time-iteration for instance). Here we choose to use the classic value-function iteration instead.\nGiven the formulation of the household problem, we can look for a decision rule for consumption \\(c(a)\\) with \\(c(a)\\in]0,a]\\). To implement value function iteration, we will also define \\(V(a)\\).\n\n\n\n\n\n\nNote\n\n\n\nSince all agents are identical ex ante, we need to solve only one optimization problem. Hence we drop the \\(i\\) subscripts.\n\n\nIn theory, the state-space is \\(]0,\\infty]\\) but in practice we approximate the system on \\(]0,\\overline{A}]\\) and adjust \\(\\overline{A}\\) until the solution is well defined.\n\n\n\n\n\n\nNote\n\n\n\nIf \\(\\color{green}e^i_t\\) has a compact support, theoretical considerations show that one can choose such an \\(\\overline{A}\\).\n\n\n\nWrite the Bellman equation\n\nyour text there\n\nApproximate space\nTo represent functions (\\(c()\\) and \\(V()\\)) using a finite number of parameters, we discretize the state-space into a finite grid g, made of \\(N\\) linearly spaced points between \\(\\epsilon&gt;0\\) and \\(\\overline{A}\\) (the role of \\(\\epsilon&gt;0\\) is to avoid undefined behaviour for \\(c=0\\)).\nWe use gauss-hermite nodes and weights weights to approximate the shock \\(\\epsilon\\).\n\nCreate a namedtuple dis to represent the discretized model (i.e. the grid and the quadrature).\n\n# your code here\n\n\nValue Function Iteration\n\nTake an initial guess vvec (preferably concave) for the values on the grid and define the function value_update(a, c, vvec, m, p, dis)::Float64 which compute the expression inside the max in the Bellman equation for any state a, any acceptable consumption level c and a continuation value, obtained by interpolating the values vvec at any point outside the grid.\n\n# your code here\n\nUse your preferred method for constrained optimization to compute the value \\(c\\in]0,a]\\) which maximizes the function value_update for a given a of your choice.\n\n\n\n\n\n\n\nNote\n\n\n\nThis is the crucial step. You can test whether it works for different values of a and debug what’s going by making a plot.\n\n\n# your code here\n\nWrite a function bellman_step(vvec, m, p, dis)::Tuple{Vector, Vector} which takes in a vector representing the value function tomorrow and returns a new value vector and policy vector resulting from the maximization.\n\n# your code here\n\nWrite a vfi(m, p, dis) function, which solves the consumption savings problem by value function iteration. It should return the vector of values and the consumption vector.\n\n# your code here\n\nCheck that the solution makes sense: plot the solution, the boundaries, check the extrapolation behaviour…\n\n# your code here\n\n\nPolicy Function Iteration\n\nSolve the consumption savings problem using policy function iteration (i.e. using howard improvement steps). Compare execution time with value function iteration.\n\n\n\n\n\n\n\nNote\n\n\n\nYou might need to define some intermediary functions, like value_step which updates the value at all grid points, for a given vector of policy choices and policy_eval which returns the value vector obtained by iterating value_step many times.\n\n\n# your code here\n\n\n\nComputing the Stable Distribution\nNow that we have a consumption rule represented by a vector of consumption values cvec, we would like to compute the corresponding ergodic distribution in order to approximate capital supply \\(\\int_i a_i\\)\n\nWith Monte Carlo\n\nWrite a function transition(a, cvec, m, p) which returns a new random asset level, from an initial a. The consumption choices are defined using cvec and can be interpolated as before.\n\n# your code here\n\nPropose a way to draw \\(L=1000\\) random points from the ergodic distribution. Plot the result.\n\n# your code here\n\nCompute the average of these values. It corresponds to the capital supply. What is the standard deviation of this method? (you can evaluate the standard deviation by performing the procedure again)\n\n# your code here\n\n\nWith a Markov Chain\n\nWrite a function transition(a, c, m, p, dis)::Vector{Tuple{Float64, Float64}} which returns a vector of asset levels with matching probabilities, obtained from initial level a, with consumption choice c for the various realizations of the discretized shocks (obtained from the quadrature).\n\n# your code here\n\nUse the transition function to define a stochastic matrix P of size \\(N\\times N\\) such that \\(P_{ij}\\) represents the probability of reaching grid point \\(j\\) from grid point \\(i\\). Use the trembling hand method to deal with asset levels that are out of the approximation grid.\n\n\n\n\n\n\n\nTremblilng hand\n\n\n\nWhen a given asset level \\(a\\) reached with probability \\(w\\) falls between two grid points \\(a_j\\) and \\(a_{j+1}\\), we consider that it reaches \\(a_j\\) with probability \\(w\\frac{a_{j+1}-a}{a_{j+1}-a_j}\\) and \\(a_{j+1}\\) with probability \\(w\\frac{a_{a-a_j}{a_{j+1}-a_j}\\). This trick ensures that the stochastic matrix depends smoothly on the decision rule.\n\n\n# your code here\n\nCompute the stable distribution \\(\\mu\\) of \\(P\\). Compute the capital demand.\n\n# your code here\n\n\n\nSolve the Model\n\nUsing everything you have done so far write a function capital_supply(K, m, p, dis) which computes the rates corresponding to K, solves the consumption problem, computes the ergodic distribution and the corresponding capital supply.\n\n# your code here\n\nPlot capital supply and capital demand (line \\(K=K\\)) for different levels of capital. Find the level of capital such that market for capital clears.\n\n# your code here"
  },
  {
    "objectID": "1_epidemiology.html",
    "href": "1_epidemiology.html",
    "title": "Epidemiology Models",
    "section": "",
    "text": "H.W. Heathcote: epidemiologic models are deterministic models for infectious diseases which are spread by direct person-to-person contact in a population.\nThis kind of models has been used since by a few decades by economist, for matters that have nothing to do with health.\n\ndiffusion of information, or opinions on social medias\nasset prices and fads\nexpectation formation for macroeconomic outcomes (ex: The Epidemiology of Macroeconomic Expectations by Chris Carroll)\n\nEpidemiologic models have two features that depart from standard economic models:\n\nAgent’s behaviour does not take the full system into account, an is irrational in the sense that it isn’t forward looking. Instead, an agent is given a behavioural heuristic.\nThe transitions of the whole system can be determined without solving for complex interactions first.\n\nUnderstanding why these two assumptions are very costly for economists will keep us busy during a big part of the course. Here we just consider two simple models as small programming exercises.\n\nSimple SIR model\nThere is a continuum of agents of mass \\(1\\). Each agent can be either “Susceptible” (S), “Infected” (I) or “Recovered” (R). In each period, one agent meets another agent drawn randomly. During a meeting Susceptible agents who meet an infected agent, will always catch the disease (or the fad) but are not contagious. Infected agents, have a probability \\(\\pi\\) of being recovered. Nothing happens to Recovered agents who meet other people. No distinction is made between recovering as a healthy or a dead person.\nWe’re interested in the evolution in the number infected persons, both the speed of infection and the total amount of infected people in every period.\nWrite down the transition equations for \\(n_I\\), the number of infected people, for \\(n_R\\) the number of recovered people and \\(n_S\\) the number of susceptible people.\nCompute the transition function f for the vector state \\(s_t\\) returning \\(s_{t+1}\\).\nCompute the transitions over \\(T\\) periods. Plot the result using Plots.jl. (bonus: check against closed form solution)\nWe now assume a Susceptible person who meets an infected one has a probability \\(\\mu\\) of catching the disease. Update the transition function. Update function \\(f\\) and write a function of \\(\\mu\\), \\(\\pi\\) which returns the simulation. Compare different values of the parameters. How would you interpret “social distancing”? How would you choose parameters \\(\\Pi\\) and \\(\\mu\\)\n\n\nA Spatial SIR model\nWe now consider another version of the model where agents evolve in the space \\(\\mathcal{S}=[0,1]\\times[0,1]\\). There are \\(N\\in\\mathbb{N}\\) agent. At any date, each agent \\(n \\in [0,1]\\) is located at \\((x_n,y_n)\\in \\mathcal{S}\\).\nEach agent moves follows a random walk bounded by \\(\\mathcal{S}\\): \\[x_t = \\min(\\max( x_{t-1} + \\epsilon_t, 0), 1)\\] \\[y_t = \\min(\\max( y_{t-1} + \\eta_t, 0), 1)\\] where \\(\\epsilon_t\\) and \\(\\eta_t\\) are both normally distributed with standard deviation \\(\\sigma\\).\nAt any date, the individual state of an agent is \\(s_t=(x_t, y_t, h_t)\\) where \\(h_t\\) is either “S”, “I” or “R”. \\(v_t\\) denotes the states of all agents (for instance \\(v_t=(s_{n,t})_n\\). The health status of each agent is updated in the following way:\n\nAgents \\(R\\) stay \\(R\\).\nAgents \\(I\\) have probability \\(\\pi\\) to become \\(R\\). They stay \\(I\\) otherwise.\nAn agent of type \\(S\\) in position \\((x,y)\\) has a probability \\(prob(x,y,S)\\) to be infected that is \\(\\mu\\) if there is another infected agent within a radius \\(r&gt;0\\).\n\nDefine a type Agent, which holds the type of an agent. The state of the whole system will be held in a Vector[Agent] type.\nWrite a function spatial_transition(S::Vector{Agent})::Vector{Agent} to compute the transition of the positions. Write another function random_guess(T=100) which simulates for \\(T\\) periods in order to find a good initial guess.\nWrite a function show_population to plot all agents with different colors for different health status.\nWrite a function evolve(S::Vector[Agent])::Vector[Agent] which takes the population in a given state and returns the same population with updated health status.\nWrite a function simulate(S0::Vector[Agent], k=1) to simulate the economy starting from an initially random position with k infected individuals. The returned object should be of type Vector[Vector[Agent]].\nCompute statistics along a simulated path for \\(n_I\\), \\(n_S\\), \\(n_R\\). Plot and compare with the basic SIR model\n\n\nAdditional questions\nHave fun by trying to answer one of these questions: - change probability of infection so that it depends on the number of infected people in the vincinity (with some suitable functional formulation for) - compute an animation of the transition - compute an interactive visualisation (with Interact.jl if available)"
  },
  {
    "objectID": "slides/session_2/index.html#life-of-a-computational-economist",
    "href": "slides/session_2/index.html#life-of-a-computational-economist",
    "title": "Convergence of Sequences",
    "section": "Life of a computational economist",
    "text": "Life of a computational economist",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#life-of-a-computational-economist-1",
    "href": "slides/session_2/index.html#life-of-a-computational-economist-1",
    "title": "Convergence of Sequences",
    "section": "Life of a computational economist",
    "text": "Life of a computational economist\nVideo\n\n\nWe spend a lot of time waiting for algorithms to converge!\n\n\nsolution 1: program better\n\nsolution 2: better algorithms\n\neven better: understand convergence properties (information about the model)",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#recursive-sequence",
    "href": "slides/session_2/index.html#recursive-sequence",
    "title": "Convergence of Sequences",
    "section": "Recursive sequence",
    "text": "Recursive sequence\nConsider a function \\(f: R^n\\rightarrow R^n\\) and a recursive sequence \\((x_n)\\) defined by \\(x_0\\in R^n\\) and \\(x_n = f(x_{n-1})\\).\nWe want to compute a fixed point of \\(f\\) and study its properties.\n  \n\nToday: Some methods for the case \\(n=1\\).\n  \n\n\nAnother day:\n\nthe matrix case: \\(x_n = A^n x_0\\) whre \\(A\\in R^n \\times R^n\\)\nthe finite nonlinear case: \\(x_n = f(x_{n-1})\\)",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#example-growth-model",
    "href": "slides/session_2/index.html#example-growth-model",
    "title": "Convergence of Sequences",
    "section": "Example: growth model",
    "text": "Example: growth model\n\n\n\nSolow growth model:\n\ncapital accumulation: \\[k_t = (1-\\delta)k_{t-1} + i_{t-1}\\]\nproduction: \\[y_t = k_t^\\alpha\\]\nconsumption: \\[c_t = (1-{\\color{red}s})y_t\\] \\[i_t = s y_t\\]\n\n\n\n\n\n\n\nFor a given value of \\({\\color{red} s}\\in\\mathbb{R}^{+}\\) ( \\({\\color{red} s}\\) is a decision rule) \\[k_{t+1} = f(k_t, {\\color{red} s})\\]\n\nbackward-looking iterations\nSolow hypothesis: saving rate is invariant\n\n\n\nQuestions:\n\nWhat is the steady-state?\nCan we characterize the transition back the steady-state?\nCharacterize the dynamics close to the steady-state?\nwhat is the optimal \\(s\\) ?",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#another-example-linear-new-keynesian-model",
    "href": "slides/session_2/index.html#another-example-linear-new-keynesian-model",
    "title": "Convergence of Sequences",
    "section": "Another example: linear new keynesian model",
    "text": "Another example: linear new keynesian model\n\n\n\nBasic New Keynesian model (full derivation if curious )\n\nnew philips curve (PC):\\[\\pi_t = \\beta \\mathbb{E}_t \\pi_{t+1} + \\kappa y_t\\]\ndynamic investment-saving equation (IS):\\[y_t = \\beta \\mathbb{E}_t y_{t+1} - \\frac{1}{\\sigma}(i_t - \\mathbb{E}_t(\\pi_{t+1}) ) - {\\color{green} z_t}\\]\ninterest rate setting (taylor rule): \\[i_t = \\alpha_{\\pi} \\pi_t + \\alpha_{y} y_t\\]\n\n\nSolving the system:\n\nsolution: \\(\\begin{bmatrix}\\pi_t \\\\\\\\ y_t \\end{bmatrix} = {\\color{red} c} z_t\\)\n\n\n\n\n\nforward looking:\n\ntake \\(\\begin{bmatrix}\\pi_{t+1} \\\\\\\\ y_{t+1} \\end{bmatrix} = {\\color{red} {c_n}} z_{t+1}\\)\ndeduce \\(\\begin{bmatrix}\\pi_{t} \\\\\\\\ y_{t} \\end{bmatrix} = {\\color{red} {c_{n+1}}} z_{t}\\)\n\\(\\mathcal{T}: \\underbrace{c_{n}}_{t+1: \\; \\text{tomorrow}} \\rightarrow \\underbrace{c_{n+1}}_{t: \\text{today}}\\) is the time-iteration operator (a.k.a. Coleman operator)\n\n\n\n\n\n\nQuestions:\n\nWhat is the limit to \\(c_{t+1} = \\mathcal{T} c_n\\) ?\nUnder wich conditions (on \\(\\alpha_{\\pi}, \\alpha_y\\)) is it convergent ?\n\ndeterminacy conditions\ninterpretation: does the central bank manage to control inflation expectations?",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#recursive-sequence-2",
    "href": "slides/session_2/index.html#recursive-sequence-2",
    "title": "Convergence of Sequences",
    "section": "Recursive sequence (2)",
    "text": "Recursive sequence (2)\n\n\nWait: does a fixed point exist?\n\nwe’re not very concerned by the existence problem here\nwe’ll be happy with local conditions (existence, uniqueness) around a solution\n\nIn theoretical work, there are many fixed-point theorems to choose from.\nFor instance, we can assume there is an interval such that \\(f([a,b])\\subset[a,b]\\). Then we know there exists \\(x\\) in \\([a,b]\\) such that \\(f(x)=x\\). But there can be many such points.",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#example-growth-model-with-multiple-fixed-points",
    "href": "slides/session_2/index.html#example-growth-model-with-multiple-fixed-points",
    "title": "Convergence of Sequences",
    "section": "Example: growth model with multiple fixed points",
    "text": "Example: growth model with multiple fixed points\n\nMultiple equilibria in the growth modelIn the growth model, if we change the production function: \\(y=k^{\\alpha}\\) for a nonconvex/nonmonotonic one, we can get multiple fixed points.",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#convergence",
    "href": "slides/session_2/index.html#convergence",
    "title": "Convergence of Sequences",
    "section": "Convergence",
    "text": "Convergence\n\nGiven \\(f: R \\rightarrow R\\)\nHow do we characterize behaviour around \\(x\\) such that \\(f(x)=x\\)?\n\n\n\nStability criterium:\n\nif \\(|f^{\\prime}(x)|&gt;1\\): sequence is unstable and will not converge to \\(x\\) except by chance\nif \\(|f^{\\prime}(x)|&lt;1\\): \\(x\\) is a stable fixed point\nif \\(|f^{\\prime}(x)|=1\\): ??? (look at higher order terms, details ↓)",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#section",
    "href": "slides/session_2/index.html#section",
    "title": "Convergence of Sequences",
    "section": "",
    "text": "To get the intution about local convergence assume, you have an initial point \\(x_n\\) close to the steady state and consider the following expresion:\n\\(x_{n+1} - x = f(x_n) - f(x) = f^{\\prime}(x) (x_n-x) + o( (x_n-x) )\\)\nIf one sets aside the error term (which one can do with full mathematical rigour), the dynamics for very small perturbations are given by:\n\\(|x_{n+1} - x| = |f^{\\prime}(x)| |x_n-x|\\)\nWhen \\(|f^{\\prime}(x)|&lt;1\\), the distance to the target decreases at each iteration and we have convergence. When \\(|f^{\\prime}(x)|&gt;1\\) there is local divergence.",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#section-1",
    "href": "slides/session_2/index.html#section-1",
    "title": "Convergence of Sequences",
    "section": "",
    "text": "What about the case \\(|f^{\\prime}(x)=1|\\)? Many cases are possible. To distinguish between them, one needs to inspect higher order derivatives.\n\nwhen \\(|f^{\\prime}(x)=1|\\), \\(|f^{\\prime\\prime}(x)|\\neq 0\\) the series will convergence, only if \\((x_0-x)f^{\\prime\\prime}(x)&lt;0\\), i.e. starting from one side of the fixed point. The steady-state is not stable.\nWhen \\(|f^{\\prime}(x)=1|\\), \\(|f^{\\prime\\prime}(x)| = 0\\), \\(|f^{\\prime \\prime\\prime}(x)|\\neq 0\\) the series will converge, only if \\(f^{\\prime}(x)(f^{\\prime\\prime\\prime}(x))&lt;1\\)\n\nIn general, there is stability only if the function \\(f\\) is crossing the 45 degrees line (when \\(f^ {\\prime}(x)=1)\\), or the -45 degrees line (when \\(f^ {\\prime}(x)=1\\))\nMathematically, this involves, that:\n\nthe first non-zero coefficient \\(f^{k}(x)\\) with \\(k&gt;1\\) has odd order (\\(k\\) odd)\nit has the right sign",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#change-the-problem",
    "href": "slides/session_2/index.html#change-the-problem",
    "title": "Convergence of Sequences",
    "section": "Change the problem",
    "text": "Change the problem\n\nSometimes, we are interested in tweaking the convergence speed: \\[x_{n+1} = (1-\\lambda) x_n + \\lambda f(x_n)\\]\n\n\\(\\lambda\\) is the learning rate:\n\n\\(\\lambda&gt;1\\): acceleration\n\\(\\lambda&lt;1\\): dampening\n\n\n\n\n\n\nWe can also replace the function by another one \\(g\\) such that \\(g(x)=x\\iff f(x)=x\\), for instance: \\[g(x)=x-\\frac{f(x)-x}{f^{\\prime}(x)-1}\\]\n\nthis is the Newton iteration",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#dynamics-around-a-stable-point",
    "href": "slides/session_2/index.html#dynamics-around-a-stable-point",
    "title": "Convergence of Sequences",
    "section": "Dynamics around a stable point",
    "text": "Dynamics around a stable point\n\n\nWe can write successive approximation errors: \\[|x_t - x_{t-1}| =  | f(x_{t-1}) - f(x_{t-2})| \\] \\[|x_t - x_{t-1}| \\sim |f^{\\prime}(x_{t-1})| |x_{t-1} - x_{t-2}| \\]\nRatio of successive approximation errors \\[\\lambda_t =  \\frac{ |x_{t} - x_{t-1}| } { |x_{t-1} - x_{t-2}|}\\]\nWhen the sequence converges: \\[\\lambda_t \\rightarrow | f^{\\prime}(\\overline{x}) |\\]",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#dynamics-around-a-stable-point-2",
    "href": "slides/session_2/index.html#dynamics-around-a-stable-point-2",
    "title": "Convergence of Sequences",
    "section": "Dynamics around a stable point (2)",
    "text": "Dynamics around a stable point (2)\nHow do we derive an error bound? Suppose that we have \\(\\overline{\\lambda}&gt;|f^{\\prime}(x_k)|\\) for all \\(k\\geq k_0\\):\n\\[|x_t - x| \\leq |x_t - x_{t+1}| + |x_{t+1} - x_{t+2}| + |x_{t+2} - x_{t+3}| + ... \\]\n\\[|x_t - x| \\leq |x_t - x_{t+1}| + |f(x_{t}) - f(x_{t+1})| + |f(x_{t+1}) - f(x_{t+2})| + ... \\]\n\\[|x_t - x| \\leq |x_t - x_{t+1}| + \\overline{\\lambda} |x_t - x_{t+1}| + \\overline{\\lambda}^2 |x_t - x_{t+1}| + ... \\]\n\\[|x_t - x| \\leq \\frac{1} {1-\\overline{\\lambda}} | x_t - x_{t+1} |\\]",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#how-do-we-improve-convergence",
    "href": "slides/session_2/index.html#how-do-we-improve-convergence",
    "title": "Convergence of Sequences",
    "section": "How do we improve convergence ?",
    "text": "How do we improve convergence ?\n\\[\\frac{|x_{t-1} - x_{t-2}|} {|x_t - x_{t-1}|} \\sim |f^{\\prime}(x_{t-1})|  \\]\ncorresponds to the case of linear convergence (kind of slow).",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#aitkens-extrapolation",
    "href": "slides/session_2/index.html#aitkens-extrapolation",
    "title": "Convergence of Sequences",
    "section": "Aitken’s extrapolation",
    "text": "Aitken’s extrapolation\nWhen convergence is geometric, we have: \\[ \\lim_{x\\rightarrow \\infty}\\frac{ x_{t+1}-x}{x_t-x} = \\lambda \\in \\mathbb{R}^{\\star}\\]\nWhich implies:\n\\[\\frac{ x_{t+1}-x}{x_t-x} \\sim \\frac{ x_{t}-x}{x_{t-1}-x}\\]",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#aitkens-extrapolation-2",
    "href": "slides/session_2/index.html#aitkens-extrapolation-2",
    "title": "Convergence of Sequences",
    "section": "Aitken’s extrapolation (2)",
    "text": "Aitken’s extrapolation (2)\nTake \\(x_{t-1}, x_t\\) and \\(x_{t+1}\\) as given and solve for \\(x\\):\n\\[x = \\frac{x_{t+1}x_{t-1} - x_{t}^2}{x_{t+1}-2x_{t} + x_{t-1}}\\]\nor after some reordering\n\\[x = x_{t-1} - \\frac{(x_t-x_{t-1})^2}{x_{t+1}-2 x_t + x_{t-1}}\\]",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#steffensens-method",
    "href": "slides/session_2/index.html#steffensens-method",
    "title": "Convergence of Sequences",
    "section": "Steffensen’s Method:",
    "text": "Steffensen’s Method:\n\nstart with a guess \\(x_0\\), compute \\(x_1=f(x_0)\\) and \\(x_2=f(x_1)\\)\nuse Aitken’s guess for \\(x^{\\star}\\). If required tolerance is met, stop.\notherwise, set \\(x_0 = x^{\\star}\\) and go back to step 1.\n\nIt can be shown that the sequence generated from Steffensen’s method converges quadratically, that is\n\\(\\lim_{t\\rightarrow\\infty} \\frac{x_{t+1}-x_t}{(x_t-x_{t-1})^2} \\leq M  \\in \\mathbb{R}^{\\star}\\)",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#convergence-speed",
    "href": "slides/session_2/index.html#convergence-speed",
    "title": "Convergence of Sequences",
    "section": "Convergence speed",
    "text": "Convergence speed\nRate of convergence of series \\(x_t\\) towards \\(x^{\\star}\\) is:\n\nlinear: \\[{\\lim}_{t\\rightarrow\\infty} \\frac{|x_{t+1}-x^{\\star}|}{|x_{t}-x^{\\star}|} = \\mu \\in R^+\\]\nsuperlinear: \\[{\\lim}_{t\\rightarrow\\infty} \\frac{|x_{t+1}-x^{\\star}|}{|x_{t}-x^{\\star}|} = 0\\]\nquadratic: \\[{\\lim}_{t\\rightarrow\\infty} \\frac{|x_{t+1}-x^{\\star}|}{|x_{t}-x^{\\star}|^{\\color{red}2}} = \\mu \\in R^+\\]",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#convergence-speed-1",
    "href": "slides/session_2/index.html#convergence-speed-1",
    "title": "Convergence of Sequences",
    "section": "Convergence speed",
    "text": "Convergence speed\nRemark: in the case of linear convergence:\n\\[{\\lim}_{t\\rightarrow\\infty} \\frac{|x_{t+1}-x_t|}{|x_{t}-x_{t-1}|} = \\mu \\in R^+ \\iff {\\lim}_{t\\rightarrow\\infty} \\frac{|x_{t+1}-x^{\\star}|}{|x_{t}-x^{\\star}|}=\\frac{1}{1-\\mu}\\]",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/session_2/index.html#in-practice",
    "href": "slides/session_2/index.html#in-practice",
    "title": "Convergence of Sequences",
    "section": "In practice",
    "text": "In practice\n\n\nProblem: Suppose one is trying to find \\(x\\) solving the model \\(G(x)=0\\)\n\nAn iterative algorithm provides a function \\(f\\) defining a recursive series \\(x_{t+1}\\).\n\nThe best practice consists in monitoring at the same time:\n\nthe success criterion: \\[\\epsilon_n = |G(x_n)|\\]\n\n\nhave you found the solution?\n\nthe successive approximation errors \\[\\eta_n = |x_{n+1} - x_n|\\]\n\n\nare you making progress?\n\nthe ratio of successive approximation errors \\[\\lambda_n = \\frac{\\eta_n}{\\eta_{n-1}}\\]\n\n\nwhat kind of convergence? (if \\(|\\lambda_n|&lt;1\\): OK, otherwise: ❓)",
    "crumbs": [
      "Slides",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "slides/optimization.html#introduction-1",
    "href": "slides/optimization.html#introduction-1",
    "title": "Optimization",
    "section": "Introduction",
    "text": "Introduction\nOptimization is everywhere in economics:\n\nto model agent’s behaviour: what would a rational agent do?\n\nconsumer maximizes utility from consumption\nfirm maximizes profit\n\nan economist tries to solve a model:\n\nfind prices that clear the market"
  },
  {
    "objectID": "slides/optimization.html#plan",
    "href": "slides/optimization.html#plan",
    "title": "Optimization",
    "section": "Plan",
    "text": "Plan\n\ngeneral consideration about optimization problems\none-dimensional root-finding\none-dimensional optimization\nlocal root-finding\nlocal optimization\nconstrained optimization\nconstrained root-finding"
  },
  {
    "objectID": "slides/optimization.html#optimization-tasks-come-in-many-flavours",
    "href": "slides/optimization.html#optimization-tasks-come-in-many-flavours",
    "title": "Optimization",
    "section": "Optimization tasks come in many flavours",
    "text": "Optimization tasks come in many flavours\n\ncontinuous versus discrete optimization\nconstrained and unconstrained optimization\nglobal and local\nstochastic and deterministic optimization\nconvexity"
  },
  {
    "objectID": "slides/optimization.html#continuous-versus-discrete-optimization",
    "href": "slides/optimization.html#continuous-versus-discrete-optimization",
    "title": "Optimization",
    "section": "Continuous versus discrete optimization",
    "text": "Continuous versus discrete optimization\n\nChoice is picked from a given set (\\(x\\in X\\)) which can be:\n\ncontinuous: choose amount of debt \\(b_t \\in [0,\\overline{b}]\\), of capital \\(k_t \\in R^{+}\\)\ndiscrete: choose whether to repay or default \\(\\delta\\in{0,1}\\), how many machines to buy (\\(\\in N\\)), at which age to retire…\na combination of both: mixed integer programming"
  },
  {
    "objectID": "slides/optimization.html#continuous-versus-discrete-optimization-2",
    "href": "slides/optimization.html#continuous-versus-discrete-optimization-2",
    "title": "Optimization",
    "section": "Continuous versus discrete optimization (2)",
    "text": "Continuous versus discrete optimization (2)\n\nDiscrete optimization requires a lot of combinatorial thinking\n\nWe don’t cover it today.\n…if needed, we just test all choices until we find the best one\n\nSometimes a discrete choice can be approximated by a mixed strategy (i.e. a random strategy).\n\nInstead of \\(\\delta\\in{0,1}\\) we choose \\(x\\) in \\(prob(\\delta=1)=\\sigma(x)\\)\nwith \\(\\sigma(x)=\\frac{2}{1+\\exp(-x)}\\)"
  },
  {
    "objectID": "slides/optimization.html#constrained-and-unconstrained-optimization",
    "href": "slides/optimization.html#constrained-and-unconstrained-optimization",
    "title": "Optimization",
    "section": "Constrained and Unconstrained optimization",
    "text": "Constrained and Unconstrained optimization\n\nUnconstrained optimization: \\(x\\in R\\)\nConstrained optimization: \\(x\\in X\\)\n\nbudget set: \\(p_1 c_1 + p_2 c_2 \\leq I\\)\npositivity of consumption: \\(c \\geq 0\\).\n\nIn good cases, the optimization set is convex…\n\npretty much always in this course"
  },
  {
    "objectID": "slides/optimization.html#stochastic-vs-determinstic",
    "href": "slides/optimization.html#stochastic-vs-determinstic",
    "title": "Optimization",
    "section": "Stochastic vs Determinstic",
    "text": "Stochastic vs Determinstic\n\nCommon case, especially in machine learning \\[f(x) = E_{\\epsilon}[ \\xi (\\epsilon, x)]\\]\nOne wants to maximize (resp solve) w.r.t. \\(x\\) but it is costly to compute expectation precisely using Monte-Carlo draws (there are other methods).\nA stochastic optimization method allows to use noisy estimates of the expectation, and will still converge in expectation.\nFor now we focus on deterministic methods. Maybe later…"
  },
  {
    "objectID": "slides/optimization.html#local-vs-global-algorithms",
    "href": "slides/optimization.html#local-vs-global-algorithms",
    "title": "Optimization",
    "section": "Local vs global Algorithms",
    "text": "Local vs global Algorithms\n\nIn principle, there can be many roots (resp maxima) within the optimization set.\nAlgorithms that find them all are called “global”. For instance:\n\ngrid search\nsimulated annealing\n\nWe will deal only with local algorithms, and consider local convergence properties.\n\n-&gt;then it might work or not\nto perform global optimization just restart from different points."
  },
  {
    "objectID": "slides/optimization.html#math-vs-practice",
    "href": "slides/optimization.html#math-vs-practice",
    "title": "Optimization",
    "section": "Math vs practice",
    "text": "Math vs practice\n\nThe full mathematical treatment will typically assume that \\(f\\) is smooth (\\(\\mathcal{C}_1\\) or \\(\\mathcal{C}_2\\) depending on the algorithm).\nIn practice we often don’t know about these properties\n\nwe still try and check thqt we have a local optimal\n\nSo: fingers crossed"
  },
  {
    "objectID": "slides/optimization.html#math-vs-practice-1",
    "href": "slides/optimization.html#math-vs-practice-1",
    "title": "Optimization",
    "section": "Math vs practice",
    "text": "Math vs practice\nHere is the surface representing the objective that a deep neural network training algorithm tries to minimize.\n\nAnd yet, neural networks do great things!"
  },
  {
    "objectID": "slides/optimization.html#what-do-you-need-to-know",
    "href": "slides/optimization.html#what-do-you-need-to-know",
    "title": "Optimization",
    "section": "What do you need to know?",
    "text": "What do you need to know?\n\nbe able to handcode simple algos (Newton, Gradient Descent)\nunderstand the general principle of the various algorithms to compare them in terms of\n\nrobustness\nefficiency\naccuracy\n\nthen you can just switch the various options, when you use a library…"
  },
  {
    "objectID": "slides/optimization.html#bisection",
    "href": "slides/optimization.html#bisection",
    "title": "Optimization",
    "section": "Bisection",
    "text": "Bisection\n\nFind \\(x \\in [a,b]\\) such that \\(f(x) = 0\\). Assume \\(f(a)f(b) &lt;0\\).\nAlgorithm\n\nStart with \\(a_n, b_n\\). Set \\(c_n=(a_n+b_n)/2\\)\nCompute \\(f(c_n)\\)\n\n\nif \\(f(c_n)f(a_n)&lt;0\\) then set \\((a_{n+1},b_{n+1})=(a_n,c_n)\\)\nelse set \\((a_{n+1},b_{n+1})=(c_n,b_n)\\)\n\n\nIf \\(|f(c_n)|&lt;\\epsilon\\) and/or \\(\\frac{b-a}{2^n}&lt;\\delta\\) stop. Otherwise go back to 1."
  },
  {
    "objectID": "slides/optimization.html#bisection-2",
    "href": "slides/optimization.html#bisection-2",
    "title": "Optimization",
    "section": "Bisection (2)",
    "text": "Bisection (2)\n\nNo need for initial guess: globally convergent algorithm\n\nnot a global algorithm…\n… in the sense that it doesn’t find all solutions\n\n\\(\\delta\\) is a guaranteed accuracy on \\(x\\)\n\\(\\epsilon\\) is a measure of how good the solution is\nthink about your tradeoff: (\\(\\delta\\) or \\(\\epsilon\\) ?)"
  },
  {
    "objectID": "slides/optimization.html#newton-algorithm",
    "href": "slides/optimization.html#newton-algorithm",
    "title": "Optimization",
    "section": "Newton algorithm",
    "text": "Newton algorithm\n\nFind \\(x\\) such that \\(f(x) = 0\\). Use \\(x_0\\) as initial guess.\n\\(f\\) must be \\(\\mathcal{C_1}\\) and we assume we can compute its derivative \\(f^{\\prime}\\)\nGeneral idea:\n\nobserve that the zero \\(x^{\\star}\\) must satisfy \\[f(x^{\\star})=0=f(x_0)+f^{\\prime}(x_0)(x^{\\star}-x_0) + o(x-x_0)\\]\nHence a good approximation should be \\[x^{\\star}\\approx = x_0- f(x_0)/f^{\\prime}(x_0)\\]\nCheck it is good. otherwise, replace \\(x_0\\) by \\(x^{\\star}\\)"
  },
  {
    "objectID": "slides/optimization.html#newton-algorithm-2",
    "href": "slides/optimization.html#newton-algorithm-2",
    "title": "Optimization",
    "section": "Newton algorithm (2)",
    "text": "Newton algorithm (2)\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n- \\frac{f(x_n)}{f^{\\prime}(x_n)}=f^{\\text{newton}}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic"
  },
  {
    "objectID": "slides/optimization.html#quasi-newton",
    "href": "slides/optimization.html#quasi-newton",
    "title": "Optimization",
    "section": "Quasi-Newton",
    "text": "Quasi-Newton\n\nWhat if we can’t compute \\(f^{\\prime}\\) or it is expensive to do so?\n\nIdea: try to approximate \\(f^{\\prime}(x_n)\\) from the last iterates\n\nSecant method: \\[f^{\\prime}(x_n)\\approx \\frac{f(x_n)-f(x_{n-1})}{x_n-x_{n-1}}\\] \\[x_{n+1} = x_n- f(x_n)\\frac{x_n-x_{n-1}}{f(x_n)-f(x_{n-1})}\\]\n\nrequires two initial guesses: \\(x_1\\) and \\(x_0\\)\nsuperlinear convergence: \\(\\lim \\frac{x_t-x^{\\star}}{x_{t-1}-x^{\\star}}\\rightarrow 0\\)"
  },
  {
    "objectID": "slides/optimization.html#limits-of-newtons-method",
    "href": "slides/optimization.html#limits-of-newtons-method",
    "title": "Optimization",
    "section": "Limits of Newton’s method",
    "text": "Limits of Newton’s method\n\nHow could Newton method fail?\n\nbad guess\n\n-&gt; start with a better guess\n\novershoot\n\n-&gt; dampen the update (problem: much slower)\n-&gt; backtrack\n\nstationary point\n\n-&gt; if root of multiplicity \\(m\\) try \\(x_{n+1} = x_n- m \\frac{f(x_n)}{f^{\\prime}(x_n)}\\)"
  },
  {
    "objectID": "slides/optimization.html#backtracking",
    "href": "slides/optimization.html#backtracking",
    "title": "Optimization",
    "section": "Backtracking",
    "text": "Backtracking\n\nSimple idea:\n\nat stage \\(n\\) given \\(f(x_n)\\) compute Newton step \\(\\Delta_n=-\\frac{f(x_n)}{f^{\\prime}(x_n)}\\)\nfind the smallest \\(k\\) such that \\(|f(x_n-\\Delta/2^k)|&lt;|f(x_n)|\\)\nset \\(x_{n+1}=x_n-\\Delta/2^k\\)"
  },
  {
    "objectID": "slides/optimization.html#golden-section-search",
    "href": "slides/optimization.html#golden-section-search",
    "title": "Optimization",
    "section": "Golden section search",
    "text": "Golden section search\n\nMinimize \\(f(x)\\) for \\(x \\in [a,b]\\)\nChoose \\(\\Phi \\in [0,0.5]\\)\nAlgorithm:\n\nstart with \\(a_n &lt; b_n\\) (initially equal to \\(a\\) and \\(b\\))\ndefine \\(c_n = a_n+\\Phi(b_n-a_n)\\) and \\(d_n = a_n+(1-\\Phi)(b_n-a_n)\\)\n\nif \\(f(c_n)&lt;f(d_n)\\) set \\(a_{n+1},b_{n+1}=a_n, d_n\\)\nelse set \\(a_{n+1}, b_{n+1}= c_n, b_n\\)"
  },
  {
    "objectID": "slides/optimization.html#golden-section-search-2",
    "href": "slides/optimization.html#golden-section-search-2",
    "title": "Optimization",
    "section": "Golden section search (2)",
    "text": "Golden section search (2)\n\nThis is guaranteed to converge to a local minimum\nIn each step, the size of the interval is reduced by a factor \\(\\Phi\\)\nBy choosing \\(\\Phi=\\frac{\\sqrt{5}-1}{2}\\) one can save one evaluation by iteration.\n\nyou can check that either \\(c_{n+1} = d_n\\) or \\(d_{n+1} = c_n\\)\n\nRemark that bisection is not enough"
  },
  {
    "objectID": "slides/optimization.html#newton-raphson-algorithm-2",
    "href": "slides/optimization.html#newton-raphson-algorithm-2",
    "title": "Optimization",
    "section": "Newton-Raphson Algorithm (2)",
    "text": "Newton-Raphson Algorithm (2)\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n-\\frac{f^{\\prime}(x_0)}{f^{\\prime\\prime}(x_0)}\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f^{\\prime}(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic"
  },
  {
    "objectID": "slides/optimization.html#unconstrained-problems",
    "href": "slides/optimization.html#unconstrained-problems",
    "title": "Optimization",
    "section": "Unconstrained problems",
    "text": "Unconstrained problems\n\nMinimize \\(f(x)\\) for \\(x \\in R^n\\) given initial guess \\(x_0 \\in R^n\\)\nMany intuitions from the 1d case, still apply\n\nreplace derivatives by gradient, jacobian and hessian\nrecall that matrix multiplication is not commutative\n\nSome specific problems:\n\nupdate speed can be specific to each dimension\nsaddle-point issues (for minimization)"
  },
  {
    "objectID": "slides/optimization.html#quick-terminology",
    "href": "slides/optimization.html#quick-terminology",
    "title": "Optimization",
    "section": "Quick terminology",
    "text": "Quick terminology\nFunction \\(f: R^p \\rightarrow R^q\\)\n\nJacobian: \\(J(x)\\) or \\(f^{\\prime}\\_x(x)\\), \\(p\\times q\\) matrix such that: \\[J(x)\\_{ij} = \\frac{\\partial f(x)\\_i}{\\partial x_j}\\]\nGradient: \\(\\nabla f(x) = J(x)\\), gradient when \\(q=1\\)\nHessian: denoted by \\(H(x)\\) or \\(f^{\\prime\\prime}\\_{xx}(x)\\) when \\(q=1\\): \\[H(x)\\_{jk} = \\frac{\\partial f(x)}{\\partial x_j\\partial x_k}\\]\nIn the following explanations, \\(|x|\\) denotes the supremum norm, but most of the following explanations also work with other norms."
  },
  {
    "objectID": "slides/optimization.html#multidimensional-newton-raphson",
    "href": "slides/optimization.html#multidimensional-newton-raphson",
    "title": "Optimization",
    "section": "Multidimensional Newton-Raphson",
    "text": "Multidimensional Newton-Raphson\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n- J(x_{n})^{-1}f(x_n)=f^{\\text{newton}}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic"
  },
  {
    "objectID": "slides/optimization.html#multidimensional-newton-root-finding-2",
    "href": "slides/optimization.html#multidimensional-newton-root-finding-2",
    "title": "Optimization",
    "section": "Multidimensional Newton root-finding (2)",
    "text": "Multidimensional Newton root-finding (2)\n\nwhat matters is the computation of the step \\(\\Delta_n = {\\color{\\red}{J(x_{n})^{-1}}} f(x_n)\\)\ndon’t compute \\(J(x_n)^{-1}\\)\n\nit takes less operations to compute \\(X\\) in \\(AX=Y\\) than \\(A^{-1}\\) then \\(A^{-1}Y\\)\nin Julia: X = A \\ Y\n\nstrategies to improve convergence:\n\ndampening: \\(x_n = (1-\\lambda)x_{n-1} - \\lambda \\Delta_n\\)\nbacktracking: choose \\(k\\) such that \\(|f(x_n-2^{-k}\\Delta_n)|\\)&lt;\\(|f(x_{n-1})|\\)\nlinesearch: choose \\(\\lambda\\in[0,1]\\) so that \\(|f(x_n-\\lambda\\Delta_n)|\\) is minimal"
  },
  {
    "objectID": "slides/optimization.html#multidimensional-gradient-descent",
    "href": "slides/optimization.html#multidimensional-gradient-descent",
    "title": "Optimization",
    "section": "Multidimensional Gradient Descent",
    "text": "Multidimensional Gradient Descent\n\nMinimize \\(f(x) \\in R\\) for \\(x \\in R^n\\) given \\(x_0 \\in R^n\\)\nAlgorithm\n\nstart with \\(x_n\\) \\[x_{n+1} = (1-\\lambda) x_n - \\lambda \\nabla f(x_n)\\]\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nComments:\n\nlots of variants\nautomatic differentiation software makes gradient easy to compute\nconvergence is typically linear"
  },
  {
    "objectID": "slides/optimization.html#gradient-descent-variants",
    "href": "slides/optimization.html#gradient-descent-variants",
    "title": "Optimization",
    "section": "Gradient descent variants",
    "text": "Gradient descent variants"
  },
  {
    "objectID": "slides/optimization.html#multidimensional-newton-minimization",
    "href": "slides/optimization.html#multidimensional-newton-minimization",
    "title": "Optimization",
    "section": "Multidimensional Newton Minimization",
    "text": "Multidimensional Newton Minimization\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n-{\\color{\\red}{H(x_{n})^{-1}}}\\color{\\green}{ J(x_n)'}\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic\nProblem:\n\n\\(H(x_{n})\\) hard to compute efficiently\nrather unstable"
  },
  {
    "objectID": "slides/optimization.html#quasi-newton-method-for-multidimensional-minimization",
    "href": "slides/optimization.html#quasi-newton-method-for-multidimensional-minimization",
    "title": "Optimization",
    "section": "Quasi-Newton method for multidimensional minimization",
    "text": "Quasi-Newton method for multidimensional minimization\n\nRecall the secant method:\n\n\\(f(x_{n-1})\\) and \\(f(x_{n-2})\\) are used to approximate \\(f^{\\prime}(x_{n-2})\\).\nIntuitively, \\(n\\) iterates would be needed to approximate a hessian of size \\(n\\)….\n\nBroyden method: takes \\(2 n\\) steps to solve a linear problem of size \\(n\\)\n\nuses past information incrementally"
  },
  {
    "objectID": "slides/optimization.html#quasi-newton-method-for-multidimensional-minimization-1",
    "href": "slides/optimization.html#quasi-newton-method-for-multidimensional-minimization-1",
    "title": "Optimization",
    "section": "Quasi-Newton method for multidimensional minimization",
    "text": "Quasi-Newton method for multidimensional minimization\n\nConsider the approximation: \\[f(x_n)-f(x_{n-1}) \\approx J(x_n) (x_n - x_{n-1})\\]\n\n\\(J(x_n)\\) is unknown and cannot be determined directly as in the secant method.\nidea: \\(J(x_n)\\) as close as possible to \\(J(x_{n-1})\\) while solving the secant equation\nformula: \\[J_n = J_{n-1} + \\frac{(f(x_n)-f(x_{n-1})) - J_{n-1}(x_n-x_{n-1})}{||x_n-x_{n-1}||^2}(x_n-x_{n-1})^{\\prime}\\]"
  },
  {
    "objectID": "slides/optimization.html#gauss-newton-minimization",
    "href": "slides/optimization.html#gauss-newton-minimization",
    "title": "Optimization",
    "section": "Gauss-Newton Minimization",
    "text": "Gauss-Newton Minimization\n\nRestrict to least-square minimization: $min_x _i f(x)_i^2 R $\nThen up to first order, \\(H(x_n)\\approx J(x_n)^{\\prime}J(x_n)\\)\nUse the step: \\(({J(x_n)^{\\prime}J(x_n)})^{-1}\\color{\\green}{ J(x_n)}\\)\nConvergence:\n\ncan be quadratic at best\nlinear in general"
  },
  {
    "objectID": "slides/optimization.html#levenberg-marquardt",
    "href": "slides/optimization.html#levenberg-marquardt",
    "title": "Optimization",
    "section": "Levenberg-Marquardt",
    "text": "Levenberg-Marquardt\n\nLeast-square minimization: $min_x _i f(x)_i^2 R $\nreplace \\({J(x_n)^{\\prime}J(x_n)}^{-1}\\) by \\({J(x_n)^{\\prime}J(x_n)}^{-1} +\\mu I\\)\n\nadjust \\(\\lambda\\) depending on progress\n\nuses only gradient information like Gauss-Newton\nequivalent to Gauss-Newton close to the solution (\\(\\mu\\) small)\nequivalent to Gradient far from solution (\\(\\mu\\) high)"
  },
  {
    "objectID": "slides/optimization.html#consumption-optimization",
    "href": "slides/optimization.html#consumption-optimization",
    "title": "Optimization",
    "section": "Consumption optimization",
    "text": "Consumption optimization\nConsider the optimization problem: \\[\\max U(x_1, x_2)\\]\nunder the constraint \\(p_1 x_1 + p_2 x_2 \\leq B\\)\nwhere \\(U(.)\\), \\(p_1\\), \\(p_2\\) and \\(B\\) are given.\nHow do you find a solution by hand?"
  },
  {
    "objectID": "slides/optimization.html#consumption-optimization-1",
    "href": "slides/optimization.html#consumption-optimization-1",
    "title": "Optimization",
    "section": "Consumption optimization (1)",
    "text": "Consumption optimization (1)\n\nCompute by hand\nEasy:\n\nsince the budget constraint must be binding, get rid of it by stating \\(x_2 = B - p_1 x_1\\)\nthen maximize in \\(x_1\\), \\(U(x_1, B - p_1 x_1)\\) using the first order conditions.\n\nIt works but:\n\nbreaks symmetry between the two goods\nwhat if there are other constraints: \\(x_1\\geq \\underline{x}\\)?\nwhat if constraints are not binding?\nis there a better way to solve this problem?"
  },
  {
    "objectID": "slides/optimization.html#consumption-optimization-2",
    "href": "slides/optimization.html#consumption-optimization-2",
    "title": "Optimization",
    "section": "Consumption optimization (2)",
    "text": "Consumption optimization (2)\n\nAnother method, which keeps the symmetry. Constraint is binding, trying to minimize along the budget line yields an implicit relation between \\(d x_1\\) and \\(d x_2\\) \\[p_1 d {x_1} + p_2 d {x_2} = 0\\]\nAt the optimal: \\(U^{\\prime}\\_{x_1}(x_1, x_2)d {x_1} + U^{\\prime}\\_{x_2}(x_1, x_2)d {x_2} = 0\\)\nEliminate \\(d {x_1}\\) and \\(d {x_2}\\) to get one condition which characterizes optimal choices for all possible budgets. Combine with the budget constraint to get a second condition."
  },
  {
    "objectID": "slides/optimization.html#penalty-function",
    "href": "slides/optimization.html#penalty-function",
    "title": "Optimization",
    "section": "Penalty function",
    "text": "Penalty function\n\nTake a penalty function \\(p(x)\\) such that \\(p(x)=K&gt;0\\) if \\(x&gt;0\\) and \\(p(x)=0\\) if \\(x \\leq 0\\). Maximize: \\(V(x_1, x_2) = U(x_1, x_2) - p( p_1 x_1 + p_2 x_2 - B)\\)\nClearly, \\(\\min U \\iff \\min V\\)\nProblem: \\(\\nabla V\\) is always equal to \\(\\nabla U\\).\nSolution: use a smooth solution function like \\(p(x) = x^2\\)\nProblem: distorts optimization\n\nSolution: adjust weight of barrier and minimize \\(U(x_1, x_2) - \\kappa p(x)\\)\n\nPossible but hard to choose the weights/constraints."
  },
  {
    "objectID": "slides/optimization.html#penalty-function-1",
    "href": "slides/optimization.html#penalty-function-1",
    "title": "Optimization",
    "section": "Penalty function",
    "text": "Penalty function\n\nAnother idea: is there a canonical way to choose \\(\\lambda\\) such that at the minimum it is equivalent to minimize the original problem under constraint or to minimize \\[V(x_1, x_2) = U(x_1, x_2) - \\lambda (p_1 x_1 + p_2 x_2 - B)\\]\nClearly, when the constraint is not binding we must have \\(\\lambda=0\\). What should be the value of \\(\\lambda\\) when the constraint is binding ?"
  },
  {
    "objectID": "slides/optimization.html#karush-kuhn-tucker-conditions",
    "href": "slides/optimization.html#karush-kuhn-tucker-conditions",
    "title": "Optimization",
    "section": "Karush-Kuhn-Tucker conditions",
    "text": "Karush-Kuhn-Tucker conditions\n\nIf \\((x^{\\star},y^{\\star})\\) is optimal there exists \\(\\lambda\\) such that:\n\n\\((x^{\\star},y^{\\star})\\) maximizes lagrangian \\(\\mathcal{L} = U(x_1, x_2) + \\lambda (B- p_1 x_1 - p_2 x_2)\\)\n\\(\\lambda \\geq 0\\)\n\\(B- p_1 x_1 - p_2 x_2 \\geq 0\\)\n\\(\\lambda  (B - p_1 x_1 - p_2 x_2 ) = 0\\)\n\nThe three latest conditions are called “complementarity” or “slackness” conditions\n\nthey are equivalent to \\(\\min(\\lambda, B - p_1 x_1 - p_2 x_2)=0\\)\nwe denote \\(\\lambda \\geq 0 \\perp B- p_1 x_1 + p_2 x_2  \\geq 0\\)\n\n\\(\\lambda\\) can be interpreted as the welfare gain of relaxing the constraint."
  },
  {
    "objectID": "slides/optimization.html#karush-kuhn-tucker-conditions-1",
    "href": "slides/optimization.html#karush-kuhn-tucker-conditions-1",
    "title": "Optimization",
    "section": "Karush-Kuhn-Tucker conditions",
    "text": "Karush-Kuhn-Tucker conditions\n\nWe can get first order conditions that factor in the constraints:\n\n\\(U^{\\prime}_x - \\lambda p_1 = 0\\)\n\\(U^{\\prime}_y - \\lambda p_2 = 0\\)\n\\(\\lambda \\geq 0 \\perp B-p_1 x_1 -p_2 x_2 \\geq 0\\)\n\nIt is now a nonlinear system of equations with complementarities (NCP)\n\nthere are specific solution methods to deal with it"
  },
  {
    "objectID": "slides/optimization.html#solution-strategies-for-ncp-problems",
    "href": "slides/optimization.html#solution-strategies-for-ncp-problems",
    "title": "Optimization",
    "section": "Solution strategies for NCP problems",
    "text": "Solution strategies for NCP problems\n\nGeneral formulation for vector-valued functions \\[f(x)\\geq 0 \\perp g(x)\\geq 0\\] means \\[\\forall i, f_i(x)\\geq 0 \\perp g_i(x)\\geq 0\\]\n\nNCP do not necessarily arise from a single optimization problem\n\nThere are robust (commercial) solvers for NCP problems (PATH, Knitro) for that\nHow do we solve it numerically?\n\nassume constraint is binding then non-binding then check which one is good\n\nOK if not too many constraints\n\nreformulate it as a smooth problem\napproximate the system by a series of linear complementarities problems (LCP)"
  },
  {
    "objectID": "slides/optimization.html#optimization-libraries",
    "href": "slides/optimization.html#optimization-libraries",
    "title": "Optimization",
    "section": "Optimization libraries",
    "text": "Optimization libraries\n\nRobust optimization code is contained in the following libraries:\n\nRoots.jl: one-dimensional root finding\nNLSolve.jl: multidimensional root finding (+complementarities)\nOptim.jl: minimization\n\nThe two latter libraries have a somewhat peculiar API, but it’s worth absorbing it.\n\nin particular they provide non-allocating algorithms for functions that modify arguments in place\nthey are compatible with automatic differentiation\n\n\njulia&gt; f(x) = [x[1] - x[2] - 1, x[1] + x[2]]\nf (generic function with 1 method)\n\njulia&gt; NLsolve.nlsolve(f, [0., 0.0])\nResults of Nonlinear Solver Algorithm\n * Algorithm: Trust-region with dogleg and autoscaling\n * Starting Point: [0.0, 0.0]\n * Zero: [0.5000000000009869, -0.5000000000009869]\n * Inf-norm of residuals: 0.000000       \n * Iterations: 1                       \n * Convergence: true\n   * |x - x'| &lt; 0.0e+00: false\n   * |f(x)| &lt; 1.0e-08: true                           \n * Function Calls (f): 2\n * Jacobian Calls (df/dx): 2"
  },
  {
    "objectID": "slides/session_ddp/index.html#introduction",
    "href": "slides/session_ddp/index.html#introduction",
    "title": "Discrete Dynamic Programming",
    "section": "Introduction",
    "text": "Introduction",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#section",
    "href": "slides/session_ddp/index.html#section",
    "title": "Discrete Dynamic Programming",
    "section": "",
    "text": "The imperialism of Dynamic Programming\n— Recursive Macroeconomic Theory (Ljunqvist & Sargent)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#section-1",
    "href": "slides/session_ddp/index.html#section-1",
    "title": "Discrete Dynamic Programming",
    "section": "",
    "text": "I spent the Fall quarter (of 1950) at RAND. My first task was to find a name for multistage decision processes. An interesting question is, “Where did the name, dynamic programming, come from?” The 1950s were not good years for mathematical research. We had a very interesting gentleman in Washington named Wilson. He was Secretary of Defense, and he actually had a pathological fear and hatred of the word “research”. I’m not using the term lightly; I’m using it precisely. His face would suffuse, he would turn red, and he would get violent if people used the term research in his presence. You can imagine how he felt, then, about the term mathematical. The RAND Corporation was employed by the Air Force, and the Air Force had Wilson as its boss, essentially. Hence, I felt I had to do something to shield Wilson and the Air Force from the fact that I was really doing mathematics inside the RAND Corporation. What title, what name, could I choose? In the first place I was interested in planning, in decision making, in thinking. But planning, is not a good word for various reasons. I decided therefore to use the word “programming”. I wanted to get across the idea that this was dynamic, this was multistage, this was time-varying. I thought, let’s kill two birds with one stone. Let’s take a word that has an absolutely precise meaning, namely dynamic, in the classical physical sense. It also has a very interesting property as an adjective, and that is it’s impossible to use the word dynamic in a pejorative sense. Try thinking of some combination that will possibly give it a pejorative meaning. It’s impossible. Thus, I thought dynamic programming was a good name. It was something not even a Congressman could object to. So I used it as an umbrella for my activities.\n\n— Richard Bellman, Eye of the Hurricane: An Autobiography (1984, page 159)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#markov-chain-and-markov-process-1",
    "href": "slides/session_ddp/index.html#markov-chain-and-markov-process-1",
    "title": "Discrete Dynamic Programming",
    "section": "Markov chain and Markov process",
    "text": "Markov chain and Markov process\n\nStochastic process: family of random variables indexed by time\nA stochastic process has the Markov property if its future evolution depends only on its current state.\nSpecial cases:\n\n\n\n\n\n\n\n\n\n\nDiscrete States\nContinuous States\n\n\n\n\nDiscrete Time\nDiscrete Markov Chain\nContinuous Markov Chain\n\n\nContinuous Time\nMarkov Jump Process\nMarkov Process",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#stochastic-matrices",
    "href": "slides/session_ddp/index.html#stochastic-matrices",
    "title": "Discrete Dynamic Programming",
    "section": "Stochastic matrices",
    "text": "Stochastic matrices\n\na matrix \\(M \\in R^n\\times R^n\\) matrix is said to be stochastic if\n\nall coefficents are non-negative\nall the lines lines sum to 1 (\\(\\forall i, \\sum_j M_{ij} = 1\\))\n\na probability density is a vector \\(\\mu \\in R^n\\) such that :\n\nall components are non-negative\nall coefficients sum to 1 (\\(\\sum_{i=1}^n \\mu_{i} = 1\\))\n\na distribution is a vector with such that:\n\nall components are non-negative",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#simulation",
    "href": "slides/session_ddp/index.html#simulation",
    "title": "Discrete Dynamic Programming",
    "section": "Simulation",
    "text": "Simulation\n\nConsider: \\(\\mu_{i,t+1}' =\\mu_t' P\\)\nWe have \\(\\mu_{i,t+1} = \\sum_{k=1}^n  \\mu_{k,t}  P_{k, i}\\)\nAnd: \\(\\sum_i\\mu_{i,t+1} = \\sum_i \\mu_{i,t}\\)\nPostmultiplication by a stochastic matrix preserves the mass.\nInterpretation: \\(P_{ij}\\) is the fraction of the mass initially in state \\(i\\) which ends up in \\(j\\)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#example",
    "href": "slides/session_ddp/index.html#example",
    "title": "Discrete Dynamic Programming",
    "section": "Example",
    "text": "Example\n\\[\\underbrace{\n\\begin{pmatrix}\n? & ? & ?\n\\end{pmatrix}\n}_{\\mu_{t+1}'} = \\underbrace{\n\\begin{pmatrix}\n0.5 & 0.3 & 0.2\n\\end{pmatrix}\n}_{\\mu_t'} \\begin{pmatrix}\n0.4 & 0.6 & 0.0 \\\\\\\\\n0.2 & 0.5 & 0.3 \\\\\\\\\n0 & 0 & 1.0\n\\end{pmatrix}\\]\n\nGraphical Representation:",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#probabilistic-interpretation",
    "href": "slides/session_ddp/index.html#probabilistic-interpretation",
    "title": "Discrete Dynamic Programming",
    "section": "Probabilistic interpretation",
    "text": "Probabilistic interpretation\n\nDenote by \\(S=(s_1,...s_n)\\) a finite set with \\(n\\) elements (\\(|S|=n\\)).\nA Markov Chain with values in \\(S\\) and with transitions given by a stochastic matrix \\(P\\in R^n\\times R^n\\) identfies a stochastic process \\((X_t)_{t\\geq 0}\\) such that \\[P_{ij} = Prob(X_{t+1}=s_j|X_t=s_i)\\]\nIn words, line \\(i\\) describes the conditional distribution of \\(X_{t+1}\\) conditional on \\(X_t=s_i\\).",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#what-about-longer-horizons",
    "href": "slides/session_ddp/index.html#what-about-longer-horizons",
    "title": "Discrete Dynamic Programming",
    "section": "What about longer horizons?",
    "text": "What about longer horizons?\n\nIt is easy to show that for any \\(k\\), \\(P^k\\) is a stochastic matrix.\n\\(P^k_{ij}\\) denotes the probability of ending in \\(j\\), after \\(k\\) periods, starting from \\(i\\)\nGiven an initial distribution \\(\\mu_0\\in R^{+ n}\\)\n\nWhich states will visited with positive probability between t=0 and t=k?\nWhat happens in the very long run?\n\nWe need to study a little bit the properties of Markov Chains",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#connectivity",
    "href": "slides/session_ddp/index.html#connectivity",
    "title": "Discrete Dynamic Programming",
    "section": "Connectivity",
    "text": "Connectivity\n\nTwo states \\(s_i\\) and \\(s_j\\) are connected if \\(P_{ij}&gt;0\\)\nWe call incidence matrix: \\(\\mathcal{I}(P)=(\\delta_{P_{ij}&gt;0})_{ij}\\)\nTwo states \\(i\\) and \\(j\\) communicate with each other if there are \\(k\\) and \\(l\\) such that: \\((P^k)_ {i,j}&gt;0\\) and \\((P^l)_ {j,i}&gt;0\\)\n\nit is an equivalence relation\nwe can define equivalence classes\n\nA stochastic matrix \\(P\\) is irreducible if all states communicate\n\nthere is a unique communication class",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#connectivity-and-irreducibility",
    "href": "slides/session_ddp/index.html#connectivity-and-irreducibility",
    "title": "Discrete Dynamic Programming",
    "section": "Connectivity and irreducibility",
    "text": "Connectivity and irreducibility\n\n\nIrreducible\n\n\n\n\n\n\n\n\n\n\n\nIrreducible: all states can be reached with positive probability from any initial state.\n\nNot irreducible\n\n\n\n\n\n\n\n\n\n\n\n\nHere there is a subset of states (poor), which absorbs all the mass coming in.",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#aperiodicity",
    "href": "slides/session_ddp/index.html#aperiodicity",
    "title": "Discrete Dynamic Programming",
    "section": "Aperiodicity",
    "text": "Aperiodicity\n\nAre there cycles? Starting from a state \\(i\\), how long does it take to return to \\(i\\)?\nThe period of a state is defined as \\[gcd( {k\\geq 1 | (P^k)_{i,i}&gt;0} )\\]\nIf a state has a period d&gt;1 the chain returns to the state only at dates multiple of d.",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#aperiodicity-1",
    "href": "slides/session_ddp/index.html#aperiodicity-1",
    "title": "Discrete Dynamic Programming",
    "section": "Aperiodicity",
    "text": "Aperiodicity\n\n\nPeriodic\n\n\n\n\n\n\n\n\n\n\n\n\nIf you start from some states, you return to it, but not before two periods.\n\n\nAperiodic\n\n\n\n\n\n\n\n\n\n\n\n\nIf some mass leaves a state, some of it returns to the state in the next period.",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#stationary-distribution",
    "href": "slides/session_ddp/index.html#stationary-distribution",
    "title": "Discrete Dynamic Programming",
    "section": "Stationary distribution",
    "text": "Stationary distribution\n\n\\(\\mu\\) is a stationary distribution if \\(\\mu' = \\mu' P\\)\nTheorem: there always exists such a distribution\n\nproof: Brouwer theorem (fixed-point result for compact-convex set)\n\\(f: \\mu\\rightarrow (\\mu'P)'\\)\n\nTheorem:\n\nif P is irreducible the fixed point \\(\\mu^{\\star}\\) is unique\nif P is irreducible and aperiodic \\(|\\mu_0' P^k - \\mu^{\\star}| \\underset{k\\to+\\infty}{\\longrightarrow}0\\) for any initial distribution \\(\\mu_0\\)\n\nWe then say the Markov chain is ergodic\n\\(\\mu^{\\star}\\) is the ergodic distribution\n\nit is the best guess, one can do for the state of the chain in the very far future",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#stationary-distribution-proof",
    "href": "slides/session_ddp/index.html#stationary-distribution-proof",
    "title": "Discrete Dynamic Programming",
    "section": "Stationary distribution (proof)",
    "text": "Stationary distribution (proof)\n\nBrouwer’s theorem: Let \\(\\mathcal{C}\\) be a compact convex subset of \\(R^n\\) and \\(f\\) a continuous mapping \\(\\mathcal{C}\\rightarrow \\mathcal{C}\\). Then there exists a fixed point \\(x_0\\in \\mathcal{C}\\) such that \\(f(x_0)=x_0\\)\nResult hinges on:\n\ncontinuity of \\(f: \\mu \\mapsto \\mu P\\)\nconvexity of \\(\\\\{x \\in R^n | |x|=1 \\\\}\\) (easy to check)\ncompactness of \\(\\\\{x \\in R^n | |x|=1 \\\\}\\)\n\nit is bounded\nand closed (the inverse image of 1 for \\(u\\mapsto |u|\\) which is continuous)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#stationary-distribution-1",
    "href": "slides/session_ddp/index.html#stationary-distribution-1",
    "title": "Discrete Dynamic Programming",
    "section": "Stationary distribution?",
    "text": "Stationary distribution?\nHow do we compute the stationary distribution?\n\nSimulation\nLinear algebra\nDecomposition",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#simulating-a-markov-chain",
    "href": "slides/session_ddp/index.html#simulating-a-markov-chain",
    "title": "Discrete Dynamic Programming",
    "section": "Simulating a Markov Chain",
    "text": "Simulating a Markov Chain\n\nVery simple idea:\n\nstart with any \\(\\mu_0\\) and compute the iterates recursively\n\\(\\mu_{n+1}' = \\mu_n' P\\)\nconvergence is linear:\n\n\\(|\\mu_{n+1} - \\mu_n| \\leq |P| |\\mu_n - \\mu_{n-1}|\\)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#using-linear-algebra",
    "href": "slides/session_ddp/index.html#using-linear-algebra",
    "title": "Discrete Dynamic Programming",
    "section": "Using Linear Algebra",
    "text": "Using Linear Algebra\n\nFind the solution of \\(\\mu'(P-I) = 0\\) ?\n\nnot well defined, 0 is a solution\nwe need to incorporate the constraint \\(\\sum_i(\\mu_i)=1\\)\n\nMethod:\n\nDefine \\(M_{ij} =  \\begin{cases} 1  &\\text{if} & j =0 \\\\\\\\ (P-I)_{ij}  & \\text{if} & j&gt; 1  \\end{cases}\\)\nDefine \\(D_i = \\begin{cases} 1 & \\text{if} & j = 0 \\\\\\\\0 & \\text{if} & j&gt;0 \\end{cases}\\)\nWith a linear algebra solver\n\nlook for a solution \\(\\mu\\) of \\(\\mu' M = D\\)\nor \\(M^{\\prime} \\mu = D\\prime\\)\nif you find a solution, it is unique (theorem)\n\n\nAlternative:\n\nminimize residual squares of overidentified system",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#code-example",
    "href": "slides/session_ddp/index.html#code-example",
    "title": "Discrete Dynamic Programming",
    "section": "Code example",
    "text": "Code example\n# we use the identity matrix and the \\ operator\nusing LinearAlgebra: I, \\\n# define a stochastic matrix (lines sum to 1)\nP = [  0.9  0.1 0.0  ;\n       0.05 0.9 0.05 ;\n       0.0  0.9 0.1  ]\n# define an auxiliary matrix\nM = P' - I\nM[end,:] .= 1.0\n# define rhs\nR = zeros(3)\nR[end] = 1\n# solve the system\nμ = M\\R\n# check that you have a solution:\n@assert sum(μ) == 1\n@assert all(abs.(μ'P - μ').&lt;1e-10)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#further-comments",
    "href": "slides/session_ddp/index.html#further-comments",
    "title": "Discrete Dynamic Programming",
    "section": "Further comments",
    "text": "Further comments\n\nKnowledge about the structure of the Markov Chain can help speedup the calculations\nThere are methods for potentially very-large linear system\n\nNewton-Krylov based methods, GMRES\n\nBasic algorithms are easy to implement by hand\nQuantEcon toolbox has very good methods to study markov chains",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#section-2",
    "href": "slides/session_ddp/index.html#section-2",
    "title": "Discrete Dynamic Programming",
    "section": "",
    "text": "Consider the following problems:\n  \n\n\n\nMonopoly pricing:\n\\[\\max_{q} \\pi(q) - c(q)\\]\n\nShopping problem\n\\[\\max_{\\substack{c_1, c_2 \\\\ p_1 c_1 + p_2 c_2 \\leq B}} U(c_1,c_2)\\]\n\nConsumption Savings\n\\[\\max_{\\substack{c() \\\\ w_{t+1}=(w_t-c(w_t))(1+r)) + y_{t+1}}} E_0 \\sum_t \\beta^t U(c(w_t))\\]\n\n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem\nobjective\naction\nstate\ntransition\ntype\n\n\n\n\nmonopoly pricing\nprofit\nchoose quantity to produce\n\n\noptimization\n\n\nshopping problem\nutility\nchoose consumption composition\nbudget \\(B\\)\n\ncomparative statics\n\n\nconsumption/savings\nexpected welfare\nsave or consume\navailable income\nevolution of wealth\ndynamic optimization",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#general-formulation",
    "href": "slides/session_ddp/index.html#general-formulation",
    "title": "Discrete Dynamic Programming",
    "section": "General Formulation",
    "text": "General Formulation\nMarkov Decision Problem\n\n\n\n\nEnvironment\n\nstates: \\(s \\in S\\)\nactions: \\(x \\in X(s)\\)\ntransitions: \\(\\pi(s'| s, x) \\in S\\)\n\n\\(probability\\) of going to \\(s'\\) in state \\(s\\)…\n… given action \\(x\\)\n\n\n\n\n\n\nReward: \\(r(s,x) \\in R\\)\n\naka felicity, intratemporal utility\n\n\nPolicy: \\(x(): s \\rightarrow x\\in X(s)\\)\n\na.k.a. decision rule\nwe consider deterministic policy\ngiven \\(x()\\), the evolution of \\(s\\) is a Markov process\n\n\\(\\pi(. |s, x())\\) is a distribution for \\(s'\\) over \\(S\\)\nit depends only on \\(s\\)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#objective",
    "href": "slides/session_ddp/index.html#objective",
    "title": "Discrete Dynamic Programming",
    "section": "Objective",
    "text": "Objective\n\nexpected lifetime reward:\n\nvalue of following policy \\(x()\\) starting from \\(s\\): \\[R(s; x()) =  E_0 \\sum_t^T \\delta^t \\left[ r_t\\right]\\]\n\\(\\delta \\in [0,1[\\): discount factor\nhorizon: \\(T \\in \\\\{N, \\infty\\\\}\\)\n\nvalue of a state \\(s\\)\n\nvalue of following the optimal policy starting from \\(s\\) \\[V(s) = \\max_{ x()} R(s, x())\\]\n\\(V()\\) is the value function (t.b.d.)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#classes-of-dynamic-optimization",
    "href": "slides/session_ddp/index.html#classes-of-dynamic-optimization",
    "title": "Discrete Dynamic Programming",
    "section": "Classes of Dynamic Optimization",
    "text": "Classes of Dynamic Optimization\n\nThe formulation so far is very general. It encompasses several variants of the problem:\n\nfinite horizon vs infinite horizon\ndiscrete-space problem vs continuous-state space problem\nsome learning problems (reinforcement learning…)\n\nThere are also variants not included:\n\nnon time-separable problems\nnon time-homogenous problems\nsome learning problems (bayesian updating, …)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#finite-horizon-vs-infinite-horizon",
    "href": "slides/session_ddp/index.html#finite-horizon-vs-infinite-horizon",
    "title": "Discrete Dynamic Programming",
    "section": "Finite horizon vs infinite horizon",
    "text": "Finite horizon vs infinite horizon\n\nRecall objective: \\(V(s; x()) =  \\max E_0\\sum_{t=0}^T \\delta^t \\left[ r(s_t, x_t) \\right]\\)\nIf \\(T&lt;\\infty\\), the decision in the last periods, will be different from the periods before\n\none must find a decision rule \\(\\pi_t()\\) per period\nor, equivalently, add \\(t\\) to the state space: \\(\\tilde{S}=S\\times[0,T]\\)\n\nIf \\(T=\\infty\\), the continuation value of being in state \\(s_t\\) is independent from \\(t\\)\n\n\\[V(s; x()) = E_0 \\max \\sum_ {t=0}^{T_0} \\delta^t \\left[ r(s_t, x_t) \\right] + \\delta^{T_0} E_0  \\sum_ {t=T_0}^{\\infty} \\delta^t \\left[ r(s_t, x_t) \\right]\\]\n\\[ = E_0 \\left[ \\max \\sum_ {t=0}^{T_0} \\delta^t \\left[ r(s_t, x_t) \\right] +  \\delta^{T_0} V(s_ {T_0}; x()) \\right]\\]",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#continuous-vs-discrete",
    "href": "slides/session_ddp/index.html#continuous-vs-discrete",
    "title": "Discrete Dynamic Programming",
    "section": "Continuous vs discrete",
    "text": "Continuous vs discrete\n\nDiscrete Dynamic Programming (today)\n\ndiscrete states: \\(s \\in {s_1, \\cdots, s_N}\\)\ndiscrete controls: \\(|X(s)|&lt;\\infty\\)\nthere is a finite number of policies, the can be represented exactly\nunless \\(|S|\\) is very large (cf go game)\n\nContinuous problem:\n\n\\(x(s)\\), \\(V(s; \\pi)\\) require an infinite number of coefficients\nsame general approach but different implementation\ntwo main variants:\n\ndiscretize the initial problem: back to DDP\nuse approximation techniques (i.e. interpolation)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#non-time-separable-example",
    "href": "slides/session_ddp/index.html#non-time-separable-example",
    "title": "Discrete Dynamic Programming",
    "section": "Non time separable example",
    "text": "Non time separable example\n\nFor instance Epstein-Zin preferences: \\[\\max V(;c())\\] where \\[V_t = (1-\\delta) \\frac{c_t^{1-\\sigma}}{1-\\sigma} + \\delta \\left[ E_t V_{t+1}^{\\alpha} \\right]^{\\frac{1}{\\alpha}}\\]\nWhy would you do that?\n\nto disentangle risk aversion and elasticity of intertemporal substitution\nrobust control\n\nYou can still use ideas from Dynamic Programming.",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#non-homogenous-preference",
    "href": "slides/session_ddp/index.html#non-homogenous-preference",
    "title": "Discrete Dynamic Programming",
    "section": "Non homogenous preference",
    "text": "Non homogenous preference\n\nLook at the \\(\\alpha-\\beta\\) model. \\[V_t = \\max \\sum_t^{\\infty} \\beta_t U(c_t)\\] where \\(\\delta_0 = 1\\), \\(\\delta_1=\\alpha\\), \\(\\delta_k=\\alpha\\beta^{k-1}\\)\nMakes the problem time-inconsistent:\n\nthe optimal policy you would choose for the continuation value after \\(T\\) is not the same if you maximize it in expectation from \\(0\\) or at \\(T\\).",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#learning-problems",
    "href": "slides/session_ddp/index.html#learning-problems",
    "title": "Discrete Dynamic Programming",
    "section": "Learning problems",
    "text": "Learning problems\n\nBayesian learning: Uncertainty about some model parameters\n\nex: variance and return of a stock market\nagent models this uncertainty as a distribution\nagent updates his priors after observing the result of his actions\nactions are taken optimally taken into account the revelation power of some actions\n\nIs it good?\n\nclean: the rational thing to do with uncertainty\nsuper hard: the state-space should contain all possible priors\nmathematical cleanness comes with many assumptions\n\nUsed to estimate rather big (mostly linear) models",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#learning-problems-2",
    "href": "slides/session_ddp/index.html#learning-problems-2",
    "title": "Discrete Dynamic Programming",
    "section": "Learning problems (2)",
    "text": "Learning problems (2)\n\nReinforcement learning\n\nmodel can be partially or totally unknown\ndecision rule is updated by observing the reward from actions\n\nno priors\n\nsolution does not derive directly from model\n\ncan be used to solve dynamic programming problems\n\n\nGood solutions maximize a criterion similar to lifetime reward but are usually not optimal:\n\nusually evaluated by replaying the game many times\ntradeoff exploration / exploitations",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#finite-horizon-dmdp-1",
    "href": "slides/session_ddp/index.html#finite-horizon-dmdp-1",
    "title": "Discrete Dynamic Programming",
    "section": "Finite horizon DMDP",
    "text": "Finite horizon DMDP\nWhen \\(T&lt;\\infty\\). With discrete action the problem can be represented by a tree.",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#finite-horizon-dmdp-2",
    "href": "slides/session_ddp/index.html#finite-horizon-dmdp-2",
    "title": "Discrete Dynamic Programming",
    "section": "Finite horizon DMDP",
    "text": "Finite horizon DMDP\n\nIntuition: backward induction.\n\nFind optimal policy \\(x_T(s_T)\\) in all terminal states \\(s_T\\). Set \\(V_T(s_T)\\) equal to \\(r(s_T, \\pi_T)\\)\nFor each state \\(s_{k-1}\\in S\\) find \\(x_{k-1}\\in X(s_{k-1})\\) which maximizes \\[V_{k-1}(s_{k-1}) = \\max_{x_{k-1}(s_{k-1})\\in X(s_{k-1})}r(s_{k-1},x_{k-1}) + \\delta \\underbrace{ \\sum_{s_k\\in S} \\pi(s_k | s_{k-1}, x_{k-1} ) V_k(s_k)} _{ \\textit{expected continuation value} }\\]\n\nPolicies \\(x_0(), ... x_T()\\) are Markov-perfect:\n\nthey maximize utility on all subsets of the “game”\nalso from t=0",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#remarks",
    "href": "slides/session_ddp/index.html#remarks",
    "title": "Discrete Dynamic Programming",
    "section": "Remarks",
    "text": "Remarks\n\nCan we do better than this naive algorithm?\n\nnot really\nbut we can try to limit \\(S\\) to make the maximization step faster\nexclude a priori some branches in the tree using knowledge of the problem",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#infinite-horizon-dmdp-1",
    "href": "slides/session_ddp/index.html#infinite-horizon-dmdp-1",
    "title": "Discrete Dynamic Programming",
    "section": "Infinite horizon DMDP",
    "text": "Infinite horizon DMDP\n\nHorizon is infinite: \\[V(s) =  \\max E_0 \\sum_{t=0}^{\\infty} \\delta^t r(s_t, x_t) \\]\nIntuition:\n\nlet’s consider the finite horizon version \\(T&lt;\\infty\\) and \\(T &gt;&gt; 1\\)\ncompute the solution, increase \\(T\\) until the solution doesn’t change\nin practice: take an initial guess for \\(V_{T}\\) then compute optimal \\(V_{T-1}\\), \\(V_{T_2}\\) and so on, until convergence of the \\(V\\)s",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#infinite-horizon-dmdp-2",
    "href": "slides/session_ddp/index.html#infinite-horizon-dmdp-2",
    "title": "Discrete Dynamic Programming",
    "section": "Infinite horizon DMDP (2)",
    "text": "Infinite horizon DMDP (2)\n\nThis is possible, it’s called Successive Approximation or Value Function Iteration\n\nhow fast does it converge? linearly\ncan we do better? yes, quadratically\n\nwith howard improvement steps",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#successive-approximation",
    "href": "slides/session_ddp/index.html#successive-approximation",
    "title": "Discrete Dynamic Programming",
    "section": "Successive Approximation",
    "text": "Successive Approximation\n\nConsider the decomposition: \\[V(s; x()) = E_0 \\sum_{t=0}^{\\infty} \\delta^t r(s_t, x_t) = E_0 \\left[ r(s, x(s)) + \\sum_{t=1}^{\\infty} \\delta^t r(s_t, x_t) \\right]\\]\n\nor\n\\[V(s; x()) =  r(s, x(s)) + \\delta \\sum_{s'} p(s'|s,x(s)) V(s'; x()) \\]",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#successive-approximation-2",
    "href": "slides/session_ddp/index.html#successive-approximation-2",
    "title": "Discrete Dynamic Programming",
    "section": "Successive Approximation (2)",
    "text": "Successive Approximation (2)\n\nTaking continuation value as given we can certainly improve the value in every state \\(\\tilde{V}\\) by choosing \\(\\tilde{x}()\\) so as to maximize \\[\\tilde{V}(s; \\tilde{x}(), x()) =  r(s, \\tilde{x}(s)) + \\delta \\sum_{s'} \\pi(s'|s,\\tilde{x}(s) )V(s'; x()) \\]\nBy construction: \\(\\forall s, \\tilde{V}(s, \\tilde{x}(), x()) &gt; {V}(s, x())\\)\n\nit is an improvement step\n\nCan \\({V}(s, \\tilde{x}())\\) be worse for some states than \\({V}(s, x())\\) ?\n\nactually no",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#bellman-equation",
    "href": "slides/session_ddp/index.html#bellman-equation",
    "title": "Discrete Dynamic Programming",
    "section": "Bellman equation",
    "text": "Bellman equation\n\nIdea:\n\nit should not be possible to improve upon the optimal solution.\nHence the optimal value \\(V\\) and policy \\(x^{\\star}\\) should satisfy: \\[\\forall s\\in S, V(s) = \\max_{y(s)} r(s, y(s)) + \\delta \\sum_{s^{\\prime}\\in S} \\pi(s^{\\prime}| s, y(s)) V(s^{\\prime})\\] with the maximum attained at \\(x(s)\\).\n\nThis is referred to as the Bellman equation.\nConversely, it is possible to show that a solution to the Bellman equation is also an optimal solution to the initial problem.",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#bellman-operator",
    "href": "slides/session_ddp/index.html#bellman-operator",
    "title": "Discrete Dynamic Programming",
    "section": "Bellman operator",
    "text": "Bellman operator\n\nThe function \\(G\\) is known as the Bellman operator: \\[G: V \\rightarrow \\max_{y(s)} r(s, y(s)) + \\delta \\sum_{s^{\\prime}\\in S} \\pi(s^{\\prime}| s, y(s)) V(s^{\\prime})\\]\nDefine sequence \\(V_n = G(V_{n-1})\\)\n\nit goes back in time\nbut is not the time-iteration operator\n\nOptimal value is a fixed point of G\nDoes \\(G\\) converges to it ? Yes, if \\(G\\) is a contraction mapping.",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#blackwells-theorem",
    "href": "slides/session_ddp/index.html#blackwells-theorem",
    "title": "Discrete Dynamic Programming",
    "section": "Blackwell’s theorem",
    "text": "Blackwell’s theorem\n\nLet \\(X\\subset R^n\\) and let \\(\\mathcal{C}(X)\\) be a space of bounded functions \\(f: X\\rightarrow  R\\), with the sup-metric. \\(B: \\mathcal{C}(X)\\rightarrow \\mathcal{C}(X)\\) be an operator satisfying two conditions:\n\n(monotonicity) if \\(f,g \\in \\mathcal{C}(X)\\) and \\(\\forall x\\in X, f(x)\\leq g(x)\\) then\n\n\\(\\forall x \\in X (Bf)(x)\\leq(Bg)(x)\\)\n\n(discounting) there exists some \\(\\delta\\in]0,1[\\) such that: \\(B.(f+a)(x)\\leq (B.f)(x) + \\delta a, \\forall f \\in \\mathcal{C}(X), a\\geq 0, x\\in X\\)\n\nThen \\(B\\) is a contraction mapping with modulus \\(\\delta\\).",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#successive-approximation-1",
    "href": "slides/session_ddp/index.html#successive-approximation-1",
    "title": "Discrete Dynamic Programming",
    "section": "Successive Approximation",
    "text": "Successive Approximation\n\nUsing the Blackwell’s theorem, we can prove the Bellman operator is a contraction mapping.\nThis justifies the Value Function Iteration algorithm:\n\nchoose an initial \\(V_0\\)\ngiven \\(V_n\\) compute \\(V_{n+1} = G(V_n)\\)\niterate until \\(|V_{n+1}- V_n|\\leq \\eta\\)\n\nPolicy rule is deduced from \\(V\\) as the maximand in the Bellman step",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#successive-approximation-2-1",
    "href": "slides/session_ddp/index.html#successive-approximation-2-1",
    "title": "Discrete Dynamic Programming",
    "section": "Successive Approximation (2)",
    "text": "Successive Approximation (2)\nAssume that \\(X\\) is finite.\n\nNote that convergence of \\(V_n\\) is geometric\nBut \\(x_n\\) converges after a finite number of iteration.\n\nsurely the latest iterations are suboptimal\nthey serve only to evaluate the value of \\(x\\)\n\nIn fact:\n\n\\(V_n\\) is never the value of \\(x_n()\\)\nshould we try to keep both in sync?",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#policy-iteration-for-dmdp",
    "href": "slides/session_ddp/index.html#policy-iteration-for-dmdp",
    "title": "Discrete Dynamic Programming",
    "section": "Policy iteration for DMDP",
    "text": "Policy iteration for DMDP\n\nChoose initial policy \\(x_0()\\)\nGiven initial guess \\(x_n()\\)\n\ncompute the value function \\(V_n=V( ;x_n)\\) which satisfies\n\\(\\forall s,  V_n(s) = r(s, x_n(s)) + \\delta \\sum_{s'} \\pi(s'| s, x_n(s)) V_n(s')\\)\nimprove policy by maximizing in \\(x_n()\\) \\[\\max_{x_n()} r(s, x_n(s)) + \\delta \\sum_{s^{\\prime}\\in S} \\pi(s^{\\prime}| s, x_n(s)) V_{n-1}(s^{\\prime})\\]\n\nRepeat until convergence, i.e. \\(x_n=x_{n+1}\\)\nOne can show the speed of convergence (for \\(V_n\\)) is quadratic\n\nit corresponds the Newton-Raphson steps applied to \\(V\\rightarrow G(V)-V\\)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#how-do-we-compute-the-value-of-a-policy",
    "href": "slides/session_ddp/index.html#how-do-we-compute-the-value-of-a-policy",
    "title": "Discrete Dynamic Programming",
    "section": "How do we compute the value of a policy?",
    "text": "How do we compute the value of a policy?\n\nGiven \\(x_n\\), goal is to find \\(V_n(s)\\) in \\[\\forall s,  V_n(s) = r(s, x_n(s)) + \\delta \\sum_{s'} \\pi(s'| s, x_n(s)) V_n(s')\\]\nThree approaches:\n\nsimulate the policy rule and compute \\(E\\left[ \\sum_t \\delta^t r(s_t, x_t) \\right]\\) with Monte-Carlo draws\nsuccessive approximation:\n\nput \\(V_k\\) in the rhs and recompute the lhs \\(V_{k+1}\\), replace \\(V_k\\) by \\(V_{k+1}\\) and iterate until convergence\n\nsolve a linear system in \\(V_n\\)\n\nFor 2 and 3 it is useful to constuct a linear operator \\(M\\) such that \\(V_{n+1} = R_n + \\delta M_n .  V_n\\)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#idea",
    "href": "slides/session_ddp/index.html#idea",
    "title": "Discrete Dynamic Programming",
    "section": "Idea",
    "text": "Idea\n\nMcCall model:\n\nwhen should an unemployed person accept a job offer?\nchoice between:\n\nwait for a better offer (and receive low unemp. benefits)\naccept a suboptimal job offer\n\n\nWe present a variant of it, with a small probability of loosing a job.",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#formalization",
    "href": "slides/session_ddp/index.html#formalization",
    "title": "Discrete Dynamic Programming",
    "section": "Formalization",
    "text": "Formalization\n\nWhen unemployed in date, a job-seeker\n\nconsumes unemployment benefit \\(c = \\underline{c}\\)\nreceives in every date \\(t\\) a job offer \\(w\\)\n\n\\(w\\) is i.i.d.,\ntakes values \\(w_1, w_2, w_3\\) with probabilities \\(p_1, p_2, p_3\\)\n\nif job-seeker accepts, becomes employed at rate \\(w\\) in the next period\nelse he stays unemployed\n\nWhen employed at rate \\(w\\)\n\nworker consumes salary \\(c = w\\)\nwith small probability \\(\\lambda&gt;0\\) looses his job:\n\nstarts next period unemployed\n\notherwise stays employed at same rate\n\nObjective: \\(\\max E_0 \\left\\{ \\sum \\beta^t \\log(c^t) \\right\\}\\)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#states-reward",
    "href": "slides/session_ddp/index.html#states-reward",
    "title": "Discrete Dynamic Programming",
    "section": "States / reward",
    "text": "States / reward\n\nWhat are the states?\n\nemployement status: Unemployed / Employed\nif Unemployed:\n\nthe level \\(w\\in {w_1, w_2, w_3}\\) of the salary that is currently proposed\n\nif Employed:\n\nthe level \\(w\\in {w_1, w_2, w_3}\\) at which worker was hired\n\ncurrent state, can be represented by a 2x3 index\n\nWhat are the actions?\n\nif Unemployed:\n\nreject (false) / accept (true)\n\nif Employed: None\nactions (when unemployed) are represented by a 3 elements binary vector\n\nWhat is the (intratemporal) reward?\n\nif Unemployed: \\(U(c)\\)\nif Employed at rate w: \\(U(w)\\)\nhere it doesn’t depend on the action",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#value-function",
    "href": "slides/session_ddp/index.html#value-function",
    "title": "Discrete Dynamic Programming",
    "section": "Value function",
    "text": "Value function\n\\(\\newcommand{\\E}{\\mathbb{E}}\\)\n\nWhat is the value of being in a given state?\nIf Unemployed, facing current offer \\(w\\):\n\\[V^U(w) = U(\\underline{c}) + \\max_{a} \\begin{cases} \\beta V^E(w) & \\text{if $a(w)$ is true} \\\\ \\beta  E_{w'}\\left[ V^U(w^{\\prime}) \\right]  & \\text{if $a(w)$ is false} \\end{cases}\\]\nIf Employed, at rate \\(w\\) \\[V^E(w) = U(w) +  (1-\\lambda) \\beta V^E(w) +  \\lambda \\beta E_{w'}\\left[ V^U(w^{\\prime}) \\right] \\]\nWe can represent value as two functions \\(V^U\\) and \\(V^E\\) of the states as\n\ntwo vectors of Floats, with three elements (recall: value-function is real valued)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#value-function-iteration",
    "href": "slides/session_ddp/index.html#value-function-iteration",
    "title": "Discrete Dynamic Programming",
    "section": "Value function iteration",
    "text": "Value function iteration\n\nTake a guess for value function \\(\\tilde{V^E}\\), \\(\\tilde{V^U}\\), tomorrow\nUse it to compute value function today: \\[V^U(w) = U(\\underline{c}) + \\max_{a(w)} \\begin{cases} \\beta \\tilde{V}^E(w) & \\text{if $a(w)$ is true} \\\\ \\beta  E_{w'}\\left[ \\tilde{V}^U(w^{\\prime}) \\right]  & \\text{if $a(w)$ is false} \\end{cases}\\] \\[V^E(w) = U(w) +  (1-\\lambda) \\beta \\tilde{V}^E(w) +  \\lambda \\beta E_{w'}\\left[\\tilde{V}^U(w^{\\prime}) \\right] \\]\n\\((\\tilde{V}^E, \\tilde{V}^U)\\mapsto (V^E, V^U)\\) is one value iteration step\nNote that we don’t have to keep track of policies tomorrow\n\nall information about future decisions is contained in \\(\\tilde{V}^E, \\tilde{V}^U\\)\nbut we can keep track of current policy: \\(a(w): \\arg\\max \\cdots\\)",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#value-evaluation",
    "href": "slides/session_ddp/index.html#value-evaluation",
    "title": "Discrete Dynamic Programming",
    "section": "Value evaluation",
    "text": "Value evaluation\n\nSuppose we take a policy \\(a(w)\\) as given. What is the value of following this policy forever?\nThe value function \\(V_a^E\\), \\(V_a^U\\) satisfies \\[V_a^U(w) = U(\\underline{c}) + \\begin{cases} \\beta {V}^E_a(w) & \\text{if $a(w)$ is true} \\\\ \\beta  E_{w'}\\left[ {V}^U_a(w^{\\prime}) \\right]  & \\text{if $a(w)$ is false} \\end{cases}\\] \\[V_a^E(w) = U(w) +  (1-\\lambda) \\beta {V}^E_a(w) +  \\lambda \\beta E_{w'}\\left[{V}^U_a(w^{\\prime}) \\right] \\]\nNote the absence of the max function: we don’t reoptimize",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#value-evaluation-2",
    "href": "slides/session_ddp/index.html#value-evaluation-2",
    "title": "Discrete Dynamic Programming",
    "section": "Value evaluation (2)",
    "text": "Value evaluation (2)\n\nHow do you compute value of policy \\(a(w)\\) recursively?\nIterate: \\((\\tilde{V}^E_a, \\tilde{V}^U)\\mapsto (V^E_a, V^U_a)\\) \\[V_a^U(w) \\leftarrow U(\\underline{c}) + \\begin{cases} \\beta \\tilde{V}^E_a(w) & \\text{if $a(w)$ is true} \\\\ \\beta  E_{w'}\\left[ \\tilde{V}^U_a(w^{\\prime}) \\right]  & \\text{if $a(w)$ is false} \\end{cases}\\] \\[V_a^E(w) \\leftarrow U(w) +  (1-\\lambda) \\beta \\tilde{V}^E_a(w) +  \\lambda \\beta E_{w'}\\left[\\tilde{V}^U_a(w^{\\prime}) \\right] \\]\nNote the absence of the max function:\n\nwe don’t reoptimize\nwe we keep the same policy all along",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/session_ddp/index.html#policy-iteration",
    "href": "slides/session_ddp/index.html#policy-iteration",
    "title": "Discrete Dynamic Programming",
    "section": "Policy iteration",
    "text": "Policy iteration\n\nstart with policy \\(a(w)\\)\nevaluate the value of this policy \\(V^E_a, V^U_a\\)\ncompute the optimal policy \\(a(w)\\) in the Bellman iteration\n\nhere: \\(a(w) = \\arg\\max_{a(w)} \\begin{cases} \\beta \\tilde{V}^E(w)\\\\ \\beta  E_{a'}\\left[ \\tilde{V}^U(a^{\\prime}) \\right] \\end{cases}\\)\n\niterate until \\(a(w)\\) converges",
    "crumbs": [
      "Slides",
      "Discrete Dynamic Programming"
    ]
  },
  {
    "objectID": "slides/optimization copy.html",
    "href": "slides/optimization copy.html",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Optimization is everywhere in economics:\n\nto model agent’s behaviour: what would a rational agent do?\n\nconsumer maximizes utility from consumption\nfirm maximizes profit\n\nan economist tries to solve a model:\n\nfind prices that clear the market\n\n\n\n\n\n\n\nroot finding: \\(\\text{find  $x$ in $X$ such that $f(x)=0$}\\)\nminimization/maximization \\(\\min_{x\\in X} f(x)\\) or \\(\\max_{x\\in X} f(x)\\)\noften a minimization problem can be reformulated as a root-finding problem\n\\[x_0 = {argmin}_{x\\in X} f(x) \\overbrace{\\iff}^{??} f^{\\prime} (x_0) = 0\\]\n\n\n\n\n\n\ngeneral consideration about optimization problems\none-dimensional root-finding\none-dimensional optimization\nlocal root-finding\nlocal optimization\nconstrained optimization\nconstrained root-finding\n\n\n\n\n\n\n\n\n\n\ncontinuous versus discrete optimization\nconstrained and unconstrained optimization\nglobal and local\nstochastic and deterministic optimization\nconvexity\n\n\n\n\n\n\nChoice is picked from a given set (\\(x\\in X\\)) which can be:\n\ncontinuous: choose amount of debt \\(b_t \\in [0,\\overline{b}]\\), of capital \\(k_t \\in R^{+}\\)\ndiscrete: choose whether to repay or default \\(\\delta\\in{0,1}\\), how many machines to buy (\\(\\in N\\)), at which age to retire…\na combination of both: mixed integer programming\n\n\n\n\n\n\n\nDiscrete optimization requires a lot of combinatorial thinking. We don’t cover it.\nSometimes a discrete choice can be approximated by a mixed strategy (i.e. a random strategy).\n\nInstead of \\(\\delta\\in{0,1}\\) we choose \\(x\\) in \\(prob(\\delta=1)=\\sigma(x)\\)\nwith \\(\\sigma(x)=\\frac{2}{1+\\exp(-x)}\\)\n\n\n\n\n\n\n\nUnconstrained optimization: \\(x\\in R\\)\nConstrained optimization: \\(x\\in X\\)\n\nbudget set: \\(p_1 c_1 + p_2 c_2 \\leq I\\)\npositivity of consumption: \\(c \\geq 0\\).\n\nIn good cases, the optimization set is convex…\n\npretty much always in this course\n\n\n\n\n\n\n\nCommon case, especially in machine learning \\[f(x) = E_{\\epsilon}[ \\xi (\\epsilon, x)]\\]\nOne wants to maximize (resp solve) w.r.t. \\(x\\) but it is costly to compute expectation precisely using Monte-Carlo draws (there are other methods).\nA stochastic optimization method allows to use noisy estimates of the expectation, and will still converge in expectation.\nFor now we focus on deterministic methods. Maybe later…\n\n\n\n\n\n\nIn principle, there can be many roots (resp maxima) within the optimization set.\nAlorithma that find them all are called “global”. For instance:\n\ngrid search\nsimulated annealing\n\nWe will deal only with local algorithms, and consider local convergence properties.\n\n-&gt;then it might work or not\nto perform global optimization just restart from different points.\n\n\n\n\n\n\n\nThe full mathematical treatment will typically assume that \\(f\\) is smooth (\\(\\mathcal{C}_1\\) or \\(\\mathcal{C}_2\\) depending on the algorithm).\nIn practice we often don’t know about these properties\n\nwe still try and check we have a local optimal\n\nSo: fingers crossed\n\n\n\n\n\nHere is the surface representing the objective that a deep neural network training algorithm tries to minimize.\n\nAnd yet, neural networks do great things!\n\n\n\n\n\nbe able to handcode simple algos (Newton, Gradient Descent)\nunderstand the general principle of the various algorithms to compare them in terms of\n\nrobustness\nefficiency\naccuracy\n\nthen you can just switch the various options, when you use a library…\n\n\n\n\n\n\n\n\n\n\nFind \\(x \\in [a,b]\\) such that \\(f(x) = 0\\). Assume \\(f(a)f(b) &lt;0\\).\nAlgorithm\n\nStart with \\(a_n, b_n\\). Set \\(c_n=(a_n+b_n)/2\\)\nCompute \\(f(c_n)\\)\n\n\nif \\(f(c_n)f(a_n)&gt;0\\) then set \\((a_{n+1},b_{n+1})=(a_n,c_n)\\)\nelse set \\((a_{n+1},b_{n+1})=(c_n,b_n)\\)\n\n\nIf \\(f(c_n)&lt;\\epsilon\\) and/or \\(\\frac{b-a}/2^n&lt;\\delta\\) stop. Otherwise go back to 1.\n\n\n\n\n\n\n\nNo need for initial guess: globally convergent algorithm\n\nnot a global algorithm…\n… in the sense that it doesn’t find all solutions\n\n\\(\\delta\\) is a guaranteed accuracy on \\(x\\)\n\\(\\epsilon\\) is a measure of how good the solution is\nthink about your tradeoff: (\\(\\delta\\) or \\(\\epsilon\\) ?)\n\n\n\n\n\n\n\nFind \\(x\\) such that \\(f(x) = 0\\). Use \\(x_0\\) as initial guess.\n\\(f\\) must be \\(\\mathcal{C_1}\\) and we assume we can compute its derivative \\(f^{\\prime}\\)\nGeneral idea:\n\nobserve that the zero \\(x^{\\star}\\) must satisfy \\[f(x^{\\star})=0=f(x_0)+f^{\\prime}(x_0)(x^{\\star}-x_0) + o(x-x_0)\\]\nHence a good approximation should be \\[x^{\\star}\\approx = x_0- f(x_0)/f^{\\prime}(x_0)\\]\n\n\n\n\n\n\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n- \\frac{f(x_n}{f^{\\prime}(x_n)}=f^{\\text{newton}}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic\n\n\n\n\n\n\n\nWhat if we can’t compute \\(f^{\\prime}\\) or it is expensive to do so?\n\nIdea: try to approximate \\(f^{\\prime}(x_n)\\) from the last iterates\n\nsecant method: \\(f^{\\prime}(x_n)\\approx \\frac{f(x_n)-f(x_{n-1})}{x_n-x_{n-1}}\\) \\(x_{n+1} = x_n- f(x_n)\\frac{x_n-x_{n-1}}{f(x_n)-f(x_{n-1})}\\)\n\nrequires two initial guesses: \\(x_1\\) and \\(x_0\\)\nsuperlinear convergence: \\(\\lim \\frac{x_t-x^{\\star}}{x_{t-1}-x^{\\star}}\\rightarrow 0\\)\n\n\n\n\n\n\n\nHow could Newton method fail?\n\nbad guess\n\n-&gt; start with a better guess\n\novershoot\n\n-&gt; dampen the update (problem: much slower)\n-&gt; backtrack\n\nstationary point\n\n-&gt; if root of multiplicity \\(m\\) try \\(x_{n+1} = x_n- m f(x_n)/f^{\\prime}(x_n)\\) (FIX)\n\n\n\n\n\n\n\n\nSimple idea:\n\nat stage \\(n\\) given \\(f(x_n)\\) compute Newton step \\(\\Delta_n=-\\frac{f(x_n)}{f^{\\prime}(x_n)}\\)\nfind the smallest \\(k\\) such that \\(|f(x_n-\\Delta/2^k)|&lt;|f(x_n)|\\)\nset \\(x_{n+1}=x_n-\\Delta/2^k\\)\n\n\n\n\n\n\n\n\n\n\n\nMinimize \\(f(x)\\) for \\(x \\in [a,b]\\)\nChoose \\(\\Phi \\in [0,0.5]\\)\nAlgorithm:\n\nstart with \\(a_n &lt; b_n\\) (initially equal to \\(a\\) and \\(b\\))\ndefine \\(c_n = a_n+\\Phi(b_n-a_n)\\) and \\(d_n = a_n+(1-\\Phi)(b_n-a_n)\\)\n\nif \\(f(c_n)&lt;f(d_n)\\) set \\(a_{n+1},b_{n+1}=a_n, d_n\\)\nelse set \\(a_{n+1}, b_{n+1}= c_n, b_n\\)\n\n\n\n\n\n\n\n\nThis is guaranteed to converge to a local minimum\nIn each step, the size of the interval is reduced by a factor \\(\\Phi\\)\nBy choosing \\(\\Phi=\\frac{\\sqrt{5}-1}{2}\\) one can save one evaluation by iteration.\nRemark that bisection is not enough\n\n\n\n\n\n\n\nMinimize \\(f(x)\\) for \\(x \\in R\\) given initial guess \\(x_0\\)\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n (1-\\lambda)- \\lambda f^{\\prime}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f^{\\prime}(x_n)| &lt; \\epsilon\\)\n\n\n\n\n\n\n\nUses local information\n\none needs to compute the gradient\nnote that gradient at \\(x_n\\) does not provide a better guess for the minimum than \\(x_n\\) itself\nlearning speed is crucial\n\nConvergence speed: linear\n\nrate depend on the learning speed\noptimal learning speed? the fastest for which there is convergence\n\n\n\n\n\n\n\nMinimize \\(f(x)\\) for \\(x \\in R\\) given initial guess \\(x_0\\)\nBuild a local model of \\(f\\) around \\(x_0\\) \\[f(x) = f(x_0) + f^{\\prime}(x_0)(x-x_0) + f^{\\prime\\prime}(x_0)\\frac{(x-x_0)^2}{2} + o(x-x_0)^2\\]\nAccording to this model, \\[ f(x{\\star}) = min_x f(x)\\iff \\frac{d}{d x} \\left[ f(x_0) + f^{\\prime}(x_0)(x-x_0) + f^{\\prime\\prime}(x_0)\\frac{(x-x_0)^2}{2} \\right] = 0\\] which yields: \\(x^{\\star} = x_0 - \\frac{f^{\\prime}(x_0)}{f^{\\prime\\prime}(x_0)}\\)\nthis is Newton applied to \\(f^{\\prime}(x)=0\\)\n\n\n\n\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n-\\frac{f^{\\prime}(x_0)}{f^{\\prime\\prime}(x_0)}\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f^{\\prime}(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic\n\n\n\n\n\n\n\n\n\n\n\nMinimize \\(f(x)\\) for \\(x \\in R^n\\) given initial guess \\(x_0 \\in R^n\\)\nMany intuitions from the 1d case, still apply\n\nreplace derivatives by gradient, jacobian and hessian\nrecall that matrix multiplication is not commutative\n\nSome specific problems:\n\nupdate speed can be specific to each dimension\nsaddle-point issues (for minimization)\n\n\n\n\n\n\nFunction \\(f: R^p \\rightarrow R^q\\)\n\nJacobian: \\(J(x)\\) or \\(f^{\\prime}\\_x(x)\\), \\(p\\times q\\) matrix such that: \\[J(x)\\_{ij} = \\frac{\\partial f(x)\\_i}{\\partial x_j}\\]\nGradient: \\(\\nabla J(x)\\), gradient when \\(q=1\\)\nHessian: denoted by \\(H(x)\\) or \\(f^{\\prime\\prime}\\_{xx}(x)\\) when \\(q=1\\): \\[H(x)\\_{jk} = \\frac{\\partial f(x)}{\\partial x_j\\partial x_k}\\]\nIn the following explanations, \\(|x|\\) denotes the supremum norm, but most of the following explanations also work with other norms.\n\n\n\n\n\n\n\n\n\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n- J(x_{n})^{-1}f(x_n)=f^{\\text{newton}}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic\n\n\n\n\n\n\nwhat matters is the computation of the step \\(\\Delta_n = {\\color{\\red}{J(x_{n})^{-1}}} f(x_n)\\)\ndon’t compute \\(J(x_n)^{-1}\\)\n\nit takes less operations to compute \\(X\\) in \\(AX=Y\\) than \\(A^{-1}\\) then \\(A^{-1}Y\\)\n\nstrategies to improve convergence:\n\ndampening: \\(x_n = (1-\\lambda)x^{n-1} - \\lambda \\Delta_n\\)\nbacktracking: choose \\(k\\) such that \\(|f(x_n-2^{-k}\\Delta_n)|\\)&lt;\\(|f(x_{n-1})|\\)\nlinesearch: choose \\(\\lambda\\in[0,1]\\) so that \\(|f(x_n-\\lambda\\Delta_n)|\\) is minimal\n\n\n\n\n\n\n\n\n\n\n\nMinimize \\(f(x) \\in R\\) for \\(x \\in R^n\\) given \\(x_0 \\in R^n\\)\nAlgorithm\n\nstart with \\(x_n\\) \\[x_{n+1} = (1-\\lambda) x_n - \\lambda \\nabla f(x_n)\\]\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nComments:\n\nlots of variants\nautomatic differentiation software makes gradient easy to compute\nconvergence is typically linear\n\n\n\n\n\n\n\n\n\n\n\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n-{\\color{\\red}{H(x_{n})^{-1}}}\\color{\\green}{ J(x_n)'}\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic\nProblem:\n\n\\(H(x_{n})\\) hard to compute efficiently\nrather unstable\n\n\n\n\n\n\n\nRecall the secant method:\n\n\\(f(x_{n-1})\\) and \\(f(x_{n-2})\\) are used to approximate \\(f^{\\prime}(x_{n-2})\\).\nIntuitively, \\(n\\) iterates would be needed to approximate a hessian of size \\(n\\)….\n\nBroyden method: takes \\(2 n\\) steps to solve a linear problem of size \\(n\\)\n\nuses past information incrementally\n\n\n\n\n\n\n\nConsider the approximation: \\[f(x_n)-f(x_{n-1}) \\approx J(x_n) (x_n - x_{n-1})\\]\n\n\\(J(x_n)\\) is unknown and cannot be determined directly as in the secant method.\nidea: \\(J(x_n)\\) as close as possible to \\(J(x_{n-1})\\) while solving the secant equation\nformula: \\[J_n = J_{n-1} + \\frac{(f(x_n)-f(x_{n-1})) - J_{n-1}(x_n-x_{n-1})}{||x_n-x_{n-1}||^2}(x_n-x_{n-1})^{\\prime}\\]\n\n\n\n\n\n\n\nRestrict to least-square minimization: $min_x _i f(x)_i^2 R $\nThen up to first order, \\(H(x_n)\\approx J(x_n)^{\\prime}J(x_n)\\)\nUse the step: \\(({J(x_n)^{\\prime}J(x_n)})^{-1}\\color{\\green}{ J(x_n)}\\)\nConvergence:\n\ncan be quadratic at best\nlinear in general\n\n\n\n\n\n\n\nLeast-square minimization: $min_x _i f(x)_i^2 R $\nreplace \\({J(x_n)^{\\prime}J(x_n)}^{-1}\\) by \\({J(x_n)^{\\prime}J(x_n)}^{-1} +\\mu I\\)\n\nadjust \\(\\lambda\\) depending on progress\n\nuses only gradient information like Gauss-Newton\nequivalent to Gauss-Newton close to the solution (\\(\\mu\\) small)\nequivalent to Gradient far from solution (\\(\\mu\\) high)\n\n\n\n\n\n\n\n\n\nConsider the optimization problem: \\[\\max U(x_1, x_2)\\]\nunder the constraint \\(p_1 x_1 + p_2 x_2 \\leq B\\)\nwhere \\(U(.)\\), \\(p_1\\), \\(p_2\\) and \\(B\\) are given.\nHow do you find a solution by hand?\n\n\n\n\n\nCompute by hand\nEasy:\n\nsince the budget constraint must be binding, get rid of it by stating \\(x_2 = B - p_1 x_1\\)\nthen maximize in \\(x_1\\), \\(U(x_1, B - p_1 x_1)\\) using the first order conditions.\n\nIt works but:\n\nbreaks symmetry between the two goods\nwhat if there are other constraints: \\(x_1\\geq \\underline{x}\\)?\nwhat if constraints are not binding?\nis there a better way to solve this problem?\n\n\n\n\n\n\n\nAnother method, which keeps the symmetry. Constraint is binding, trying to minimize along the budget line yields an implicit relation between \\(d x_1\\) and \\(d x_2\\) \\[p_1 d {x_1} + p_2 d {x_2} = 0\\]\nAt the optimal: \\(U^{\\prime}\\_{x_1}(x_1, x_2)d {x_1} + U^{\\prime}\\_{x_2}(x_1, x_2)d {x_2} = 0\\)\nEliminate \\(d {x_1}\\) and \\(d {x_2}\\) to get one condition which characterizes optimal choices for all possible budgets. Combine with the budget constraint to get a second condition.\n\n\n\n\n\n\nTake a penalty function \\(p(x)\\) such that \\(p(x)=K&gt;0\\) if \\(x&gt;0\\) and \\(p(x)=0\\) if \\(x \\leq 0\\). Maximize: \\(V(x_1, x_2) = U(x_1, x_2) - p( p_1 x_1 + p_2 x_2 - B)\\)\nClearly, \\(\\min U \\iff \\min V\\)\nProblem: \\(\\nabla V\\) is always equal to \\(\\nabla U\\).\nSolution: use a smooth solution function like \\(p(x) = x^2\\)\nProblem: distorts optimization\n\nSolution: adjust weight of barrier and minimize \\(U(x_1, x_2) - \\kappa p(x)\\)\n\nPossible but hard to choose the weights/constraints.\n\n\n\n\n\n\nAnother idea: is there a canonical way to choose \\(\\lambda\\) such that at the minimum it is equivalent to minimize the original problem under constraint or to minimize \\[V(x_1, x_2) = U(x_1, x_2) - \\lambda (p_1 x_1 + p_2 x_2 - B)\\]\nClearly, when the constraint is not binding we must have \\(\\lambda=0\\). What should be the value of \\(\\lambda\\) when the constraint is binding ?\n\n\n\n\n\n\nIf \\((x^{\\star},y^{\\star})\\) is optimal there exists \\(\\lambda\\) such that:\n\n\\((x^{\\star},y^{\\star})\\) maximizes \\(U(x_1, x_2) + \\lambda (B- p_1 x_1 - p_2 x_2)\\)\n\\(\\lambda \\geq 0\\)\n\\(B- p_1 x_1 - p_2 x_2 \\geq 0\\)\n\\(\\lambda  (B - p_1 x_1 - p_2 x_2 ) = 0\\)\n\nThe three latest conditions are called “complementarity” or “slackness” conditions\n\nthey are equivalent to \\(\\min(\\lambda, B - p_1 x_1 - p_2 x_2)=0\\)\nwe denote \\(\\lambda \\geq 0 \\perp B- p_1 x_1 + p_2 x_2  \\geq 0\\)\n\n\\(\\lambda\\) can be interpreted as the welfare gain of relaxing the constraint.\n\n\n\n\n\n\nWe can get first order conditions that factor in the constraints:\n\n\\(U^{\\prime}_x - \\lambda p_1 = 0\\)\n\\(U^{\\prime}_y - \\lambda p_2 = 0\\)\n\\(\\lambda \\geq 0 \\perp B-p_1 x_1 -p_2 x_2 \\geq 0\\)\n\nIt is now a nonlinear system of equations with complementarities (NCP)\n\nthere are specific solution methods to deal with it\n\n\n\n\n\n\n\nGeneral formulation for vector-valued functions \\[f(x)\\geq 0 \\perp g(x)\\geq 0\\] means \\[\\forall i, f_i(x)\\geq 0 \\perp g_i(x)\\geq 0\\]\n\nNCP do not necessarily arise from a single optimization problem\n\nThere are robust (commercial) solvers for NCP problems (PATH, Knitro) for that\nHow do we solve it numerically?\n\nassume constraint is binding then non-binding then check which one is good\n\nOK if not too many constraints\n\nreformulate it as a smooth problem\napproximate the system by a series of linear complementarities problems (LCP)\n\n\n\n\n\n\n\n\nConsider the Fisher-Burmeister function \\[\\phi(a,b) = a+b-\\sqrt{a^2+b^2}\\]\nIt is infinitely differentiable, except at \\((0,0)\\)\nShow that \\(\\phi(a,b) = 0 \\iff \\min(a,b)=0 \\iff a\\geq 0 \\perp b \\geq 0\\)\nAfter substitution in the original system one can use regular non-linear solver\n\nfun fact: the formulation with a \\(\\min\\) is nonsmooth but also works quite often\n\n\n\n\n\n\n\n\n\n\nRobust optimization code is contained in the following libraries:\n\nRoots.jl: one-dimensional root finding\nNLSolve.jl: multidimensional root finding (+complementarities)\nOptim.jl: minimization\n\nThe two latter libraries have a somewhat peculiar API, but it’s worth absorbing it.\n\nin particular they provide non-alocating algorithms for functions that modify arguments in place\nthey are compatible with automatic differentiation\n\n\njulia&gt; f(x) = [x[1] - x[2] - 1, x[1] + x[2]]\nf (generic function with 1 method)\n\njulia&gt; NLsolve.nlsolve(f, [0., 0.0])\nResults of Nonlinear Solver Algorithm\n * Algorithm: Trust-region with dogleg and autoscaling\n * Starting Point: [0.0, 0.0]\n * Zero: [0.5000000000009869, -0.5000000000009869]\n * Inf-norm of residuals: 0.000000       \n * Iterations: 1                       \n * Convergence: true\n   * |x - x'| &lt; 0.0e+00: false\n   * |f(x)| &lt; 1.0e-08: true                           \n * Function Calls (f): 2\n * Jacobian Calls (df/dx): 2"
  },
  {
    "objectID": "slides/optimization copy.html#introduction",
    "href": "slides/optimization copy.html#introduction",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Optimization is everywhere in economics:\n\nto model agent’s behaviour: what would a rational agent do?\n\nconsumer maximizes utility from consumption\nfirm maximizes profit\n\nan economist tries to solve a model:\n\nfind prices that clear the market\n\n\n\n\n\n\n\nroot finding: \\(\\text{find  $x$ in $X$ such that $f(x)=0$}\\)\nminimization/maximization \\(\\min_{x\\in X} f(x)\\) or \\(\\max_{x\\in X} f(x)\\)\noften a minimization problem can be reformulated as a root-finding problem\n\\[x_0 = {argmin}_{x\\in X} f(x) \\overbrace{\\iff}^{??} f^{\\prime} (x_0) = 0\\]\n\n\n\n\n\n\ngeneral consideration about optimization problems\none-dimensional root-finding\none-dimensional optimization\nlocal root-finding\nlocal optimization\nconstrained optimization\nconstrained root-finding"
  },
  {
    "objectID": "slides/optimization copy.html#general-considerations",
    "href": "slides/optimization copy.html#general-considerations",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "continuous versus discrete optimization\nconstrained and unconstrained optimization\nglobal and local\nstochastic and deterministic optimization\nconvexity\n\n\n\n\n\n\nChoice is picked from a given set (\\(x\\in X\\)) which can be:\n\ncontinuous: choose amount of debt \\(b_t \\in [0,\\overline{b}]\\), of capital \\(k_t \\in R^{+}\\)\ndiscrete: choose whether to repay or default \\(\\delta\\in{0,1}\\), how many machines to buy (\\(\\in N\\)), at which age to retire…\na combination of both: mixed integer programming\n\n\n\n\n\n\n\nDiscrete optimization requires a lot of combinatorial thinking. We don’t cover it.\nSometimes a discrete choice can be approximated by a mixed strategy (i.e. a random strategy).\n\nInstead of \\(\\delta\\in{0,1}\\) we choose \\(x\\) in \\(prob(\\delta=1)=\\sigma(x)\\)\nwith \\(\\sigma(x)=\\frac{2}{1+\\exp(-x)}\\)\n\n\n\n\n\n\n\nUnconstrained optimization: \\(x\\in R\\)\nConstrained optimization: \\(x\\in X\\)\n\nbudget set: \\(p_1 c_1 + p_2 c_2 \\leq I\\)\npositivity of consumption: \\(c \\geq 0\\).\n\nIn good cases, the optimization set is convex…\n\npretty much always in this course\n\n\n\n\n\n\n\nCommon case, especially in machine learning \\[f(x) = E_{\\epsilon}[ \\xi (\\epsilon, x)]\\]\nOne wants to maximize (resp solve) w.r.t. \\(x\\) but it is costly to compute expectation precisely using Monte-Carlo draws (there are other methods).\nA stochastic optimization method allows to use noisy estimates of the expectation, and will still converge in expectation.\nFor now we focus on deterministic methods. Maybe later…\n\n\n\n\n\n\nIn principle, there can be many roots (resp maxima) within the optimization set.\nAlorithma that find them all are called “global”. For instance:\n\ngrid search\nsimulated annealing\n\nWe will deal only with local algorithms, and consider local convergence properties.\n\n-&gt;then it might work or not\nto perform global optimization just restart from different points.\n\n\n\n\n\n\n\nThe full mathematical treatment will typically assume that \\(f\\) is smooth (\\(\\mathcal{C}_1\\) or \\(\\mathcal{C}_2\\) depending on the algorithm).\nIn practice we often don’t know about these properties\n\nwe still try and check we have a local optimal\n\nSo: fingers crossed\n\n\n\n\n\nHere is the surface representing the objective that a deep neural network training algorithm tries to minimize.\n\nAnd yet, neural networks do great things!\n\n\n\n\n\nbe able to handcode simple algos (Newton, Gradient Descent)\nunderstand the general principle of the various algorithms to compare them in terms of\n\nrobustness\nefficiency\naccuracy\n\nthen you can just switch the various options, when you use a library…"
  },
  {
    "objectID": "slides/optimization copy.html#one-dimensional-root-finding",
    "href": "slides/optimization copy.html#one-dimensional-root-finding",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Find \\(x \\in [a,b]\\) such that \\(f(x) = 0\\). Assume \\(f(a)f(b) &lt;0\\).\nAlgorithm\n\nStart with \\(a_n, b_n\\). Set \\(c_n=(a_n+b_n)/2\\)\nCompute \\(f(c_n)\\)\n\n\nif \\(f(c_n)f(a_n)&gt;0\\) then set \\((a_{n+1},b_{n+1})=(a_n,c_n)\\)\nelse set \\((a_{n+1},b_{n+1})=(c_n,b_n)\\)\n\n\nIf \\(f(c_n)&lt;\\epsilon\\) and/or \\(\\frac{b-a}/2^n&lt;\\delta\\) stop. Otherwise go back to 1.\n\n\n\n\n\n\n\nNo need for initial guess: globally convergent algorithm\n\nnot a global algorithm…\n… in the sense that it doesn’t find all solutions\n\n\\(\\delta\\) is a guaranteed accuracy on \\(x\\)\n\\(\\epsilon\\) is a measure of how good the solution is\nthink about your tradeoff: (\\(\\delta\\) or \\(\\epsilon\\) ?)\n\n\n\n\n\n\n\nFind \\(x\\) such that \\(f(x) = 0\\). Use \\(x_0\\) as initial guess.\n\\(f\\) must be \\(\\mathcal{C_1}\\) and we assume we can compute its derivative \\(f^{\\prime}\\)\nGeneral idea:\n\nobserve that the zero \\(x^{\\star}\\) must satisfy \\[f(x^{\\star})=0=f(x_0)+f^{\\prime}(x_0)(x^{\\star}-x_0) + o(x-x_0)\\]\nHence a good approximation should be \\[x^{\\star}\\approx = x_0- f(x_0)/f^{\\prime}(x_0)\\]\n\n\n\n\n\n\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n- \\frac{f(x_n}{f^{\\prime}(x_n)}=f^{\\text{newton}}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic\n\n\n\n\n\n\n\nWhat if we can’t compute \\(f^{\\prime}\\) or it is expensive to do so?\n\nIdea: try to approximate \\(f^{\\prime}(x_n)\\) from the last iterates\n\nsecant method: \\(f^{\\prime}(x_n)\\approx \\frac{f(x_n)-f(x_{n-1})}{x_n-x_{n-1}}\\) \\(x_{n+1} = x_n- f(x_n)\\frac{x_n-x_{n-1}}{f(x_n)-f(x_{n-1})}\\)\n\nrequires two initial guesses: \\(x_1\\) and \\(x_0\\)\nsuperlinear convergence: \\(\\lim \\frac{x_t-x^{\\star}}{x_{t-1}-x^{\\star}}\\rightarrow 0\\)\n\n\n\n\n\n\n\nHow could Newton method fail?\n\nbad guess\n\n-&gt; start with a better guess\n\novershoot\n\n-&gt; dampen the update (problem: much slower)\n-&gt; backtrack\n\nstationary point\n\n-&gt; if root of multiplicity \\(m\\) try \\(x_{n+1} = x_n- m f(x_n)/f^{\\prime}(x_n)\\) (FIX)\n\n\n\n\n\n\n\n\nSimple idea:\n\nat stage \\(n\\) given \\(f(x_n)\\) compute Newton step \\(\\Delta_n=-\\frac{f(x_n)}{f^{\\prime}(x_n)}\\)\nfind the smallest \\(k\\) such that \\(|f(x_n-\\Delta/2^k)|&lt;|f(x_n)|\\)\nset \\(x_{n+1}=x_n-\\Delta/2^k\\)"
  },
  {
    "objectID": "slides/optimization copy.html#one-dimensional-minimization",
    "href": "slides/optimization copy.html#one-dimensional-minimization",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Minimize \\(f(x)\\) for \\(x \\in [a,b]\\)\nChoose \\(\\Phi \\in [0,0.5]\\)\nAlgorithm:\n\nstart with \\(a_n &lt; b_n\\) (initially equal to \\(a\\) and \\(b\\))\ndefine \\(c_n = a_n+\\Phi(b_n-a_n)\\) and \\(d_n = a_n+(1-\\Phi)(b_n-a_n)\\)\n\nif \\(f(c_n)&lt;f(d_n)\\) set \\(a_{n+1},b_{n+1}=a_n, d_n\\)\nelse set \\(a_{n+1}, b_{n+1}= c_n, b_n\\)\n\n\n\n\n\n\n\n\nThis is guaranteed to converge to a local minimum\nIn each step, the size of the interval is reduced by a factor \\(\\Phi\\)\nBy choosing \\(\\Phi=\\frac{\\sqrt{5}-1}{2}\\) one can save one evaluation by iteration.\nRemark that bisection is not enough"
  },
  {
    "objectID": "slides/optimization copy.html#gradient-descent",
    "href": "slides/optimization copy.html#gradient-descent",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Minimize \\(f(x)\\) for \\(x \\in R\\) given initial guess \\(x_0\\)\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n (1-\\lambda)- \\lambda f^{\\prime}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f^{\\prime}(x_n)| &lt; \\epsilon\\)"
  },
  {
    "objectID": "slides/optimization copy.html#gradient-descent-2",
    "href": "slides/optimization copy.html#gradient-descent-2",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Uses local information\n\none needs to compute the gradient\nnote that gradient at \\(x_n\\) does not provide a better guess for the minimum than \\(x_n\\) itself\nlearning speed is crucial\n\nConvergence speed: linear\n\nrate depend on the learning speed\noptimal learning speed? the fastest for which there is convergence"
  },
  {
    "objectID": "slides/optimization copy.html#newton-raphson-method",
    "href": "slides/optimization copy.html#newton-raphson-method",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Minimize \\(f(x)\\) for \\(x \\in R\\) given initial guess \\(x_0\\)\nBuild a local model of \\(f\\) around \\(x_0\\) \\[f(x) = f(x_0) + f^{\\prime}(x_0)(x-x_0) + f^{\\prime\\prime}(x_0)\\frac{(x-x_0)^2}{2} + o(x-x_0)^2\\]\nAccording to this model, \\[ f(x{\\star}) = min_x f(x)\\iff \\frac{d}{d x} \\left[ f(x_0) + f^{\\prime}(x_0)(x-x_0) + f^{\\prime\\prime}(x_0)\\frac{(x-x_0)^2}{2} \\right] = 0\\] which yields: \\(x^{\\star} = x_0 - \\frac{f^{\\prime}(x_0)}{f^{\\prime\\prime}(x_0)}\\)\nthis is Newton applied to \\(f^{\\prime}(x)=0\\)\n\n\n\n\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n-\\frac{f^{\\prime}(x_0)}{f^{\\prime\\prime}(x_0)}\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f^{\\prime}(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic"
  },
  {
    "objectID": "slides/optimization copy.html#unconstrained-multidimensional-optimization",
    "href": "slides/optimization copy.html#unconstrained-multidimensional-optimization",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Minimize \\(f(x)\\) for \\(x \\in R^n\\) given initial guess \\(x_0 \\in R^n\\)\nMany intuitions from the 1d case, still apply\n\nreplace derivatives by gradient, jacobian and hessian\nrecall that matrix multiplication is not commutative\n\nSome specific problems:\n\nupdate speed can be specific to each dimension\nsaddle-point issues (for minimization)\n\n\n\n\n\n\nFunction \\(f: R^p \\rightarrow R^q\\)\n\nJacobian: \\(J(x)\\) or \\(f^{\\prime}\\_x(x)\\), \\(p\\times q\\) matrix such that: \\[J(x)\\_{ij} = \\frac{\\partial f(x)\\_i}{\\partial x_j}\\]\nGradient: \\(\\nabla J(x)\\), gradient when \\(q=1\\)\nHessian: denoted by \\(H(x)\\) or \\(f^{\\prime\\prime}\\_{xx}(x)\\) when \\(q=1\\): \\[H(x)\\_{jk} = \\frac{\\partial f(x)}{\\partial x_j\\partial x_k}\\]\nIn the following explanations, \\(|x|\\) denotes the supremum norm, but most of the following explanations also work with other norms."
  },
  {
    "objectID": "slides/optimization copy.html#unconstrained-multidimensional-root-finding",
    "href": "slides/optimization copy.html#unconstrained-multidimensional-root-finding",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Algorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n- J(x_{n})^{-1}f(x_n)=f^{\\text{newton}}(x_n)\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic\n\n\n\n\n\n\nwhat matters is the computation of the step \\(\\Delta_n = {\\color{\\red}{J(x_{n})^{-1}}} f(x_n)\\)\ndon’t compute \\(J(x_n)^{-1}\\)\n\nit takes less operations to compute \\(X\\) in \\(AX=Y\\) than \\(A^{-1}\\) then \\(A^{-1}Y\\)\n\nstrategies to improve convergence:\n\ndampening: \\(x_n = (1-\\lambda)x^{n-1} - \\lambda \\Delta_n\\)\nbacktracking: choose \\(k\\) such that \\(|f(x_n-2^{-k}\\Delta_n)|\\)&lt;\\(|f(x_{n-1})|\\)\nlinesearch: choose \\(\\lambda\\in[0,1]\\) so that \\(|f(x_n-\\lambda\\Delta_n)|\\) is minimal"
  },
  {
    "objectID": "slides/optimization copy.html#unconstrained-multidimensional-minimization",
    "href": "slides/optimization copy.html#unconstrained-multidimensional-minimization",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Minimize \\(f(x) \\in R\\) for \\(x \\in R^n\\) given \\(x_0 \\in R^n\\)\nAlgorithm\n\nstart with \\(x_n\\) \\[x_{n+1} = (1-\\lambda) x_n - \\lambda \\nabla f(x_n)\\]\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nComments:\n\nlots of variants\nautomatic differentiation software makes gradient easy to compute\nconvergence is typically linear\n\n\n\n\n\n\n\n\n\n\n\n\nAlgorithm:\n\nstart with \\(x_n\\)\ncompute \\(x_{n+1} = x_n-{\\color{\\red}{H(x_{n})^{-1}}}\\color{\\green}{ J(x_n)'}\\)\nstop if \\(|x_{n+1}-x_n|&lt;\\eta\\) or \\(|f(x_n)| &lt; \\epsilon\\)\n\nConvergence: quadratic\nProblem:\n\n\\(H(x_{n})\\) hard to compute efficiently\nrather unstable\n\n\n\n\n\n\n\nRecall the secant method:\n\n\\(f(x_{n-1})\\) and \\(f(x_{n-2})\\) are used to approximate \\(f^{\\prime}(x_{n-2})\\).\nIntuitively, \\(n\\) iterates would be needed to approximate a hessian of size \\(n\\)….\n\nBroyden method: takes \\(2 n\\) steps to solve a linear problem of size \\(n\\)\n\nuses past information incrementally\n\n\n\n\n\n\n\nConsider the approximation: \\[f(x_n)-f(x_{n-1}) \\approx J(x_n) (x_n - x_{n-1})\\]\n\n\\(J(x_n)\\) is unknown and cannot be determined directly as in the secant method.\nidea: \\(J(x_n)\\) as close as possible to \\(J(x_{n-1})\\) while solving the secant equation\nformula: \\[J_n = J_{n-1} + \\frac{(f(x_n)-f(x_{n-1})) - J_{n-1}(x_n-x_{n-1})}{||x_n-x_{n-1}||^2}(x_n-x_{n-1})^{\\prime}\\]\n\n\n\n\n\n\n\nRestrict to least-square minimization: $min_x _i f(x)_i^2 R $\nThen up to first order, \\(H(x_n)\\approx J(x_n)^{\\prime}J(x_n)\\)\nUse the step: \\(({J(x_n)^{\\prime}J(x_n)})^{-1}\\color{\\green}{ J(x_n)}\\)\nConvergence:\n\ncan be quadratic at best\nlinear in general\n\n\n\n\n\n\n\nLeast-square minimization: $min_x _i f(x)_i^2 R $\nreplace \\({J(x_n)^{\\prime}J(x_n)}^{-1}\\) by \\({J(x_n)^{\\prime}J(x_n)}^{-1} +\\mu I\\)\n\nadjust \\(\\lambda\\) depending on progress\n\nuses only gradient information like Gauss-Newton\nequivalent to Gauss-Newton close to the solution (\\(\\mu\\) small)\nequivalent to Gradient far from solution (\\(\\mu\\) high)"
  },
  {
    "objectID": "slides/optimization copy.html#constrained-optimization-and-complementarity-conditions",
    "href": "slides/optimization copy.html#constrained-optimization-and-complementarity-conditions",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Consider the optimization problem: \\[\\max U(x_1, x_2)\\]\nunder the constraint \\(p_1 x_1 + p_2 x_2 \\leq B\\)\nwhere \\(U(.)\\), \\(p_1\\), \\(p_2\\) and \\(B\\) are given.\nHow do you find a solution by hand?\n\n\n\n\n\nCompute by hand\nEasy:\n\nsince the budget constraint must be binding, get rid of it by stating \\(x_2 = B - p_1 x_1\\)\nthen maximize in \\(x_1\\), \\(U(x_1, B - p_1 x_1)\\) using the first order conditions.\n\nIt works but:\n\nbreaks symmetry between the two goods\nwhat if there are other constraints: \\(x_1\\geq \\underline{x}\\)?\nwhat if constraints are not binding?\nis there a better way to solve this problem?\n\n\n\n\n\n\n\nAnother method, which keeps the symmetry. Constraint is binding, trying to minimize along the budget line yields an implicit relation between \\(d x_1\\) and \\(d x_2\\) \\[p_1 d {x_1} + p_2 d {x_2} = 0\\]\nAt the optimal: \\(U^{\\prime}\\_{x_1}(x_1, x_2)d {x_1} + U^{\\prime}\\_{x_2}(x_1, x_2)d {x_2} = 0\\)\nEliminate \\(d {x_1}\\) and \\(d {x_2}\\) to get one condition which characterizes optimal choices for all possible budgets. Combine with the budget constraint to get a second condition.\n\n\n\n\n\n\nTake a penalty function \\(p(x)\\) such that \\(p(x)=K&gt;0\\) if \\(x&gt;0\\) and \\(p(x)=0\\) if \\(x \\leq 0\\). Maximize: \\(V(x_1, x_2) = U(x_1, x_2) - p( p_1 x_1 + p_2 x_2 - B)\\)\nClearly, \\(\\min U \\iff \\min V\\)\nProblem: \\(\\nabla V\\) is always equal to \\(\\nabla U\\).\nSolution: use a smooth solution function like \\(p(x) = x^2\\)\nProblem: distorts optimization\n\nSolution: adjust weight of barrier and minimize \\(U(x_1, x_2) - \\kappa p(x)\\)\n\nPossible but hard to choose the weights/constraints.\n\n\n\n\n\n\nAnother idea: is there a canonical way to choose \\(\\lambda\\) such that at the minimum it is equivalent to minimize the original problem under constraint or to minimize \\[V(x_1, x_2) = U(x_1, x_2) - \\lambda (p_1 x_1 + p_2 x_2 - B)\\]\nClearly, when the constraint is not binding we must have \\(\\lambda=0\\). What should be the value of \\(\\lambda\\) when the constraint is binding ?\n\n\n\n\n\n\nIf \\((x^{\\star},y^{\\star})\\) is optimal there exists \\(\\lambda\\) such that:\n\n\\((x^{\\star},y^{\\star})\\) maximizes \\(U(x_1, x_2) + \\lambda (B- p_1 x_1 - p_2 x_2)\\)\n\\(\\lambda \\geq 0\\)\n\\(B- p_1 x_1 - p_2 x_2 \\geq 0\\)\n\\(\\lambda  (B - p_1 x_1 - p_2 x_2 ) = 0\\)\n\nThe three latest conditions are called “complementarity” or “slackness” conditions\n\nthey are equivalent to \\(\\min(\\lambda, B - p_1 x_1 - p_2 x_2)=0\\)\nwe denote \\(\\lambda \\geq 0 \\perp B- p_1 x_1 + p_2 x_2  \\geq 0\\)\n\n\\(\\lambda\\) can be interpreted as the welfare gain of relaxing the constraint.\n\n\n\n\n\n\nWe can get first order conditions that factor in the constraints:\n\n\\(U^{\\prime}_x - \\lambda p_1 = 0\\)\n\\(U^{\\prime}_y - \\lambda p_2 = 0\\)\n\\(\\lambda \\geq 0 \\perp B-p_1 x_1 -p_2 x_2 \\geq 0\\)\n\nIt is now a nonlinear system of equations with complementarities (NCP)\n\nthere are specific solution methods to deal with it\n\n\n\n\n\n\n\nGeneral formulation for vector-valued functions \\[f(x)\\geq 0 \\perp g(x)\\geq 0\\] means \\[\\forall i, f_i(x)\\geq 0 \\perp g_i(x)\\geq 0\\]\n\nNCP do not necessarily arise from a single optimization problem\n\nThere are robust (commercial) solvers for NCP problems (PATH, Knitro) for that\nHow do we solve it numerically?\n\nassume constraint is binding then non-binding then check which one is good\n\nOK if not too many constraints\n\nreformulate it as a smooth problem\napproximate the system by a series of linear complementarities problems (LCP)"
  },
  {
    "objectID": "slides/optimization copy.html#smooth-method",
    "href": "slides/optimization copy.html#smooth-method",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Consider the Fisher-Burmeister function \\[\\phi(a,b) = a+b-\\sqrt{a^2+b^2}\\]\nIt is infinitely differentiable, except at \\((0,0)\\)\nShow that \\(\\phi(a,b) = 0 \\iff \\min(a,b)=0 \\iff a\\geq 0 \\perp b \\geq 0\\)\nAfter substitution in the original system one can use regular non-linear solver\n\nfun fact: the formulation with a \\(\\min\\) is nonsmooth but also works quite often"
  },
  {
    "objectID": "slides/optimization copy.html#practicalities",
    "href": "slides/optimization copy.html#practicalities",
    "title": "Math topic: Optimization",
    "section": "",
    "text": "Robust optimization code is contained in the following libraries:\n\nRoots.jl: one-dimensional root finding\nNLSolve.jl: multidimensional root finding (+complementarities)\nOptim.jl: minimization\n\nThe two latter libraries have a somewhat peculiar API, but it’s worth absorbing it.\n\nin particular they provide non-alocating algorithms for functions that modify arguments in place\nthey are compatible with automatic differentiation\n\n\njulia&gt; f(x) = [x[1] - x[2] - 1, x[1] + x[2]]\nf (generic function with 1 method)\n\njulia&gt; NLsolve.nlsolve(f, [0., 0.0])\nResults of Nonlinear Solver Algorithm\n * Algorithm: Trust-region with dogleg and autoscaling\n * Starting Point: [0.0, 0.0]\n * Zero: [0.5000000000009869, -0.5000000000009869]\n * Inf-norm of residuals: 0.000000       \n * Iterations: 1                       \n * Convergence: true\n   * |x - x'| &lt; 0.0e+00: false\n   * |f(x)| &lt; 1.0e-08: true                           \n * Function Calls (f): 2\n * Jacobian Calls (df/dx): 2"
  },
  {
    "objectID": "slides/rbc.html",
    "href": "slides/rbc.html",
    "title": "Real Business Cycles, with Dolo",
    "section": "",
    "text": "Like the neo-classical growth model\nWith shocks\nWith labour\nWith a decentralized interpretation\n\n\n\n\n\n\n\nstates:\n\nproductivity: \\(z_t\\)\ncapital: \\(k_t\\)\n\ntwo independent control variables:\n\nconsumption: \\(c_t \\in [0,y_t], c_t\\geq 0, c_t\\leq y_t\\)\nlabor: \\(n_t\\)\n\nshock:\n\ntfp shock: \\(\\epsilon_t \\sim \\mathcal{N}(0,\\sigma)\\)\n\nobjective: \\[\\max_{\\begin{matrix}c_t, n_t\\\\\\\\c_t \\geq 0, y_t \\geq c_t, n_t \\geq 0, 1 \\geq n_t\\end{matrix}} \\mathbb{E}_0 \\left[ \\sum \\beta^t \\left( U(c_t) + \\chi V(1-n_t) \\right) \\right]\\]\nU and V satisfy Inada conditions, ie \\(U^{\\prime}&gt;0, U^{\\prime \\prime}&lt;0, U^{\\prime}(0)=\\infty\\)\n\n\n\n\ndefinitions:\n\nproduction: \\[y_t  = \\exp(z_t) k_t^{\\alpha} n^{1-\\alpha} + i_t\\]\ninvestment: \\[i_t = y_t - c_t\\]\n\ntransitions: \\[\\begin{eqnarray}\nz_t = (1-\\rho) z_{t-1} + \\epsilon_t\\\\\\\\\nk_t = (1-\\delta) k_{t-1} + i_{t-1}\n\\end{eqnarray}\\]\n\n\n\n\n\n\nTwo variables optimization: \\[\\max_{\\begin{matrix}c_1, c_2\\\\\\\\p_1 c_1 + p_2 c_t \\leq B\\end{matrix}} U(c_1, c_2)\\]\nDeterministic opimization (finite horizon) \\[\\max_{\\begin{matrix}c_0, c_1, c_2, ... c_T \\\\\\\\ c_0 + c_1 + \\cdots + c_T \\leq B\\\\\\\\c_0\\geq0, \\cdots c_T \\geq 0 \\end{matrix}} \\sum_{i=1}^{T} \\beta^i U(c_i)\\]\nDeterministic opimization (infinite horizon) \\[\\max_{\\begin{matrix}c_0, c_1, ... \\\\\\\\ c_0 + c_1 + \\cdots \\leq B\\\\\\\\c_0\\geq0, c_1\\geq 0, \\cdots \\end{matrix}} \\sum_{i=1}^{\\infty} \\beta^i U(c_i)\\]\n\n\n\n\n\n\n\n\nexogenous process defines an event tree \\((s)\\)\n\nit is a very useful concept to understand stochastic optimization, complete markets, etc.\nmath for continuous processes a bit involved (filtrations, …), but most intuition can be gained from discrete process\n\n\n\n\n\nhead or tail\n\n\n\n\n\nconsider a discrete process (for instance \\(\\epsilon_t \\in [ \\overline{\\epsilon}, \\underline{\\epsilon}]\\))\n\nan event is defined as the history of the shocks so far\nex: \\((\\overline{\\epsilon} , \\overline{\\epsilon}, \\underline{\\epsilon}, \\overline{\\epsilon})\\)\n\nif \\(s^{\\prime}\\) is the sucessor of \\(s\\) we denote \\(s \\subset s^{\\prime}\\)\n\n\\(s\\) is in the history of \\(s^{\\prime}\\)\ntransition probabilities \\(\\tau(s,s^{\\prime})\\)\n\n\\(1 = \\sum_{s^{\\prime} | s\\subset s^{\\prime}} \\tau(s, s^{\\prime})\\)\n\n\neach node has a given probability \\(p(s)\\). By construction:\n\n\\(p(s^{\\prime}) = p(s) \\tau(s,s^{\\prime})\\)\n\nsometimes, we keep time subscript:\n\nex: \\(s_4 = (\\overline{\\epsilon} , \\overline{\\epsilon}, \\underline{\\epsilon}, \\overline{\\epsilon})\\)\nbut for each \\(t\\) there are many possible \\(s_t\\)\n\n\n\n\n\n\n\n\n\nStochastic optimization (infinite horizon) \\[\\max_{ c_t } \\mathbb{E_0} \\left[ \\sum_{t=1}^{\\infty} \\beta^i U(c_t) \\right]\\]\nWhat it really means (\\(|s|\\) is time of event \\(s\\)) \\[\\max_{ \\forall s,  c(s)} \\sum_{s} p(s) \\beta^{|s|} U(c(s))\\]\nOr: \\[\\max_{ c(s_t) } \\sum_{t}  \\beta^{t} \\sum_{s_t} p(s_t)U(c(s_t))\\]\nThink of it as a regular sum\nWhen you differentiate the lagrangian, you are differentiating w.r.t. all \\(c(s_t)\\), i.e the values of \\(c\\) on each of the nodes.\nExample: cake eating\n\n\n\n\n\n\\[\\max_{\\begin{matrix}c_t, n_t\\\\\\\\c_t \\geq 0\\\\\\\\ y_t \\geq c_t\\\\\\\\n_t \\geq 0\\\\\\\\1 \\geq n_t\\end{matrix}} \\mathbb{E}_0 \\left[ \\sum \\beta^t \\left( U(c_t) + \\chi V(1-n_t) \\right) \\right]\\]\n\nWe know that optimally \\(c_t&gt;0\\), \\(c_t&lt;y_t\\) and \\(n_t&gt;0\\)\n\nequality cases lead to zero production, i.e. infinite marginal utility\n\n\n\n\n\n\n\\[\\max_{\\begin{matrix}c_t, n_t\\\\\\\\c_t \\geq 0\\\\\\\\ k_{t+1} \\geq 0 \\\\\\\\n_t \\geq 0\\\\\\\\1 \\geq n_t \\\\\\\\ y_t \\geq c_t - i_t  \\\\\\\\ k_{t+1} = (1-\\delta) k_t  + i_t \\\\\\\\ y_t = e^{z_t} k_t^{\\alpha} n_t^{1-\\alpha} \\end{matrix}} \\mathbb{E}_0 \\left[ \\sum_t \\beta^t \\left( U(c_t) + \\chi V(1-n_t) \\right) \\right]\\]\n\nWe know that optimally \\(c_t&gt;0\\), and \\(n_t&gt;0\\), \\(k_{t+1}&gt;0\\)\n\nequality cases lead to zero production, i.e. infinite marginal utility\nwe can drop the corresponding constraints\n\nWe assume \\(n_t=1\\) is never binding (this would correspond to unemployment)\n\n\n\n\n\n\\[\\mathcal{L} = \\mathbb{E}\\_0 \\left[ \\sum_t \\beta^t \\left\\\\{ \\begin{matrix} U(c_t) + \\chi V(1-n_t) \\\\\\\\ + \\lambda_t (y_t - c_t) \\\\\\\\  + q_t (k\\_{t+1} - (1-\\delta) k_t - i_{t} ) \\\\\\\\ + \\nu_t (y_t - e^{z_t} k_t^{\\alpha}n_t^{1-\\alpha})  \\end{matrix} \\right\\\\} \\right]\\]\n\nLet’s derive w.r.t. all nonpredetermined values within the sum:\n\n… explain\n\n\n\n\n\n\n\\[\\begin{eqnarray}\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left(\n         (1-\\delta) + \\alpha e^{z\\_{t+1}} k\\_{t+1}^{\\alpha-1} n\\_{t+1}^{1-\\alpha}\n             \\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = &  (1-\\alpha) e^{z_t} k_t^{\\alpha} (n_t)^{-\\alpha} U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\n\n\n\n\nSet \\(U(x) = \\frac{c_t^{1-\\gamma}}{1-\\gamma}\\), \\(V(x) = \\frac{(1-x)^{1-\\eta}}{1-\\eta}\\)\nTry to find the steady state\n\nit is impossible to do so in closed-form\n\nSet \\(\\overline{n} = 0.33\\) and adjust \\(\\chi\\) so that it is a steady-state\n\n\n\n\n\n\n\n\n\nSo far, we have assumed, that the same agent decides on consumption and labour supply\nWhat if some decisions are taken in some decentralized markets?\nNew structure:\n\ndecentralized competitive firms\n\nrent capital and workers\nsell goods\n\na representative household\n\nsupplies labour\naccumulates capital and rents it to firms\nconsume goods\n\n\n\n\n\n\n\n\nFirm \\(i\\)\n\nchooses capital \\(k^i\\) and labour \\(n^i\\)\n\nCobb Douglas production: \\(y_i = f(k_i, n_i) = (k_i)^{\\alpha} (n_i)^(1-\\alpha)\\)\nSince there is only one good, its price can be set to \\(1\\)\nFirm takes wages \\(w\\) and rental price of capital \\(r\\) as given: \\[max_{k_i, n_i} \\pi(k_i, n_i) =  f(k_i, n_i) - r  k_i - w n_i\\]\nOptimally:\n\n\\(f_k^{\\prime}(k_i, n_i) = \\alpha k_i^{\\alpha-1} n_i^{1-\\alpha}  = r\\)\n\\(f_n^{\\prime}(k_i, n_i) = (1-\\alpha) k_i^{\\alpha-1} n_i^{-\\alpha}  = w\\)\n\nRemark:\n\ncapital share: \\(\\frac{r k_i}{y_i} = \\alpha\\)\nlabour share: \\(\\frac{w n_i}{y_i} = 1- \\alpha\\)\nprofits are zero\n\n\n\n\n\n\n\nWhat is the production of all firms if total capital is \\(K\\) and total labour is \\(L\\) ?\nNote that for each firm \\[(1 - \\alpha) \\frac{k_i}{l_i} = \\alpha \\frac{w}{r}\\]\nWe can sum over all firms to get: \\[(1-\\alpha){K} = \\alpha \\frac{w}{r}L\\]\nwe can write: \\[y_i = (k_i)^{\\alpha} (n_i)^{1-\\alpha} = k_i \\left( \\frac{k_i}{n_i} \\right)^{1-\\alpha} = k_i (K/L)^{1-\\alpha}\\]\nand sum over all firms: \\[Y = K (K/L)^{1-\\alpha} = K^\\alpha L ^{1-\\alpha}\\]\nThe sum of many cobb douglas-firms is a big cobb-douglas firm !\n\n\n\n\n\n\nOur representative agent takes \\(w_t\\) and \\(r_t\\) as given.\nHe supplies labour and capital, and decides how much to save so as to maximize: \\[\\max_{\\begin{matrix} c_t, n_t \\\\\\\\ c_t \\leq \\pi_t + r_t k_t + w_t n_t - i_t \\\\\\\\ k_{t+1} = (1-\\delta) k_t + i_t \\\\\\\\ c_t \\geq 0 \\end{matrix}} \\sum_t \\beta^t \\left(U(c_t)  + V(n_t) \\right)\\]\n\nResult: \\[\\begin{eqnarray} \\beta\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left( (1-\\delta) + r_{t+1}\\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = & w_t U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\nResult:\n\nexactly the same equations as in the central planner version (in this case)\nthis formulation can be used to study distortionary taxes:\n\nex: labour income tax \\(\\tau\\)\n\n\n\n\n\n\n\n\nOur representative agent takes \\(w_t\\) and \\(r_t\\) as given.\nHe supplies labour and capital, and decides how much to save so as to maximize: \\[\\max_{\\begin{matrix} c_t, n_t \\\\\\\\ c_t \\leq \\pi_t + (1-\\tau) w_t n_t + r_t k_t - i_t + g_t \\\\\\\\ k_{t+1} = (1-\\delta) k_t + i_t \\\\\\\\ c_t \\geq 0 \\end{matrix}} \\sum_t \\beta^t \\left(U(c_t)  + V(n_t) \\right)\\]\nNote the new budget constraint\n\nlabour income is taxed, but a lump-sum subsidy ensures nothing is destroyed\n\\(g_t =\\tau w_t k_t\\) is not taken into account for intertemporal optimization\n\n\nResult: \\[\\begin{eqnarray} \\beta\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left( (1-\\delta) + r_{t+1}\\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = & (1-\\tau) w_t U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\nResult:\n\nexactly the same equations as in the central planner version (in this case)\nthis formulation can be used to study distortionary taxes:\n\nex: labour income tax \\(\\tau\\)"
  },
  {
    "objectID": "slides/rbc.html#advanced-macro-numerical-methods-2021-mie37",
    "href": "slides/rbc.html#advanced-macro-numerical-methods-2021-mie37",
    "title": "Real Business Cycles, with Dolo",
    "section": "",
    "text": "Like the neo-classical growth model\nWith shocks\nWith labour\nWith a decentralized interpretation\n\n\n\n\n\n\n\nstates:\n\nproductivity: \\(z_t\\)\ncapital: \\(k_t\\)\n\ntwo independent control variables:\n\nconsumption: \\(c_t \\in [0,y_t], c_t\\geq 0, c_t\\leq y_t\\)\nlabor: \\(n_t\\)\n\nshock:\n\ntfp shock: \\(\\epsilon_t \\sim \\mathcal{N}(0,\\sigma)\\)\n\nobjective: \\[\\max_{\\begin{matrix}c_t, n_t\\\\\\\\c_t \\geq 0, y_t \\geq c_t, n_t \\geq 0, 1 \\geq n_t\\end{matrix}} \\mathbb{E}_0 \\left[ \\sum \\beta^t \\left( U(c_t) + \\chi V(1-n_t) \\right) \\right]\\]\nU and V satisfy Inada conditions, ie \\(U^{\\prime}&gt;0, U^{\\prime \\prime}&lt;0, U^{\\prime}(0)=\\infty\\)\n\n\n\n\ndefinitions:\n\nproduction: \\[y_t  = \\exp(z_t) k_t^{\\alpha} n^{1-\\alpha} + i_t\\]\ninvestment: \\[i_t = y_t - c_t\\]\n\ntransitions: \\[\\begin{eqnarray}\nz_t = (1-\\rho) z_{t-1} + \\epsilon_t\\\\\\\\\nk_t = (1-\\delta) k_{t-1} + i_{t-1}\n\\end{eqnarray}\\]\n\n\n\n\n\n\nTwo variables optimization: \\[\\max_{\\begin{matrix}c_1, c_2\\\\\\\\p_1 c_1 + p_2 c_t \\leq B\\end{matrix}} U(c_1, c_2)\\]\nDeterministic opimization (finite horizon) \\[\\max_{\\begin{matrix}c_0, c_1, c_2, ... c_T \\\\\\\\ c_0 + c_1 + \\cdots + c_T \\leq B\\\\\\\\c_0\\geq0, \\cdots c_T \\geq 0 \\end{matrix}} \\sum_{i=1}^{T} \\beta^i U(c_i)\\]\nDeterministic opimization (infinite horizon) \\[\\max_{\\begin{matrix}c_0, c_1, ... \\\\\\\\ c_0 + c_1 + \\cdots \\leq B\\\\\\\\c_0\\geq0, c_1\\geq 0, \\cdots \\end{matrix}} \\sum_{i=1}^{\\infty} \\beta^i U(c_i)\\]\n\n\n\n\n\n\n\n\nexogenous process defines an event tree \\((s)\\)\n\nit is a very useful concept to understand stochastic optimization, complete markets, etc.\nmath for continuous processes a bit involved (filtrations, …), but most intuition can be gained from discrete process\n\n\n\n\n\nhead or tail\n\n\n\n\n\nconsider a discrete process (for instance \\(\\epsilon_t \\in [ \\overline{\\epsilon}, \\underline{\\epsilon}]\\))\n\nan event is defined as the history of the shocks so far\nex: \\((\\overline{\\epsilon} , \\overline{\\epsilon}, \\underline{\\epsilon}, \\overline{\\epsilon})\\)\n\nif \\(s^{\\prime}\\) is the sucessor of \\(s\\) we denote \\(s \\subset s^{\\prime}\\)\n\n\\(s\\) is in the history of \\(s^{\\prime}\\)\ntransition probabilities \\(\\tau(s,s^{\\prime})\\)\n\n\\(1 = \\sum_{s^{\\prime} | s\\subset s^{\\prime}} \\tau(s, s^{\\prime})\\)\n\n\neach node has a given probability \\(p(s)\\). By construction:\n\n\\(p(s^{\\prime}) = p(s) \\tau(s,s^{\\prime})\\)\n\nsometimes, we keep time subscript:\n\nex: \\(s_4 = (\\overline{\\epsilon} , \\overline{\\epsilon}, \\underline{\\epsilon}, \\overline{\\epsilon})\\)\nbut for each \\(t\\) there are many possible \\(s_t\\)\n\n\n\n\n\n\n\n\n\nStochastic optimization (infinite horizon) \\[\\max_{ c_t } \\mathbb{E_0} \\left[ \\sum_{t=1}^{\\infty} \\beta^i U(c_t) \\right]\\]\nWhat it really means (\\(|s|\\) is time of event \\(s\\)) \\[\\max_{ \\forall s,  c(s)} \\sum_{s} p(s) \\beta^{|s|} U(c(s))\\]\nOr: \\[\\max_{ c(s_t) } \\sum_{t}  \\beta^{t} \\sum_{s_t} p(s_t)U(c(s_t))\\]\nThink of it as a regular sum\nWhen you differentiate the lagrangian, you are differentiating w.r.t. all \\(c(s_t)\\), i.e the values of \\(c\\) on each of the nodes.\nExample: cake eating\n\n\n\n\n\n\\[\\max_{\\begin{matrix}c_t, n_t\\\\\\\\c_t \\geq 0\\\\\\\\ y_t \\geq c_t\\\\\\\\n_t \\geq 0\\\\\\\\1 \\geq n_t\\end{matrix}} \\mathbb{E}_0 \\left[ \\sum \\beta^t \\left( U(c_t) + \\chi V(1-n_t) \\right) \\right]\\]\n\nWe know that optimally \\(c_t&gt;0\\), \\(c_t&lt;y_t\\) and \\(n_t&gt;0\\)\n\nequality cases lead to zero production, i.e. infinite marginal utility\n\n\n\n\n\n\n\\[\\max_{\\begin{matrix}c_t, n_t\\\\\\\\c_t \\geq 0\\\\\\\\ k_{t+1} \\geq 0 \\\\\\\\n_t \\geq 0\\\\\\\\1 \\geq n_t \\\\\\\\ y_t \\geq c_t - i_t  \\\\\\\\ k_{t+1} = (1-\\delta) k_t  + i_t \\\\\\\\ y_t = e^{z_t} k_t^{\\alpha} n_t^{1-\\alpha} \\end{matrix}} \\mathbb{E}_0 \\left[ \\sum_t \\beta^t \\left( U(c_t) + \\chi V(1-n_t) \\right) \\right]\\]\n\nWe know that optimally \\(c_t&gt;0\\), and \\(n_t&gt;0\\), \\(k_{t+1}&gt;0\\)\n\nequality cases lead to zero production, i.e. infinite marginal utility\nwe can drop the corresponding constraints\n\nWe assume \\(n_t=1\\) is never binding (this would correspond to unemployment)\n\n\n\n\n\n\\[\\mathcal{L} = \\mathbb{E}\\_0 \\left[ \\sum_t \\beta^t \\left\\\\{ \\begin{matrix} U(c_t) + \\chi V(1-n_t) \\\\\\\\ + \\lambda_t (y_t - c_t) \\\\\\\\  + q_t (k\\_{t+1} - (1-\\delta) k_t - i_{t} ) \\\\\\\\ + \\nu_t (y_t - e^{z_t} k_t^{\\alpha}n_t^{1-\\alpha})  \\end{matrix} \\right\\\\} \\right]\\]\n\nLet’s derive w.r.t. all nonpredetermined values within the sum:\n\n… explain\n\n\n\n\n\n\n\\[\\begin{eqnarray}\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left(\n         (1-\\delta) + \\alpha e^{z\\_{t+1}} k\\_{t+1}^{\\alpha-1} n\\_{t+1}^{1-\\alpha}\n             \\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = &  (1-\\alpha) e^{z_t} k_t^{\\alpha} (n_t)^{-\\alpha} U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\n\n\n\n\nSet \\(U(x) = \\frac{c_t^{1-\\gamma}}{1-\\gamma}\\), \\(V(x) = \\frac{(1-x)^{1-\\eta}}{1-\\eta}\\)\nTry to find the steady state\n\nit is impossible to do so in closed-form\n\nSet \\(\\overline{n} = 0.33\\) and adjust \\(\\chi\\) so that it is a steady-state\n\n\n\n\n\n\n\n\n\nSo far, we have assumed, that the same agent decides on consumption and labour supply\nWhat if some decisions are taken in some decentralized markets?\nNew structure:\n\ndecentralized competitive firms\n\nrent capital and workers\nsell goods\n\na representative household\n\nsupplies labour\naccumulates capital and rents it to firms\nconsume goods\n\n\n\n\n\n\n\n\nFirm \\(i\\)\n\nchooses capital \\(k^i\\) and labour \\(n^i\\)\n\nCobb Douglas production: \\(y_i = f(k_i, n_i) = (k_i)^{\\alpha} (n_i)^(1-\\alpha)\\)\nSince there is only one good, its price can be set to \\(1\\)\nFirm takes wages \\(w\\) and rental price of capital \\(r\\) as given: \\[max_{k_i, n_i} \\pi(k_i, n_i) =  f(k_i, n_i) - r  k_i - w n_i\\]\nOptimally:\n\n\\(f_k^{\\prime}(k_i, n_i) = \\alpha k_i^{\\alpha-1} n_i^{1-\\alpha}  = r\\)\n\\(f_n^{\\prime}(k_i, n_i) = (1-\\alpha) k_i^{\\alpha-1} n_i^{-\\alpha}  = w\\)\n\nRemark:\n\ncapital share: \\(\\frac{r k_i}{y_i} = \\alpha\\)\nlabour share: \\(\\frac{w n_i}{y_i} = 1- \\alpha\\)\nprofits are zero\n\n\n\n\n\n\n\nWhat is the production of all firms if total capital is \\(K\\) and total labour is \\(L\\) ?\nNote that for each firm \\[(1 - \\alpha) \\frac{k_i}{l_i} = \\alpha \\frac{w}{r}\\]\nWe can sum over all firms to get: \\[(1-\\alpha){K} = \\alpha \\frac{w}{r}L\\]\nwe can write: \\[y_i = (k_i)^{\\alpha} (n_i)^{1-\\alpha} = k_i \\left( \\frac{k_i}{n_i} \\right)^{1-\\alpha} = k_i (K/L)^{1-\\alpha}\\]\nand sum over all firms: \\[Y = K (K/L)^{1-\\alpha} = K^\\alpha L ^{1-\\alpha}\\]\nThe sum of many cobb douglas-firms is a big cobb-douglas firm !\n\n\n\n\n\n\nOur representative agent takes \\(w_t\\) and \\(r_t\\) as given.\nHe supplies labour and capital, and decides how much to save so as to maximize: \\[\\max_{\\begin{matrix} c_t, n_t \\\\\\\\ c_t \\leq \\pi_t + r_t k_t + w_t n_t - i_t \\\\\\\\ k_{t+1} = (1-\\delta) k_t + i_t \\\\\\\\ c_t \\geq 0 \\end{matrix}} \\sum_t \\beta^t \\left(U(c_t)  + V(n_t) \\right)\\]\n\nResult: \\[\\begin{eqnarray} \\beta\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left( (1-\\delta) + r_{t+1}\\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = & w_t U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\nResult:\n\nexactly the same equations as in the central planner version (in this case)\nthis formulation can be used to study distortionary taxes:\n\nex: labour income tax \\(\\tau\\)\n\n\n\n\n\n\n\n\nOur representative agent takes \\(w_t\\) and \\(r_t\\) as given.\nHe supplies labour and capital, and decides how much to save so as to maximize: \\[\\max_{\\begin{matrix} c_t, n_t \\\\\\\\ c_t \\leq \\pi_t + (1-\\tau) w_t n_t + r_t k_t - i_t + g_t \\\\\\\\ k_{t+1} = (1-\\delta) k_t + i_t \\\\\\\\ c_t \\geq 0 \\end{matrix}} \\sum_t \\beta^t \\left(U(c_t)  + V(n_t) \\right)\\]\nNote the new budget constraint\n\nlabour income is taxed, but a lump-sum subsidy ensures nothing is destroyed\n\\(g_t =\\tau w_t k_t\\) is not taken into account for intertemporal optimization\n\n\nResult: \\[\\begin{eqnarray} \\beta\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left( (1-\\delta) + r_{t+1}\\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = & (1-\\tau) w_t U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\nResult:\n\nexactly the same equations as in the central planner version (in this case)\nthis formulation can be used to study distortionary taxes:\n\nex: labour income tax \\(\\tau\\)"
  },
  {
    "objectID": "slides/rbc.html#the-decentralized-story",
    "href": "slides/rbc.html#the-decentralized-story",
    "title": "Real Business Cycles, with Dolo",
    "section": "",
    "text": "So far, we have assumed, that the same agent decides on consumption and labour supply\nWhat if some decisions are taken in some decentralized markets?\nNew structure:\n\ndecentralized competitive firms\n\nrent capital and workers\nsell goods\n\na representative household\n\nsupplies labour\naccumulates capital and rents it to firms\nconsume goods\n\n\n\n\n\n\n\n\nFirm \\(i\\)\n\nchooses capital \\(k^i\\) and labour \\(n^i\\)\n\nCobb Douglas production: \\(y_i = f(k_i, n_i) = (k_i)^{\\alpha} (n_i)^(1-\\alpha)\\)\nSince there is only one good, its price can be set to \\(1\\)\nFirm takes wages \\(w\\) and rental price of capital \\(r\\) as given: \\[max_{k_i, n_i} \\pi(k_i, n_i) =  f(k_i, n_i) - r  k_i - w n_i\\]\nOptimally:\n\n\\(f_k^{\\prime}(k_i, n_i) = \\alpha k_i^{\\alpha-1} n_i^{1-\\alpha}  = r\\)\n\\(f_n^{\\prime}(k_i, n_i) = (1-\\alpha) k_i^{\\alpha-1} n_i^{-\\alpha}  = w\\)\n\nRemark:\n\ncapital share: \\(\\frac{r k_i}{y_i} = \\alpha\\)\nlabour share: \\(\\frac{w n_i}{y_i} = 1- \\alpha\\)\nprofits are zero\n\n\n\n\n\n\n\nWhat is the production of all firms if total capital is \\(K\\) and total labour is \\(L\\) ?\nNote that for each firm \\[(1 - \\alpha) \\frac{k_i}{l_i} = \\alpha \\frac{w}{r}\\]\nWe can sum over all firms to get: \\[(1-\\alpha){K} = \\alpha \\frac{w}{r}L\\]\nwe can write: \\[y_i = (k_i)^{\\alpha} (n_i)^{1-\\alpha} = k_i \\left( \\frac{k_i}{n_i} \\right)^{1-\\alpha} = k_i (K/L)^{1-\\alpha}\\]\nand sum over all firms: \\[Y = K (K/L)^{1-\\alpha} = K^\\alpha L ^{1-\\alpha}\\]\nThe sum of many cobb douglas-firms is a big cobb-douglas firm !\n\n\n\n\n\n\nOur representative agent takes \\(w_t\\) and \\(r_t\\) as given.\nHe supplies labour and capital, and decides how much to save so as to maximize: \\[\\max_{\\begin{matrix} c_t, n_t \\\\\\\\ c_t \\leq \\pi_t + r_t k_t + w_t n_t - i_t \\\\\\\\ k_{t+1} = (1-\\delta) k_t + i_t \\\\\\\\ c_t \\geq 0 \\end{matrix}} \\sum_t \\beta^t \\left(U(c_t)  + V(n_t) \\right)\\]\n\nResult: \\[\\begin{eqnarray} \\beta\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left( (1-\\delta) + r_{t+1}\\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = & w_t U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\nResult:\n\nexactly the same equations as in the central planner version (in this case)\nthis formulation can be used to study distortionary taxes:\n\nex: labour income tax \\(\\tau\\)\n\n\n\n\n\n\n\n\nOur representative agent takes \\(w_t\\) and \\(r_t\\) as given.\nHe supplies labour and capital, and decides how much to save so as to maximize: \\[\\max_{\\begin{matrix} c_t, n_t \\\\\\\\ c_t \\leq \\pi_t + (1-\\tau) w_t n_t + r_t k_t - i_t + g_t \\\\\\\\ k_{t+1} = (1-\\delta) k_t + i_t \\\\\\\\ c_t \\geq 0 \\end{matrix}} \\sum_t \\beta^t \\left(U(c_t)  + V(n_t) \\right)\\]\nNote the new budget constraint\n\nlabour income is taxed, but a lump-sum subsidy ensures nothing is destroyed\n\\(g_t =\\tau w_t k_t\\) is not taken into account for intertemporal optimization\n\n\nResult: \\[\\begin{eqnarray} \\beta\nU^{\\prime}(c_t) & = & \\beta \\mathbb{E}\\_t \\left[  U^{\\prime} (c_{t+1}) \\left( (1-\\delta) + r_{t+1}\\right) \\right] \\\\\\\\\n\\chi V^{\\prime} (1-n_t) & = & (1-\\tau) w_t U^{\\prime}(c_t)\n\\end{eqnarray}\\]\n\nResult:\n\nexactly the same equations as in the central planner version (in this case)\nthis formulation can be used to study distortionary taxes:\n\nex: labour income tax \\(\\tau\\)"
  },
  {
    "objectID": "tutorials/1_Julia_Basics_correction.html",
    "href": "tutorials/1_Julia_Basics_correction.html",
    "title": "Julia Basics",
    "section": "",
    "text": "developped at MIT on top of opensource technologies\n\nlinux / git / llvm\n\nsyntax inspired by Matlab but:\n\nmore consistent\nlots of features from high level languages\n\neverything is JIT-compiled\n\ninterpreted vs compiled treadeoff\n-&gt; very fast\nmost of the base library is written in Julia\n\nopensource/free + vibrant community\n\nSome useful links from QuantEcon:\n\nJulia cheatsheet\nJulia-Matlab comparison\nJulia essentials\nVectors, arrays and matrices\n\nExcellent resources at: julialang - checkout JuliaAcademy, it’s free - ongoing MOOC at MIT"
  },
  {
    "objectID": "tutorials/1_Julia_Basics_correction.html#additional-exercises",
    "href": "tutorials/1_Julia_Basics_correction.html#additional-exercises",
    "title": "Julia Basics",
    "section": "Additional Exercises",
    "text": "Additional Exercises\nTaken from QuantEcon’s Julia Essentials and Vectors, Arrays, and Matrices lectures.\n\nConsider the polynomial \\[p(x) = \\sum_{i=0}^n a_0 x^0\\] Using enumerate, write a function p such that p(x, coeff) computes the value of the polynomial with coefficients coeff evaluated at x.\n\n\n\n\nppp (generic function with 1 method)\n\n\n\nWrite a function solve_discrete_lyapunov that solves the discrete Lyapunov equation \\[S = ASA' + \\Sigma \\Sigma'\\] using the iterative procedure \\[S_0 = \\Sigma \\Sigma'\\] \\[S_{t+1} = A S_t A' + \\Sigma \\Sigma'\\] taking in as arguments the \\(n \\times n\\) matrix \\(A\\), the \\(n \\times k\\) matrix \\(\\Sigma\\), and a number of iterations."
  },
  {
    "objectID": "tutorials/2_solow.html",
    "href": "tutorials/2_solow.html",
    "title": "Convergence of Sequences",
    "section": "",
    "text": "Tutorial: Convergence\n\nSolow Model\nA representative agent uses capital \\(k_t\\) to produce \\(y_t\\) using the following production function:\n\\[y_t = k_t^{\\alpha}\\]\nHe chooses to consume an amount \\(c_t \\in ]0, y_t]\\) and invests what remains:\n\\[i_t = y_t - c_t\\]\nHe accumulates capital \\(k_t\\) according to:\n\\[k_{t+1} = \\left( 1-\\delta \\right) k_{t} + i_{t}\\]\nwhere \\(\\delta\\) is the depreciation rate and \\(i_t\\) is the amount invested.\nThe goal of the representative agent is to maximize:\n\\[\\sum_{t\\geq 0} \\beta^t U(c_t)\\]\nwhere \\(U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}\\) and \\(\\beta&lt;1\\) is the discount factor.\nFor now, we ignore the objective and assume that the saving rate \\(s=\\frac{c_t}{y_t}\\) is constant over time.\nCreate a NamedTuple to hold parameter values \\(\\beta=0.96\\), \\(\\delta=0.1\\), \\(\\alpha=0.3\\), \\(\\gamma=4\\).\n\nα = 0.3\nβ = 0.96\nγ = 4.0\nδ = 0.1\ns = 0.2\n\n0.91\n\n\n\nstruct SolowModel\n    α::Float64\n    β::Float64\n    γ::Float64\n    δ::Float64\nend\n\n\nsm = SolowModel(\n0.3::Float64,\n0.96::Float64,\n4.0::Float64,\n0.1::Float64,\n)\n\nUndefVarError: UndefVarError: `T` not defined in `Main`\nSuggestion: check for spelling errors or missing imports.\nUndefVarError: `T` not defined in `Main`\n\nSuggestion: check for spelling errors or missing imports.\n\n\n\nStacktrace:\n\n [1] top-level scope\n\n   @ ~/Teaching/ensae/mie37/tutorials/jl_notebook_cell_df34fa98e69747e1a8f8a730347b8e2f_W5sZmlsZQ==.jl:1\n\n\n\n# dictionary (symbol=&gt;float)\nd = Dict(\n    :α =&gt; 0.3,\n    :β =&gt; 0.96,\n    :γ =&gt; 4.0,\n    :δ =&gt; 0.1\n)\n\nDict{Symbol, Float64} with 4 entries:\n  :α =&gt; 0.3\n  :γ =&gt; 4.0\n  :δ =&gt; 0.1\n  :β =&gt; 0.96\n\n\n\nd[:α]\n\n0.3\n\n\n\n# namedtuple\n\nmodel = (; α=0.3, β=0.96, γ=4.0, δ=0.1, s=0.2)\n\n(α = 0.3, β = 0.96, γ = 4.0, δ = 0.1, s = 0.2)\n\n\n\n#unpack values with keywords\nα = model.α\nβ = model.β\n\n(;α,β) = model\n\n(α = 0.3, β = 0.96, γ = 4.0, δ = 0.1)\n\n\nWrite down the formula of function \\(f\\) such that \\(k_{t+1}\\): \\(k_{t+1} = f(k_t)\\).\nDefine a function f(k::Float64, p::NamedTuple)::Float64 to represent \\(f\\) for a given calibration\n\n# add saving rate\nfunction f(k,p)\n    \n    (;α, β, γ, δ, s) = p\n\n    # production\n\n    y = k^α\n    i = s*y\n\n    K = (1-δ)*k  + i\n\n    return K\nend\n\nf (generic function with 2 methods)\n\n\n\n@time f(2.0, model)\n\n  0.000011 seconds (1 allocation: 16 bytes)\n\n\n2.0462288826689834\n\n\nWrite a function simulate(k0::Float64, T::Int, p::NamedTuple)::Vector{Float64} to compute the simulation over T periods starting from initial capital level k0.\n\nfunction simulate(k0, T, p)\n\n    res = [k0]\n    for t=1:T\n        k = res[end]\n        K = f(k, p)\n        push!(res, K)\n    end\n    return res\nend\n\nsimulate (generic function with 1 method)\n\n\n\nT = 50\nres = simulate(2.0, T, model)\n\n51-element Vector{Float64}:\n 2.0\n 2.0462288826689834\n 2.089528674917447\n 2.1300608401704926\n 2.167981873889157\n 2.2034426980783923\n 2.236588248806851\n 2.2675572178060395\n 2.2964819166036654\n 2.323488237574935\n ⋮\n 2.6574948869350297\n 2.659891647730072\n 2.662121260861985\n 2.6641953419773485\n 2.6661247051029044\n 2.667919417201969\n 2.6695888491235507\n 2.6711417231678323\n 2.6725861574799716\n\n\nMake a nice plot to illustrate the convergence. Do we get convergence from any initial level of capital?\n\nusing Plots   # all exported functions become available including `plot``\n\n\nimport Plots\nPlots.dosomething\n\n\ntvec = 0:T\nplot(tvec, res; title=\"Solow Model\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# make the plot with different capital levels\nT = 80\nres_1 = simulate(1.0, T, model)\nres_2 = simulate(2.0, T, model)\nres_3 = simulate(3.0, T, model);\n\n\ntvec = 0:T\npl = plot(tvec, res_1; title=\"Solow Model\", label=\"\\$k_0=1.0\\$\");\nplot!(pl, tvec, res_2; label=\"\\$k_0=2.0\\$\");\nplot!(pl, tvec, res_3; label=\"\\$k_0=3.0\\$\");\npl\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# what about other value of svaing rates ?\nres_1 = simulate(2.0, T, merge(model, (;s=0.1)))\nres_2 = simulate(2.0, T, merge(model, (;s=0.2)))\nres_3 = simulate(2.0, T, merge(model, (;s=0.3)));\npl = plot(tvec, res_1; title=\"Solow Model\", label=\"\\$s=1.0\\$\", xlabel=\"\\$t\\$\");\nplot!(pl, tvec, res_2; label=\"\\$s=2.0\\$\");\nplot!(pl, tvec, res_3; label=\"\\$s=3.0\\$\");\npl\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSuppose you were interested in using f to compute the steady-state. What would you propose to measure convergence speed? To speed-up convergence? Implement these ideas.",
    "crumbs": [
      "Tutorials",
      "Convergence of Sequences"
    ]
  },
  {
    "objectID": "tutorials/1_epidemiology.html",
    "href": "tutorials/1_epidemiology.html",
    "title": "Epidemiology Models",
    "section": "",
    "text": "H.W. Heathcote: epidemiologic models are deterministic models for infectious diseases which are spread by direct person-to-person contact in a population.\nThis kind of models has been used since by a few decades by economist, for matters that have nothing to do with health.\n\ndiffusion of information, or opinions on social medias\nasset prices and fads\nexpectation formation for macroeconomic outcomes (ex: The Epidemiology of Macroeconomic Expectations by Chris Carroll)\n\nEpidemiologic models have two features that depart from standard economic models:\n\nAgent’s behaviour does not take the full system into account, an is irrational in the sense that it isn’t forward looking. Instead, an agent is given a behavioural heuristic.\nThe transitions of the whole system can be determined without solving for complex interactions first.\n\nUnderstanding why these two assumptions are very costly for economists will keep us busy during a big part of the course. Here we just consider two simple models as small programming exercises.\n\nSimple SIR model\nThere is a continuum of agents of mass \\(1\\). Each agent can be either “Susceptible” (S), “Infected” (I) or “Recovered” (R). In each period, one agent meets another agent drawn randomly. During a meeting Susceptible agents who meet an infected agent, will always catch the disease (or the fad) but are not contagious. Infected agents, have a probability \\(\\pi\\) of being recovered. Nothing happens to Recovered agents who meet other people. No distinction is made between recovering as a healthy or a dead person.\nWe’re interested in the evolution in the number infected persons, both the speed of infection and the total amount of infected people in every period.\nWrite down the transition equations for \\(n_I\\), the number of infected people, for \\(n_R\\) the number of recovered people and \\(n_S\\) the number of susceptible people.\nCompute the transition function f for the vector state \\(s_t\\) returning \\(s_{t+1}\\).\nCompute the transitions over \\(T\\) periods. Plot the result using Plots.jl. (bonus: check against closed form solution)\nWe now assume a Susceptible person who meets an infected one has a probability \\(\\mu\\) of catching the disease. Update the transition function. Update function \\(f\\) and write a function of \\(\\mu\\), \\(\\pi\\) which returns the simulation. Compare different values of the parameters. How would you interpret “social distancing”? How would you choose parameters \\(\\Pi\\) and \\(\\mu\\)\n\n\nA Spatial SIR model\nWe now consider another version of the model where agents evolve in the space \\(\\mathcal{S}=[0,1]\\times[0,1]\\). There are \\(N\\in\\mathbb{N}\\) agent. At any date, each agent \\(n \\in [0,1]\\) is located at \\((x_n,y_n)\\in \\mathcal{S}\\).\nEach agent moves follows a random walk bounded by \\(\\mathcal{S}\\): \\[x_t = \\min(\\max( x_{t-1} + \\epsilon_t, 0), 1)\\] \\[y_t = \\min(\\max( y_{t-1} + \\eta_t, 0), 1)\\] where \\(\\epsilon_t\\) and \\(\\eta_t\\) are both normally distributed with standard deviation \\(\\sigma\\).\nAt any date, the individual state of an agent is \\(s_t=(x_t, y_t, h_t)\\) where \\(h_t\\) is either “S”, “I” or “R”. \\(v_t\\) denotes the states of all agents (for instance \\(v_t=(s_{n,t})_n\\). The health status of each agent is updated in the following way:\n\nAgents \\(R\\) stay \\(R\\).\nAgents \\(I\\) have probability \\(\\pi\\) to become \\(R\\). They stay \\(I\\) otherwise.\nAn agent of type \\(S\\) in position \\((x,y)\\) has a probability \\(prob(x,y,S)\\) to be infected that is \\(\\mu\\) if there is another infected agent within a radius \\(r&gt;0\\).\n\nDefine a type Agent, which holds the type of an agent. The state of the whole system will be held in a Vector[Agent] type.\nWrite a function spatial_transition(S::Vector{Agent})::Vector{Agent} to compute the transition of the positions. Write another function random_guess(T=100) which simulates for \\(T\\) periods in order to find a good initial guess.\nWrite a function show_population to plot all agents with different colors for different health status.\nWrite a function evolve(S::Vector[Agent])::Vector[Agent] which takes the population in a given state and returns the same population with updated health status.\nWrite a function simulate(S0::Vector[Agent], k=1) to simulate the economy starting from an initially random position with k infected individuals. The returned object should be of type Vector[Vector[Agent]].\nCompute statistics along a simulated path for \\(n_I\\), \\(n_S\\), \\(n_R\\). Plot and compare with the basic SIR model\n\n\nAdditional questions\nHave fun by trying to answer one of these questions: - change probability of infection so that it depends on the number of infected people in the vincinity (with some suitable functional formulation for) - compute an animation of the transition - compute an interactive visualisation (with Interact.jl if available)",
    "crumbs": [
      "Tutorials",
      "Epidemiology Models"
    ]
  },
  {
    "objectID": "tutorials/4_Optimization.html",
    "href": "tutorials/4_Optimization.html",
    "title": "Optimization",
    "section": "",
    "text": "In this tutorial you will learn to code and use common optimization algorithms for static models.",
    "crumbs": [
      "Tutorials",
      "Optimization"
    ]
  },
  {
    "objectID": "tutorials/4_Optimization.html#computational-economics-mie37",
    "href": "tutorials/4_Optimization.html#computational-economics-mie37",
    "title": "Optimization",
    "section": "",
    "text": "In this tutorial you will learn to code and use common optimization algorithms for static models.",
    "crumbs": [
      "Tutorials",
      "Optimization"
    ]
  },
  {
    "objectID": "tutorials/4_Optimization.html#profit-optimization-by-a-monopolist",
    "href": "tutorials/4_Optimization.html#profit-optimization-by-a-monopolist",
    "title": "Optimization",
    "section": "Profit optimization by a monopolist",
    "text": "Profit optimization by a monopolist\nA monopolist produces quantity \\(q\\) of goods X at price \\(p\\). Its cost function is \\(c(q) = 0.5 + q (1-qe^{-q})\\)\nThe consumer’s demand for price \\(p\\) is \\(x(p)=2 e^{-0.5 p}\\) (constant elasticity of demand to price).\nWrite down the profit function of the monopolist and find the optimal production (if any). Don’t use any library except for plotting.\n\n# c(q) = 2exp(-0.5q)\nc(q) = 0.5 + q*(1-q*exp(-q))\np(q) = -2(log(q)-log(2))\nπ(q) = q*p(q) - c(q)\n\nπ (generic function with 1 method)\n\n\n\nusing Plots\n\n\nqvec = range(0.0001,3; length=100)\n# πvec = [π(e) for e in qvec]\nπvec = π.(qvec);\n\n\nplot(qvec, πvec)\nplot!(qvec, qvec*0)\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfunction grid_search(f, a, b, N)\n    # looks for the optimal on N+1 points grid\n    i0 = -1 # keeps index of the optimal\n    f0 = -10000\n    for n = 1:N\n        xi = a + (b-a)*(n-1)/(N-1)\n        fi = f(xi)\n        if fi&gt;f0\n            f0 = fi\n            i0 = n\n        end\n    end\n\n    η = (b-a)/N\n    #return optimal x\n    return a + (b-a)*(i0-1)/(N-1)\nend\n\ngrid_search (generic function with 1 method)\n\n\n\nres =  grid_search(π, 0.00001, 2, 10000)\n\n0.5618633763376337\n\n\n\nplot(qvec, πvec; label=\"Profit\", title=\"Profit Maximization\")\nplot!(qvec, qvec*0; label=\"\", linestyle=:dash)\nscatter!([res], [π(res)]; label=\"Optimal\")\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfun(u) = 1-(u-1)^2\n\nfun (generic function with 1 method)\n\n\n\ngrid_search(fun, -2, 2, 10000)\n\n0.9998999899989998\n\n\n\nfindmax( [fun(e) for e in range(-2,2; length=1000)])\n\n(0.999998997996996, 750)\n\n\n\n# # let's implement the grid search algorithm\n\n# function bisection(f, a, b; η=1e-8, ϵ=1e-10)\n\n#     N = log((b-a)/η)/log(2)\n\n#     a0, b0 = a, b\n\n#     for n=1:N\n\n#         fa = f(a0)\n#         fb = f(a0)\n\n#         @assert fa*fb&lt;=0\n\n#         c = (a0 + b0)/2\n\n#         fc = f(c)\n#         if abs(fc)&lt;ϵ\n#             return c\n#         end\n\n#         if fc*fa&lt;=0\n#             # solution must be in [a0,c]\n#             b0 = c\n#         else\n#             # solution must be in [c,b0]\n#             a0 = c\n#         end\n        \n#     end\n\n#     error(\"No solution was found\")\n\n# end\n\nbisection (generic function with 1 method)",
    "crumbs": [
      "Tutorials",
      "Optimization"
    ]
  },
  {
    "objectID": "tutorials/4_Optimization.html#constrained-optimization",
    "href": "tutorials/4_Optimization.html#constrained-optimization",
    "title": "Optimization",
    "section": "Constrained optimization",
    "text": "Constrained optimization\nConsider the function \\(f(x,y) = 1-(x-0.5)^2 -(y-0.3)^2\\).\nUse Optim.jl to maximize \\(f\\) without constraint. Check you understand diagnostic information returned by the optimizer.\n\nusing Optim\n\n\nf(x,y) = 1-(x-0.5)^2 - (y-0.3)^2\n# f(u) = f(u[1], u[2])\nf(u::AbstractVector) = f(u...)\n\nf (generic function with 3 methods)\n\n\n\nres = Optim.optimize(\n    u-&gt;-f(u),\n    [0.1,0.3]\n)\n\n * Status: success\n\n * Candidate solution\n    Final objective value:     -1.000000e+00\n\n * Found with\n    Algorithm:     Nelder-Mead\n\n * Convergence measures\n    √(Σ(yᵢ-ȳ)²)/n ≤ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    28\n    f(x) calls:    58\n\n\n\nres.minimizer # the solution\n\n2-element Vector{Float64}:\n 0.5000402081311677\n 0.3000018404381079\n\n\n\nres.x_converged\n\nfalse\n\n\n\nfieldnames(typeof(res))\n\n(:method, :initial_x, :minimizer, :minimum, :iterations, :iteration_converged, :x_converged, :x_abstol, :x_reltol, :x_abschange, :x_relchange, :f_converged, :f_abstol, :f_reltol, :f_abschange, :f_relchange, :g_converged, :g_abstol, :g_residual, :f_increased, :trace, :f_calls, :g_calls, :h_calls, :ls_success, :time_limit, :time_run, :stopped_by)\n\n\n\nusing Plots\ncontour(\n    range(0,1; length=100),\n    range(0,1; length=100),\n    f\n)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNow, consider the constraint \\(x&lt;0.3\\) and maximize \\(f\\) under this new constraint.\n\n# with a penalty function\n\nκ = 100\n\nφ(x) = x[1]&lt;0.3 ? 0.0 : x[1]^2\n# equivalaent to \n# if x[1]&lt;0.3\n#     0.0\n# else\n#     -x[1]^2\n\ng(x) = f(x) - κ*φ(x)\n\ng (generic function with 1 method)\n\n\n\nres = Optim.optimize(\n    u-&gt;-f(u) + κ*φ(u),\n    [0.1,0.3]\n)\n\n * Status: success\n\n * Candidate solution\n    Final objective value:     -9.600000e-01\n\n * Found with\n    Algorithm:     Nelder-Mead\n\n * Convergence measures\n    √(Σ(yᵢ-ȳ)²)/n ≤ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    69\n    f(x) calls:    134\n\n\n\nres.minimizer\n\n2-element Vector{Float64}:\n 0.2999999646891661\n 0.3000426967172676\n\n\n\n# with optim\nres = Optim.optimize(\n    u-&gt;-f(u), # objective\n    [-Inf, -Inf], # lower bound\n    [0.3, Inf], # upper bound\n    [0.1,0.3], # initial guess\n)\n\n\n * Status: success\n\n * Candidate solution\n    Final objective value:     -9.600000e-01\n\n * Found with\n    Algorithm:     Fminbox with L-BFGS\n\n * Convergence measures\n    |x - x'|               = 4.00e-07 ≰ 0.0e+00\n    |x - x'|/|x'|          = 9.42e-07 ≰ 0.0e+00\n    |f(x) - f(x')|         = 0.00e+00 ≤ 0.0e+00\n    |f(x) - f(x')|/|f(x')| = 0.00e+00 ≤ 0.0e+00\n    |g(x)|                 = 4.00e-10 ≤ 1.0e-08\n\n * Work counters\n    Seconds run:   0  (vs limit Inf)\n    Iterations:    3\n    f(x) calls:    45\n    ∇f(x) calls:   45\n\n\n\nres.minimizer\n\n2-element Vector{Float64}:\n 0.29999999989879517\n 0.30000000003791916\n\n\nReformulate the problem as a root finding problem with lagrangians. Write the complementarity conditions.\nSolve using NLSolve.jl",
    "crumbs": [
      "Tutorials",
      "Optimization"
    ]
  },
  {
    "objectID": "tutorials/4_Optimization.html#consumption-optimization",
    "href": "tutorials/4_Optimization.html#consumption-optimization",
    "title": "Optimization",
    "section": "Consumption optimization",
    "text": "Consumption optimization\nA consumer has preferences \\(U(c_1, c_2)\\) over two consumption goods \\(c_1\\) and \\(c_2\\).\nGiven a budget \\(I\\), consumer wants to maximize utility subject to the budget constraint \\(p_1 c_1 + p_2 c_2 \\leq I\\).\nWe choose a Stone-Geary specification where\n\\(U(c_1, c_2)=\\beta_1 \\log(c_1-\\gamma_1) + \\beta_2 \\log(c_2-\\gamma_2)\\)\nWrite the Karush-Kuhn-Tucker necessary conditions for the problem.\nVerify the KKT conditions are sufficient for optimality.\nDerive analytically the demand functions, and the shadow price.\nInterpret this problem as a complementarity problem and solve it using NLSolve.\nProduce some nice graphs with isoutility curves, the budget constraint and the optimal choice.",
    "crumbs": [
      "Tutorials",
      "Optimization"
    ]
  },
  {
    "objectID": "tutorials/1_Julia_Basics.html",
    "href": "tutorials/1_Julia_Basics.html",
    "title": "Julia Basics",
    "section": "",
    "text": "developped at MIT on top of opensource technologies\n\nlinux / git / llvm\n\nsyntax inspired by Matlab but:\n\nmore consistent\nlots of features from high level languages\n\neverything is JIT-compiled\n\ninterpreted vs compiled treadeoff\n-&gt; very fast\nmost of the base library is written in Julia\n\nopensource/free + vibrant community\n\nSome useful links from QuantEcon:\n\nJulia cheatsheet\nJulia-Matlab comparison\nJulia essentials\nVectors, arrays and matrices\n\nExcellent resources at: julialang - checkout JuliaAcademy, it’s free - ongoing MOOC at MIT",
    "crumbs": [
      "Tutorials",
      "Julia Basics"
    ]
  },
  {
    "objectID": "tutorials/1_Julia_Basics.html#additional-exercises",
    "href": "tutorials/1_Julia_Basics.html#additional-exercises",
    "title": "Julia Basics",
    "section": "Additional Exercises",
    "text": "Additional Exercises\nTaken from QuantEcon’s Julia Essentials and Vectors, Arrays, and Matrices lectures.\n\nConsider the polynomial \\[p(x) = \\sum_{i=0}^n a_0 x^0\\] Using enumerate, write a function p such that p(x, coeff) computes the value of the polynomial with coefficients coeff evaluated at x.\n\n\n\n\nppp (generic function with 1 method)\n\n\n\nWrite a function solve_discrete_lyapunov that solves the discrete Lyapunov equation \\[S = ASA' + \\Sigma \\Sigma'\\] using the iterative procedure \\[S_0 = \\Sigma \\Sigma'\\] \\[S_{t+1} = A S_t A' + \\Sigma \\Sigma'\\] taking in as arguments the \\(n \\times n\\) matrix \\(A\\), the \\(n \\times k\\) matrix \\(\\Sigma\\), and a number of iterations.",
    "crumbs": [
      "Tutorials",
      "Julia Basics"
    ]
  },
  {
    "objectID": "tutorials/1_Julia_Basics_pablo.html",
    "href": "tutorials/1_Julia_Basics_pablo.html",
    "title": "Julia Basics",
    "section": "",
    "text": "developped at MIT on top of opensource technologies\n\nlinux / git / llvm\n\nsyntax inspired by Matlab but:\n\nmore consistent\nlots of features from high level languages\n\neverything is JIT-compiled\n\ninterpreted vs compiled treadeoff\n-&gt; very fast\nmost of the base library is written in Julia\n\nopensource/free + vibrant community\n\nSome useful links from QuantEcon:\n\nJulia cheatsheet\nJulia-Matlab comparison\nJulia essentials\nVectors, arrays and matrices\n\nExcellent resources at: julialang - checkout JuliaAcademy, it’s free - ongoing MOOC at MIT"
  },
  {
    "objectID": "tutorials/1_Julia_Basics_pablo.html#additional-exercises",
    "href": "tutorials/1_Julia_Basics_pablo.html#additional-exercises",
    "title": "Julia Basics",
    "section": "Additional Exercises",
    "text": "Additional Exercises\nTaken from QuantEcon’s Julia Essentials and Vectors, Arrays, and Matrices lectures.\n\nConsider the polynomial \\[p(x) = \\sum_{i=0}^n a_0 x^0\\] Using enumerate, write a function p such that p(x, coeff) computes the value of the polynomial with coefficients coeff evaluated at x.\n\n\n\n\nppp (generic function with 1 method)\n\n\n\nWrite a function solve_discrete_lyapunov that solves the discrete Lyapunov equation \\[S = ASA' + \\Sigma \\Sigma'\\] using the iterative procedure \\[S_0 = \\Sigma \\Sigma'\\] \\[S_{t+1} = A S_t A' + \\Sigma \\Sigma'\\] taking in as arguments the \\(n \\times n\\) matrix \\(A\\), the \\(n \\times k\\) matrix \\(\\Sigma\\), and a number of iterations."
  },
  {
    "objectID": "pushups/2_Optimization_pushups.html",
    "href": "pushups/2_Optimization_pushups.html",
    "title": "Optimization Pushups",
    "section": "",
    "text": "The spirit of this simple tutorial consists in learning how to write simple solution algorithms. For each algorithm, test that it works, using simple test functions whose solution is known.\nWrite a function fixed_point(f::Function, x0::Float64) which computes the fixed point of f starting from initial point x0.\nWrite a function bisection(f::Function, a::Float64, b::Float64) which computes a zero of function f within (a,b) using a bisection method.\nWrite a function golden(f::Function, a::Float64, b::Float64) which computes a zero of function f within (a,b) using a golden ratio method.\nWrite a function zero_newton(f::Function, x0::Float64) which computes the zero of function f starting from initial point x0.\nAdd an option zero_newton(f::Function, x0::Float64, backtracking=true) which computes the zero of function f starting from initial point x0 using backtracking in each iteration.\nWrite a function min_gd(f::Function, x0::Float64) which computes the minimum of function f using gradient descent. Assume f returns a scalar and a gradient.\nWrite a function min_nr(f::Function, x0::Float64) which computes the minimum of function f using Newton-Raphson method. Assume f returns a scalar, a gradient, and a hessian.\nWrite a method zero_newton(f::Function, x0::Vector{Float64}) which computes the zero of a vector valued function f starting from initial point x0.\nAdd an method zero_newton(f::Function, x0::Vector{Float64}, backtracking=true) which computes the zero of function f starting from initial point x0 using backtracking in each iteration.\nAdd a method zero_newton(f::Function, x0::Vector{Float64}, backtracking=true, lb=Vector{Float64}) which computes the zero of function f starting from initial point x0 taking complementarity constraint into account x&gt;=lb using the Fischer-Burmeister method.",
    "crumbs": [
      "Pushups",
      "Optimization Pushups"
    ]
  },
  {
    "objectID": "6_automatic_differentiation.html",
    "href": "6_automatic_differentiation.html",
    "title": "Simulation and Automatic Differentiation",
    "section": "",
    "text": "Choose a 2x2 matrix \\(P\\) (with spectral radius &lt;1) and a 2x2 matrix Q.\nConsider the VAR1 process \\(x_t = P x_{t-1} + Q \\epsilon_t\\) where \\(\\epsilon_t= (\\eta_{1,t}, \\eta_{2,t})\\) with \\(\\eta_1\\sim\\mathcal{N}(0,1)\\) and \\(\\eta_1\\sim\\mathcal{N}(0,1)\\)\nCompute impulse response functions.\nSimulate the process for \\(T\\) periods.\nSimulate the process \\(N=1000\\) times for \\(T=1000\\) periods. How would you store the results?\nBonus: how can you make the calculation faster?\nMake density plots to illustrate the ergodic property of the process\nCompute the asymptotic variance of the process. Compare with the theoretical one."
  },
  {
    "objectID": "6_automatic_differentiation.html#learning-the-consumption-rule",
    "href": "6_automatic_differentiation.html#learning-the-consumption-rule",
    "title": "Simulation and Automatic Differentiation",
    "section": "Learning the Consumption Rule",
    "text": "Learning the Consumption Rule\nThis exercise is inspired from Individual learning about consumption by Todd Allen and Chris Carroll link and from Deep Learning for Solving Economic models by Maliar, Maliar and Winant link\nWe consider the following consumption saving problem. An agent receives random income \\(y_t = \\exp(\\epsilon_t)\\) where \\(\\epsilon_t\\sim \\mathcal{N}(\\sigma)\\) (\\(\\sigma\\) is the standard deviation.)\nConsumer starts the period with available income \\(w_t\\). The law of motion for available income is:\n\\[w_t = \\exp(\\epsilon_t) + (w_{t-1}-c_{t-1}) r\\]\nwhere consumption \\(c_t \\in ]0,w_t]\\) is chosen in each period in order to maximize:\n\\[E_t \\sum_{t=0}^T \\beta^t U(c_t)\\]\ngiven initial available income \\(w_0\\).\nIn the questions below, we will use the following calibration:\n\n\\(\\beta = 0.9\\)\n\\(\\sigma = 0.1\\)\n\\(T=100\\)\n\\(U(x) = \\frac{x^{1-\\gamma}}{1-\\gamma}\\) with \\(\\gamma=2\\)\n\\(w_0 = 1.1\\) (alternatively, consider values 0.5 and 1)\n\nThe theoretical solution to this problem is a concave function \\(\\varphi\\) such that \\(\\varphi(x)\\in ]0,x]\\) and \\(\\forall t,  c_t=\\varphi(w_t)\\). Qualitatively, agents accumulate savings, up to a certain point (a buffer stock), beyond which wealth is not increasing any more (in expectation).\nCarroll and Allen have noticed that the true solution can be approximated very well by a simple rule:\n\\(\\psi(x) = \\min(x, \\theta_0 + \\theta_1 (x - \\theta_0) )\\)\nThe main question they ask in the aforementioned paper is whether it is realistic that agents would learn good values of \\(\\theta_0\\) and \\(\\theta_1\\) by observing past experiences.\nWe would like to examine this result by checking convergence of speed of stochastic gradient algorithm.\n\nLifetime reward\nDefine a NamedTuple to hold the parameter values\nDefine simple rule fonction consumption(w::Number, θ_0::Number, θ_1::Number, p::NamedTuple) which compute consumption using a simple rule. What is the meaning of \\(\\theta_0\\) and \\(\\theta_1\\)? Make a plot in the space \\(w,c\\), including consumption rule and the line where \\(w_{t+1} = w_t\\).\n(remark for later: Number type is compatible with ForwardDiff.jl 😉)\nWrite a function lifetime_reward(w_0::Number, θ_0::Number, θ_1::Number, p::NamedTuple) which computes one realization of \\(\\sum \\beta^t U(c_t)\\) for initial wealth w_0 and simple rule θ_0, θ_1. Mathematically, we denote it by \\(\\xi(\\omega; \\theta_0, \\theta_1)\\), where \\(\\omega\\) represents the succession of random income draws.\nWrite a function expected_lifetime_reward(w_0::Number, θ_0::Number, θ_1::Number,  p::NamedTuple; N=1000) which computes expected lifetime reward using N Monte-Carlo draws. Mathematically, we write it \\(\\Xi^{N}(\\theta_0, \\theta_1) =\\frac{1}{N} \\sum_1^N {\\xi(\\omega_N; \\theta_0, \\theta_1)}\\). Check empirically that standard deviation of these draws decrease proportionally to \\(\\frac{1}{\\sqrt{N}}\\) .\n__Using a high enough number for N, compute optimal values for \\(\\theta_0\\) and \\(\\theta_1\\). What is the matching value for the objective function converted into an equivalent stream of determinstic consumption ? That is if V is the approximated value computed above, what is \\(\\bar{c}\\in \\R\\) such that $ V= _{t=0}^T ^t U({c})$ ?__\nUsing a high enough number for N, make contour plots of lifetime rewards as a function of θ_0 and θ_1. Ideally, represent lines with \\(1\\%\\) consumption loss, \\(5\\%\\) and \\(10\\%\\) deterministic consumption loss w.r.t. to maximum.\n\n\nLearning to save\nWe now focus on the number of steps it takes to optimize \\(\\theta_0\\), \\(\\theta_1\\).\nImplement a function ∇(θ::Vector; N=1000)::Vector which computes the gradient of the objective w.r.t. θ==[θ_0,θ_1]. (You need to use automatic differentiation, otherwise you might get incorrect results).\nImplement a gradient descent algorithm to maximize \\(\\Xi^N(\\theta_0, \\theta_1)\\) using learning rate \\(\\lambda \\in ]0,1]\\). Stop after a predefined number of iterations. Compare convergence speed for different values of \\(\\lambda\\) and plot them on the \\(\\theta_0, \\theta_1\\) plan. How many steps does it take to enter the 1% error zone? The 5% and the 10% error zone?\nEven for big N, the evaluated value of ∇ are stochastic, and always slightly inaccurate. In average, they are non-biased and the algorithm converges in expectation (it fluctuates around the maximum). This is called the stochastic gradient method.\nWhat are the values of \\(N\\) and \\(\\lambda\\) which minimize the number of iterations before reaching the target zones (at 1%, 2%, etc…)? How many simulations periods does it correspond to? Would you say it is realistic that consumers learn from their own experience?"
  }
]