{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Discretization\n",
        "subtitle:  \"Advanced Macro: Numerical Methods\"\n",
        "author: Year 2022-2023 (MIE37)\n",
        "format:\n",
        "  revealjs:\n",
        "    html-math-method: mathjax\n",
        "    navigation-mode: grid\n",
        "    width: 1920\n",
        "    height: 1080\n",
        "---"
      ],
      "id": "29de6c2e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "----\n",
        "\n",
        "### Several kinds of Discretization\n",
        "\n",
        "\n",
        "- approximate operator with a finite number of iterations:\n",
        "    - compute $\\int_a^b f(x) dx$\n",
        "    - compute $E_\\omega f(\\omega)$\n",
        "- represent an infinite dimensional object with a finite set of parameters:\n",
        "    - $f \\equiv (f(x_i))_{i=1:N}$ with $x_i=a+\\frac{i-1}{N-1}(b-a)$\n",
        "      - discretize arguments\n",
        "    - $\\omega \\equiv (\\mu_i, \\omega_i)_{i=1:N}$ such that $E_\\omega f(\\omega) \\approx \\sum_i \\mu_i f(\\omega_i)$ (quantization)\n",
        "- discretize continous process by a discrete one:\n",
        "  - continuous markov chain to discrete markov Chain"
      ],
      "id": "564be295"
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Discretizing an AR1\n",
        "\n",
        "----\n",
        "\n",
        "### Discretizing an AR1\n",
        "\n",
        "- Take $AR1$ process $$x_t = \\rho x_{t-1} + \\epsilon_t$$\n",
        "    - with $|\\rho| <1$ and $\\epsilon \\sim N(0,\\sigma)$\n",
        "- Can we replace $(x_t)$ by a discrete markov chain?\n",
        "    - approximate version:\n",
        "      - good time $x^g$ and bad time $x^b$. Probability $\\pi$ of staying in the same, $1-\\pi$ of switching.\n",
        "    - two systematic methods (available in *QuantEcon.jl*)\n",
        "        - Tauchen\n",
        "        - Rouwenhorst\n",
        "\n",
        "----\n",
        "\n",
        "### AR1: Tauchen\n",
        "\n",
        "- The unconditional distribution of an AR1 is a normal law $\\mathcal{N}(0,\\frac{\\sigma}{\\sqrt{1-\\rho^2}})$\n",
        "\n",
        "- Choose $m>0$, typically $m=3$\n",
        "- Bound the process: $\\underline{x} = -m \\frac{\\sigma}{\\sqrt{1-\\rho^2}}$ and $\\overline{x} = m \\frac{\\sigma}{\\sqrt{1-\\rho^2}}$\n",
        "- Define the $N$ discretized points ($i\\in[1,n]$): $y_i = \\underline{x} + \\frac{i-1}{N-1}(\\overline{x}-\\underline{x})$\n",
        "- Define the transitions:\n",
        "\n",
        "$$\\begin{eqnarray}\n",
        "\\pi_{ij} & = & prob \\left( y_{t+1}=y_j|y_t=y_i\\right)\\\\\n",
        "         & = & prob \\left( |y_{t+1}-x_j| = \\inf_k |y_{t+1}-x_k| \\left| y_t=y_i \\right. \\right)\n",
        "\\end{eqnarray}$$\n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "### AR1: Tauchen (2)\n",
        "\n",
        "- Formulas $\\delta=\\frac{\\overline{x}-\\underline{x}}{N}$:\n",
        "\n",
        "    - if $1<k<N-1$\n",
        "\n",
        "        $$\\pi_{jk} = F(\\frac{y_k + \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) - F(y_k + \\delta/2-\\rho y_j)$$\n",
        "\n",
        "    - if $k=1$\n",
        "\n",
        "        $$\\pi_{j} = F(\\frac{y_k + \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) $$\n",
        "\n",
        "    - if $k=N$\n",
        "\n",
        "        $$\\pi_{j} = 1- F(\\frac{y_k - \\delta/2-\\rho y_j}{\\sigma_{\\epsilon}}) $$\n",
        "\n",
        "----\n",
        "\n",
        "### How to assess the quality of approximation ?\n",
        "\n",
        "- compare generated stationary moments between discretized process and true AR1:\n",
        "  - E(), Var(), ACor()\n",
        "\n",
        "- by looking at the exact ergodic distribution or by doing some simulations\n",
        "\n",
        "- not very precise when then process is very persistent $\\rho\\approx 1$\n",
        "\n",
        "----\n",
        "\n",
        "### Rouvenhorst method (1)\n",
        "\n",
        "- N = 2\n",
        "  - choose $y_1=-\\psi$, $y_2=\\psi$\n",
        "  - define transition matrix:\n",
        "$$\\Theta_2 = \\begin{bmatrix}\n",
        "p & 1-p\\\\\\\\\n",
        "1-q & q\n",
        "\\end{bmatrix}$$\n",
        "  - choose $p$, $q$ and $\\psi$ to match some moments: $E()$, $Var()$, $ACor()$\n",
        "    - they can be computed analytically for AR1 and for discretized version.\n",
        "\n",
        "----\n",
        "\n",
        "### Rouvenhorst method (2)\n",
        "\n",
        "- N >2\n",
        "$$\\Theta_N =\n",
        "p \\begin{bmatrix}  \n",
        "\\Theta_{N-1}  & 0\\\\\\\\\n",
        "0 & 0\n",
        "\\end{bmatrix} +\n",
        "(1-p) \\begin{bmatrix}  \n",
        "0 & \\Theta_{N-1} \\\\\\\\\n",
        "0 & 0\n",
        "\\end{bmatrix} +\n",
        "(1-q) \\begin{bmatrix}  \n",
        "0 & 0\\\\\\\\\n",
        "\\Theta_{N-1} & 0\n",
        "\\end{bmatrix} +\n",
        "q \\begin{bmatrix}  \n",
        "0 & 0\\\\\\\\\n",
        "0 & \\Theta_{N-1}\n",
        "\\end{bmatrix}\n",
        "$$\n",
        "- Normalize all lines\n",
        "\n",
        "----\n",
        "\n",
        "### Rouvenhorst method (3)\n",
        "\n",
        "- Procedure converges to Bernouilli distribution.\n",
        "\n",
        "- Moments can be computed in closed form:\n",
        "\n",
        "    - $E() = \\frac{(q-p)\\psi}{2-(p+q)}$\n",
        "    - $Var() = \\psi^2 \\left[ 1-4 s (1-s) + \\frac{4s(1-s)}{N-1}\\right]$\n",
        "    - $Acor()= p+q-1$\n",
        "\n",
        "- Rouwenhorst method performs better for highly correlated processes\n",
        "\n",
        "\n",
        "---"
      ],
      "id": "8384957d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Discretizing an iid law\n",
        "\n",
        "----\n",
        "\n",
        "### Common problem:\n",
        "\n",
        "- Given $f$, and an iid process $\\epsilon \\sim N(0,\\sigma^2)$, how to approximate\n",
        " $E_{\\epsilon} f(\\epsilon)$ ?\n",
        "\n",
        "- Ideas:\n",
        "    - draw *lots* of random $(\\epsilon\\_n)\\_{n=1:N}$ and compute $$\\frac{1}{N}\\sum_{n=1}^N f(\\epsilon_n)$$\n",
        "        - aka Monte-Carlo simulations\n",
        "    - given a method to approximate integrals, compute $$\\int_{u=-\\infty}^{\\infty} f(u) \\mu(u) du$$ with $\\mu(u)=\\frac{1}{\\sigma\\sqrt{2 \\pi}}e^{-\\frac{u^2}{2\\sigma^2}}$\n",
        "    - *discretize* (or *quantize*) the signal $\\epsilon$ as \n",
        "$(w_i, \\epsilon_i)_{i=1:N}$ and compute:\n",
        "\n",
        "$$\\frac{1}{N} \\sum_n w_n f(\\epsilon_n)$$ \n",
        "\n",
        "----\n",
        "\n",
        "### What's wrong with Monte-Carlo Simulations?\n",
        "\n",
        "- Let's take an exemple:\n",
        "  - consumption is $C(\\epsilon)=U(e^{\\epsilon})$ \n",
        "  - with ${\\sigma}\\_{\\epsilon}=0.05$ and $U(x)=\\frac{x^{1-\\gamma}}{1-\\gamma}$ and $\\gamma=40$.\n",
        "-  Let's compute $E_{\\epsilon}(C(\\epsilon))$ precisely.\n",
        "\n",
        "- Discuss value of $\\gamma$: is it crazy? (risk return)\n",
        "\n",
        "----\n",
        "\n",
        "\n",
        "### What's wrong with Monte-Carlo Simulations?\n",
        "\n",
        "Compute expectation\n",
        "\n",
        "\n",
        "```{julia [1-3|4-7|9-10|14|16-17]}\n",
        "# imports:\n",
        "using Distributions: Normal\n",
        "\n",
        "# define the model\n",
        "σ = 0.05; γ = 40\n",
        "U(x)=(x^(-γ))/(-γ)\n",
        "C(e) = U(exp(e))\n",
        "\n",
        "# create distributions\n",
        "dis = Normal(0,σ)      \n",
        "E_ϵ(f;N=1000) = sum(f(rand(dis)) for i=1:N)/N\n",
        "\n",
        "NVec = [1000, 5000, 10000, 15000, 20000]\n",
        "vals = [E_ϵ(C; N=i) for i=NVec]\n",
        "```\n",
        "\n",
        "\n",
        "```\n",
        "julia> vals = [E_ϵ(C; N=i) for i=NVec\n",
        "5-element Array{Float64,1}:\n",
        " -0.17546927855215824\n",
        " -0.2906119630309043\n",
        " -0.17924501776041424\n",
        " -0.1826805612086024\n",
        " -0.181184208323609\n",
        "``` \n",
        "<!-- .element class=\"fragment\" -->\n",
        "\n",
        "----\n",
        "\n",
        "### What's wrong with Monte-Carlo Simulations?\n",
        "\n",
        "```julia [1-2|3-7]\n",
        "using Statistics: std\n",
        "\n",
        "#computes estimates for various N\n",
        "stdev(f; N=100, K=100) = std(E_ϵ(f; N=N) for k=1:K)\n",
        "sdvals = [stdev(C; N=n, K=10000) for n=NVec]\n",
        "```\n",
        "\n",
        "```\n",
        "julia> @time sdvals = [stdev(C; N=n, K=10000) for n=NVec]      \n",
        " 99.558940 seconds (2.55 G allocations: 38.011 GiB, 0.81% gc time)\n",
        "5-element Array{Float64,1}:                                       \n",
        " 0.04106466473642666                                              \n",
        " 0.018296399941889575                                             \n",
        " 0.013174287295527257                                             \n",
        " 0.01086721462174894                                              \n",
        " 0.009383218078206898 \n",
        "```\n",
        "<!-- .element class=\"fragment\" -->\n",
        "\n",
        "----\n",
        "\n",
        "### Quick theory (1)\n",
        "\n",
        "- Fact: the sum of several independent gaussian variables is a gaussian  variable\n",
        "- So $T_N =\\frac{1}{N}\\sum_{n=1}^N \\epsilon_n$ is  gaussian variable. Its mean is 0 (unbiased).  Let's compute its variance:\n",
        "$$E(T_N^2) = \\frac{1}{N^2} \\sum_{n=1}^N E\\left[ \\epsilon_n^2 \\right]$$\n",
        "- The standard deviation is:\n",
        "$$s_N = \\sigma(T_N^2) = \\frac{1}{\\sqrt{\\color{red} N}} \\sigma_{\\epsilon}$$\n",
        "- Conclusion: the precision of (basic) Monte-Carlo decreases only as a square root of the number of experiments.\n",
        "\n",
        "----\n",
        "\n",
        "### Quick theory (2)\n",
        "\n",
        "- In the general case, the Monte-Carlo estimator is:\n",
        "$$T^{MC}\\_N =\\frac{1}{N}\\sum\\_{n=1}^N f(\\epsilon_n)$$\n",
        "- It is unbiased:\n",
        "$$E(T_N^{MC}) = E\\left[f(\\epsilon) \\right]$$\n",
        "- It's variance is \n",
        "$$E(T_N^{MC}) \\propto \\frac{1}{\\sqrt{N}}$$\n",
        "    - slow\n",
        "    - on the plus side: rate independent of the dimension of $\\epsilon$\n",
        "\n",
        "----\n",
        "\n",
        "### Quantization using quantiles\n",
        "\n",
        "\n",
        "<div class=\"container\">\n",
        "<div class=\"col\">\n",
        "\n",
        "- *Equiprobable* discretization\n",
        "- Works for any distribution with pdf and cdf\n",
        "- Split the space into equal $N$ quantiles:\n",
        "  $$(I_i=[a_i,a_{i+1}])_{i=1:N}$$ such that $$prob(\\epsilon \\in I_i)=\\frac{1}{N}$$\n",
        "- Choose the *nodes* as the median of each interval: $$prob(\\epsilon\\in[a_i,x_i]) = prob(\\epsilon\\in[x_i,a_{i+1}])$$\n",
        "- The quantization is $(1/N, x_i)_{i=1:N}$\n",
        "\n",
        "</div>\n",
        "\n",
        "<div class=\"col\">\n",
        "\n",
        "[graph]\n",
        "\n",
        "</div>\n",
        "\n",
        "</div>\n",
        "\n",
        "\n",
        "<!-- ### Quadrature rule\n",
        "\n",
        "Idea:\n",
        "- $f\\in \\mathcal{F}$ a Banach space\n",
        "  - $I: f\\rightarrow E_{\\epsilon} f(\\epsilon)$ is a linear application\n",
        "- suppose there is a dense family of polynomials $P_n$, spanning $\\mathcal{F}_n$\n",
        "  - $I$ restricted to $\\mathcal{F}_N$ is a $N$-dimensional linear form\n",
        "- take $N$ points $(a_n)_{n\\in[1,N]}$. The set $\\{f\\rightarrow\\sum_{n=1}^N w_n f(a_n) | w_1, ... w_N\\}$ is a vectorial space.\n",
        "  - one element matches exactly $\\left.I\\right|_{\\mathcal{F}}$\n",
        "- so the quadrature rule $(w_n, a_n)$ is exactly accurate for polynomials of order $n<N$.\n",
        "  - how to choose the points $a_n$?\n",
        "\n",
        "--- -->\n",
        "\n",
        "----\n",
        "\n",
        "### Gauss-Hermite\n",
        "\n",
        "- $f\\in \\mathcal{F}$ a Banach space (or $\\mathbb{R}^n$), $\\epsilon$ a gaussian variable\n",
        "  - $I: f\\rightarrow E_{\\epsilon} f(\\epsilon)$ is a linear application\n",
        "- suppose there is a dense family of polynomials $P_n$, spanning $\\mathcal{F}_n$\n",
        "  - $I$ restricted to $\\mathcal{F}_N$ is a $N$-dimensional linear form\n",
        "  \n",
        "- Gauss quadrature magic\n",
        "  - a way to choose $\\\\epsilon_i$ __and__ $w_i$ such that $$\\left(f\\rightarrow\\sum\\_{n=1}^N w_n f(\\epsilon_i) \\right)= \\left.I\\right|\\_{\\mathcal{F}_{2N}}$$\n",
        "\n",
        "----\n",
        "\n",
        "### Gauss-Hermite\n",
        "\n",
        "- Very accurate if a function can be approximated by polynomials\n",
        "- Bad:\n",
        "  - imprecise if function $f$ has kinks or non local behaviour\n",
        "    - points $\\epsilon_n$ can be very far from the origin (TODO: graph)\n",
        "  - not super easy to commute weights and nodes (but there are good libraries)\n",
        "\n",
        "----\n",
        "\n",
        "### Gauss-*\n",
        "\n",
        "- Same logic can be applied to compute integration with weight function $w(x)$: \n",
        "  $$\\int_a^b f(x) w(x)$$\n",
        "\n",
        "- Gauss-Hermite:\n",
        "  - $w(x) = e^{-x^2}$, $[a,b] = [-\\infty, \\infty]$\n",
        "\n",
        "- Gauss-Legendre:\n",
        "  - $w(x) = 1$\n",
        "\n",
        "- Gauss-Chebychev:\n",
        "  - $w(x)=\\sqrt{1-x^2}$,  $[a,b] = [-1, 1]$\n",
        "  - for periodic functions\n",
        "\n",
        "----\n",
        "\n",
        "### In practice\n",
        "\n",
        "Beware that weight is not the density of the normal law:\n",
        "\n",
        "$$\\frac{1}{\\sqrt{2 \\pi \\sigma^2}}\\int f(x) e^{-\\frac{x^2}{2\\sigma^2}}dx = \\color{red}{\\frac{1}{\\sqrt{\\pi}}}\\int f(u \\color{\\red}{\\sigma \\sqrt{2}}) e^{-{u^2}}du $$\n",
        "$$\\color{\\red}{\\frac{1}{\\sqrt{\\pi}}}\\sum_n w_n f(\\epsilon_n \\color{\\red}{\\sigma \\sqrt{2}})$$\n",
        "\n",
        "```julia\n",
        "using FastGaussQuadrature\n",
        "\n",
        "x, w = gausslegendre( 10 );\n",
        "x = x.*σ*sqrt(2) # renormalize nodes\n",
        "s = sum( w_*U(exp(x_)) for (w_,x_) in zip(x,w))\n",
        "s /= sqrt(\\pi) # renormalize output\n",
        "```\n"
      ],
      "id": "4128869b"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}